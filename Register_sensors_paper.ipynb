{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4aef01bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "import json\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import teaserpp_python\n",
    "from numpy.linalg import inv\n",
    "from scipy.spatial import cKDTree\n",
    "import time\n",
    "from PIL import Image\n",
    "import torchvision\n",
    "import torch\n",
    "from torchvision import transforms as T \n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n",
    "from numba import jit, prange\n",
    "import os\n",
    "import csv \n",
    "# Load MaskRCNN \n",
    "\n",
    "from multiprocessing import Pool\n",
    "\n",
    "def pad_depth_to_color(depth, color):\n",
    "    # Calculate differences in dimensions\n",
    "    height_diff = color.shape[0] - depth.shape[0]\n",
    "    width_diff = color.shape[1] - depth.shape[1]\n",
    "    \n",
    "    # Compute padding values for height and width\n",
    "    pad_top = height_diff // 2\n",
    "    pad_bottom = height_diff - pad_top\n",
    "    pad_left = width_diff // 2\n",
    "    pad_right = width_diff - pad_left\n",
    "    \n",
    "    # Apply padding\n",
    "    padded_depth = np.pad(depth, ((pad_top, pad_bottom), (pad_left, pad_right)), mode='constant', constant_values=0)\n",
    "    \n",
    "    return padded_depth\n",
    "\n",
    "def load_maskrcnn_model(model_path):\n",
    "    model = torchvision.models.detection.maskrcnn_resnet50_fpn(weights=\"DEFAULT\")\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, 2)\n",
    "    in_features_mask = model.roi_heads.mask_predictor.conv5_mask.in_channels\n",
    "    hidden_layer = 256\n",
    "    model.roi_heads.mask_predictor = MaskRCNNPredictor(in_features_mask, hidden_layer, 2)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model.eval()\n",
    "\n",
    "    return model\n",
    "\n",
    "def get_model_mask(model_generic, image):\n",
    "    proba_threshold = 0.5\n",
    "    ig = transform(image)\n",
    "    with torch.no_grad():\n",
    "        prediction = model_generic([ig.to(device)])\n",
    "        \n",
    "    if(prediction[0]['masks'].nelement() == 0):\n",
    "        XX = torch.empty((0,0), dtype=torch.int64)\n",
    "        return XX\n",
    "    predicted_mask = prediction[0]\n",
    "    predicted_mask = predicted_mask['masks'][0] > proba_threshold\n",
    "    \n",
    "    predicted_mask = predicted_mask.squeeze(1)\n",
    "    mask = predicted_mask.cpu().detach()\n",
    "    return mask\n",
    "\n",
    "\n",
    "def segment_images_modified(last_frame):\n",
    "    depth_PIL = Image.fromarray(np.asarray(last_frame.depth)).convert(\"RGB\")\n",
    "    rgb_image_array = np.asarray(last_frame.color)\n",
    "    depth_image_array = np.asarray(last_frame.depth)\n",
    "    rgb_PIL = Image.fromarray(rgb_image_array)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    rgb_mask = get_model_mask(model_rgb, rgb_PIL)\n",
    "    depth_mask = get_model_mask(model_depth, depth_PIL)\n",
    "\n",
    "    if depth_mask.nelement() == 0:\n",
    "        mask_combined = rgb_mask\n",
    "    else:\n",
    "        mask_combined = depth_mask | rgb_mask  # 1 vote arbitration (OR the masks)\n",
    "\n",
    "    # Convert tensor to numpy array and ensure the right datatype\n",
    "    mask_combined = mask_combined.numpy().astype(rgb_image_array.dtype)\n",
    "    mask_image = mask_combined.swapaxes(0, 2).swapaxes(0, 1)\n",
    "    mask_image = (mask_image > 0).astype(rgb_image_array.dtype)   \n",
    "\n",
    "    fg_image_rgb = rgb_image_array * mask_image\n",
    "\n",
    "    # For the depth image:\n",
    "    squeezed_mask = np.squeeze(mask_image)\n",
    "    fg_image_depth = depth_image_array * squeezed_mask\n",
    "    \n",
    "    \n",
    "    last_frame.color = o3d.geometry.Image(fg_image_rgb)\n",
    "    last_frame.depth = o3d.geometry.Image(fg_image_depth)\n",
    "   \n",
    "\n",
    "\n",
    "    return last_frame\n",
    "\n",
    "\n",
    "def filter_file_names(file_list): # to avoid the two head cameras\n",
    "    new_file_list = []\n",
    "    for f in file_list:\n",
    "        tmp = f.split('.mkv')[0]\n",
    "        ID  = tmp.split('_')[-1]\n",
    "        if (ID == \"13\" or ID == \"15\"):\n",
    "            continue\n",
    "        else :\n",
    "            new_file_list.append(f)\n",
    "    return new_file_list\n",
    "\n",
    "\n",
    "def draw_registration_result(source, target, transformation):\n",
    "    source_temp = copy.deepcopy(source)\n",
    "    target_temp = copy.deepcopy(target)\n",
    "    source_temp.paint_uniform_color([1, 0.706, 0])\n",
    "    target_temp.paint_uniform_color([0, 0.651, 0.929])\n",
    "    source_temp.transform(transformation)\n",
    "    o3d.visualization.draw_geometries([source_temp, target_temp])\n",
    "\n",
    "def cluster_point_cloud_new(outlier_cloud):\n",
    "    cloud_colors = copy.deepcopy(np.asarray(outlier_cloud.colors).T)\n",
    "    \n",
    "    with o3d.utility.VerbosityContextManager(o3d.utility.VerbosityLevel.Error) as cm:\n",
    "        labels = np.array(outlier_cloud.cluster_dbscan(eps=0.1, min_points=10, print_progress=False))\n",
    "\n",
    "    # Identify the largest cluster\n",
    "    values, counts = np.unique(labels, return_counts=True)\n",
    "    ind = np.argmax(counts)\n",
    "    largest_cluster_label = values[ind]\n",
    "    #print(f\"Largest cluster label: {largest_cluster_label}\")\n",
    "\n",
    "    # Filter points, normals, and colors for the largest cluster\n",
    "    cloud_xyz = pcd2xyz(outlier_cloud)\n",
    "    cloud_normals = pcd2normals(outlier_cloud)\n",
    "\n",
    "    cloud_filtered = cloud_xyz[:, labels == largest_cluster_label]\n",
    "    normals_filtered = cloud_normals[:, labels == largest_cluster_label]\n",
    "    colors_filtered = cloud_colors[:, labels == largest_cluster_label]\n",
    "\n",
    "    # Create a point cloud for the largest cluster\n",
    "    pcd_filtered_largest_cluster = o3d.geometry.PointCloud()\n",
    "    pcd_filtered_largest_cluster.points = o3d.utility.Vector3dVector(cloud_filtered.T)\n",
    "    pcd_filtered_largest_cluster.normals = o3d.utility.Vector3dVector(normals_filtered.T)\n",
    "    pcd_filtered_largest_cluster.colors = o3d.utility.Vector3dVector(colors_filtered.T)\n",
    "\n",
    "    #o3d.visualization.draw_geometries([pcd_filtered_largest_cluster])\n",
    "    return pcd_filtered_largest_cluster\n",
    "\n",
    "def upsample_using_reference_normals(sparse_pcd, dense_pcd, search_radius=0.02, angle_threshold=30):\n",
    "    \"\"\"\n",
    "    Efficiently upsample the sparse point cloud using the dense point cloud as reference.\n",
    "    Considers the normals to ensure added points are consistent with the sparse cloud.\n",
    "\n",
    "    Parameters:\n",
    "    - sparse_pcd: The sparse point cloud\n",
    "    - dense_pcd: The dense reference point cloud\n",
    "    - search_radius: Radius to search for neighbors\n",
    "    - angle_threshold: Maximum angle in degrees between normals to consider a point\n",
    "\n",
    "    Returns:\n",
    "    - A new upsampled point cloud\n",
    "    \"\"\"\n",
    "    # Ensure the point clouds have normals\n",
    "    if not sparse_pcd.has_normals():\n",
    "        sparse_pcd.estimate_normals()\n",
    "    if not dense_pcd.has_normals():\n",
    "        dense_pcd.estimate_normals()\n",
    "\n",
    "    kdtree = o3d.geometry.KDTreeFlann(dense_pcd)\n",
    "\n",
    "    sparse_points = np.asarray(sparse_pcd.points)\n",
    "    sparse_normals = np.asarray(sparse_pcd.normals)\n",
    "    added_points = set(map(tuple, sparse_points))\n",
    "\n",
    "    upsampled_points = list(sparse_points)\n",
    "\n",
    "    for i, point in enumerate(sparse_points):\n",
    "        [k, idx, _] = kdtree.search_radius_vector_3d(point, search_radius)\n",
    "        \n",
    "        neighbors = np.asarray(dense_pcd.points)[idx]\n",
    "        neighbor_normals = np.asarray(dense_pcd.normals)[idx]\n",
    "\n",
    "        # Calculate angles between sparse point's normal and all its neighbors' normals\n",
    "        angles = np.degrees(np.arccos(np.clip(np.dot(sparse_normals[i], neighbor_normals.T), -1.0, 1.0)))\n",
    "\n",
    "        # Filtering neighbors based on angle threshold\n",
    "        valid_neighbors = neighbors[angles < angle_threshold]\n",
    "\n",
    "        # Filtering out points that are already in the sparse cloud or have been added before\n",
    "        unique_valid_neighbors = [tuple(neighbor) for neighbor in valid_neighbors if tuple(neighbor) not in added_points]\n",
    "\n",
    "        upsampled_points.extend(unique_valid_neighbors)\n",
    "        added_points.update(unique_valid_neighbors)\n",
    "\n",
    "    upsampled_pcd = o3d.geometry.PointCloud()\n",
    "    upsampled_pcd.points = o3d.utility.Vector3dVector(upsampled_points)\n",
    "    upsampled_pcd.estimate_normals()\n",
    "\n",
    "    return upsampled_pcd\n",
    "\n",
    "\n",
    "def pcd2normals(pcd):\n",
    "    return np.asarray(pcd.normals).T\n",
    "def pcd2xyz(pcd):\n",
    "    return np.asarray(pcd.points).T\n",
    "\n",
    "\n",
    "@jit(nopython=True, parallel=True)\n",
    "def numba_eliminate_flying_pixels(depth_image, ws, threshold):\n",
    "    height, width = depth_image.shape\n",
    "    result = np.zeros_like(depth_image, dtype=np.float64)\n",
    "    \n",
    "    for cy in prange(height):\n",
    "        for cx in prange(width):\n",
    "            x_start, x_end = max(0, cx - ws), min(width, cx + ws + 1)\n",
    "            y_start, y_end = max(0, cy - ws), min(height, cy + ws + 1)\n",
    "            window = depth_image[y_start:y_end, x_start:x_end]\n",
    "            result[cy, cx] = np.sum(np.abs(window - depth_image[cy, cx]))\n",
    "    \n",
    "    return result\n",
    "\n",
    "def colored_ICP(source, target):\n",
    "    \n",
    "    voxel_radius = [0.04, 0.02, 0.01]\n",
    "    max_iter = [50, 30, 14]\n",
    "    current_transformation = np.identity(4)\n",
    "    #print(\"3. Colored point cloud registration\")\n",
    "    for scale in range(3):\n",
    "        iters = max_iter[scale]\n",
    "        radius = voxel_radius[scale]\n",
    "        #print(\"iteration: \", iters, radius, scale)\n",
    "\n",
    "        #print(\"3-1. Downsample with a voxel size %.2f\" % radius)\n",
    "        source_down = copy.deepcopy(source).voxel_down_sample(radius)\n",
    "        target_down = copy.deepcopy(target).voxel_down_sample(radius)\n",
    "\n",
    "        #print(\"3-2. Estimate normal.\")\n",
    "        source_down.estimate_normals(\n",
    "            o3d.geometry.KDTreeSearchParamHybrid(radius=radius * 2, max_nn=30))\n",
    "        target_down.estimate_normals(\n",
    "            o3d.geometry.KDTreeSearchParamHybrid(radius=radius * 2, max_nn=30))\n",
    "\n",
    "        #print(\"3-3. Applying colored point cloud registration\")\n",
    "        result_icp = o3d.pipelines.registration.registration_colored_icp(\n",
    "            source_down, target_down, radius, current_transformation,\n",
    "            o3d.pipelines.registration.TransformationEstimationForColoredICP(),\n",
    "            o3d.pipelines.registration.ICPConvergenceCriteria(relative_fitness=1e-6,\n",
    "                                                              relative_rmse=1e-6,\n",
    "                                                              max_iteration=iters))\n",
    "        current_transformation = result_icp.transformation\n",
    "    \n",
    "   \n",
    "        #draw_registration_result(source, target, current_transformation)\n",
    "    return current_transformation\n",
    "\n",
    "def backproject_o3d(rgbd_frame, intrinsics):\n",
    "    \n",
    "    rgbdc = o3d.geometry.RGBDImage.create_from_color_and_depth(\n",
    "        rgbd_frame.color, rgbd_frame.depth, depth_trunc=4.0, convert_rgb_to_intensity=False)\n",
    "    pcd = o3d.geometry.PointCloud.create_from_rgbd_image(rgbdc, intrinsics)\n",
    "    n_radius = 0.01*2.0\n",
    "    pcd.estimate_normals(\n",
    "    search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=n_radius, max_nn=30))\n",
    "    \n",
    "    return pcd\n",
    "\n",
    "def load_calibration(tform_path, num_transforms=5):\n",
    "    transforms = [np.eye(4)]  # Initialize with identity matrix\n",
    "    \n",
    "    # Load transformations from file\n",
    "    for i in range(1, num_transforms+1):\n",
    "        filename = tform_path + f\"H_0_{i}.txt\"\n",
    "        \n",
    "        if not os.path.exists(filename):\n",
    "            raise FileNotFoundError(f\"The file {filename} does not exist!\")\n",
    "        \n",
    "        transforms.append(np.loadtxt(filename))\n",
    "    \n",
    "    return transforms\n",
    "\n",
    "def perform_pairwise_alignment(pcds_tsdf,pcds_cropped):\n",
    "    #\"\"\"Compute and apply transformations.\"\"\"\n",
    "    t01 = colored_ICP(pcds_tsdf[0], pcds_tsdf[1])\n",
    "    t52 = colored_ICP(pcds_tsdf[5], pcds_tsdf[2])\n",
    "    t43 = colored_ICP(pcds_tsdf[4], pcds_tsdf[3])\n",
    "    t12 = colored_ICP(pcds_tsdf[1], pcds_tsdf[2])\n",
    "    t32 = colored_ICP(pcds_tsdf[3], pcds_tsdf[2])\n",
    "\n",
    "    H0 = t12 @ t01\n",
    "    H1 = t12\n",
    "    H3 = t32\n",
    "    H4 = t32 @ t43\n",
    "    H5 = t52\n",
    "\n",
    "    # Transform the point clouds\n",
    "    p0 = copy.deepcopy(pcds_cropped[0]).transform(H0)\n",
    "    p1 = copy.deepcopy(pcds_cropped[1]).transform(H1)\n",
    "    p3 = copy.deepcopy(pcds_cropped[3]).transform(H3)\n",
    "    p4 = copy.deepcopy(pcds_cropped[4]).transform(H4)\n",
    "    p5 = copy.deepcopy(pcds_cropped[5]).transform(H5)\n",
    "    \n",
    "    d0 = copy.deepcopy(pcds_tsdf[0]).transform(H0)\n",
    "    d1 = copy.deepcopy(pcds_tsdf[1]).transform(H1)\n",
    "    d3 = copy.deepcopy(pcds_tsdf[3]).transform(H3)\n",
    "    d4 = copy.deepcopy(pcds_tsdf[4]).transform(H4)\n",
    "    d5 = copy.deepcopy(pcds_tsdf[5]).transform(H5)\n",
    "    \n",
    "    pcd_combined = o3d.geometry.PointCloud()\n",
    "    pcd_combined = p0+p1+pcds_cropped[2]+p3+p4+p5\n",
    "    \n",
    "    ptsdf_combined = o3d.geometry.PointCloud()\n",
    "    ptsdf_combined = d0+d1+pcds_tsdf[2]+d3+d4+d5\n",
    "\n",
    "    return pcd_combined, ptsdf_combined\n",
    "\n",
    "def process_file(i):\n",
    "    inFile = files[i]\n",
    "    fname = inFile.split('/')[-1]\n",
    "    file_name = fname.split('.mkv')[0]\n",
    "    \n",
    "    reader = o3d.io.AzureKinectMKVReader()\n",
    "    reader.open(inFile)\n",
    "    \n",
    "    if not reader.is_opened():\n",
    "        raise RuntimeError(\"Unable to open file {}\".format(inFile))\n",
    "    \n",
    "    metadata = reader.get_metadata()\n",
    "\n",
    "    # write the metadata to a JSON file since that seems to be the only\n",
    "    # way to retrieve that data\n",
    "    o3d.io.write_azure_kinect_mkv_metadata('{}/{}_intrinsic.json'.format(abspath, file_name), metadata)\n",
    "\n",
    "    # Open the file and load the JSON\n",
    "    with open(abspath + \"/\" + file_name + \"_intrinsic.json\") as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    height = data['height']\n",
    "    width = data['width']\n",
    "    intrinsics = data[\"intrinsic_matrix\"]\n",
    "    time_stamp = data[\"stream_length_usec\"]\n",
    "\n",
    "    camera_intrinsics = o3d.camera.PinholeCameraIntrinsic()\n",
    "    cx = intrinsics[6]\n",
    "    cy = intrinsics[7]\n",
    "    fx = intrinsics[0]\n",
    "    fy = intrinsics[4]\n",
    "    camera_intrinsics.set_intrinsics(width, height, fx, fy, cx, cy)\n",
    "\n",
    "    last_frame = None\n",
    "    while not reader.is_eof():\n",
    "        rgbda = reader.next_frame()\n",
    "        if rgbda is None:\n",
    "            continue\n",
    "        last_frame = rgbda\n",
    "\n",
    "    if last_frame is not None:\n",
    "        return last_frame\n",
    "    else:\n",
    "        print(\"************No valid frames found in the .mkv file.**********\")\n",
    "        return None\n",
    "\n",
    "def upsample_using_reference_normals_new(sparse_pcd, dense_pcd, search_radius=0.02, angle_threshold=30):\n",
    "    # Ensure the point clouds have normals\n",
    "    if not sparse_pcd.has_normals():\n",
    "        sparse_pcd.estimate_normals()\n",
    "    if not dense_pcd.has_normals():\n",
    "        dense_pcd.estimate_normals()\n",
    "\n",
    "    dense_points = np.asarray(dense_pcd.points)\n",
    "    dense_tree = cKDTree(dense_points)\n",
    "\n",
    "    sparse_points = np.asarray(sparse_pcd.points)\n",
    "    sparse_normals = np.asarray(sparse_pcd.normals)\n",
    "    \n",
    "    # This retrieves the indices of all neighbors within the search_radius\n",
    "    neighbor_indices = dense_tree.query_ball_point(sparse_points, search_radius, workers=-1)\n",
    "    \n",
    "    valid_indices = []\n",
    "    for i, idx_row in enumerate(neighbor_indices):\n",
    "        neighbors = dense_points[idx_row]\n",
    "        neighbor_normals = np.asarray(dense_pcd.normals)[idx_row]\n",
    "\n",
    "        # Calculate angles between sparse point's normal and all its neighbors' normals\n",
    "        angles = np.degrees(np.arccos(np.clip(np.dot(sparse_normals[i], neighbor_normals.T), -1.0, 1.0)))\n",
    "\n",
    "        # Filtering neighbors based on angle threshold\n",
    "        valid_neighbor_indices = np.array(idx_row)[angles < angle_threshold]\n",
    "        valid_indices.extend(valid_neighbor_indices)\n",
    "#     valid_indices = []\n",
    "#     for i, idx_row in enumerate(neighbor_indices):\n",
    "#         neighbors = dense_points[idx_row]\n",
    "#         neighbor_normals = np.asarray(dense_pcd.normals)[idx_row]\n",
    "        \n",
    "#         # Calculate angles between sparse point's normal and all its neighbors' normals\n",
    "#         angles = np.degrees(np.arccos(np.clip(np.dot(sparse_normals[i], neighbor_normals.T), -1.0, 1.0)))\n",
    "\n",
    "#         # Filtering neighbors based on angle threshold\n",
    "#         valid_for_current = idx_row[angles < angle_threshold]\n",
    "#         valid_indices.extend(valid_for_current)\n",
    "\n",
    "    unique_valid_indices = np.unique(valid_indices)\n",
    "    final_valid_neighbors = dense_points[unique_valid_indices]\n",
    "    \n",
    "    upsampled_points = np.vstack([sparse_points, final_valid_neighbors])\n",
    "\n",
    "    upsampled_pcd = o3d.geometry.PointCloud()\n",
    "    upsampled_pcd.points = o3d.utility.Vector3dVector(upsampled_points)\n",
    "    upsampled_pcd.estimate_normals()\n",
    "\n",
    "    return upsampled_pcd\n",
    "\n",
    "\n",
    "def load_filter_pcds(data_path, ctform):  # returns a list of  pcds\n",
    "    ws = 2\n",
    "    flying_pixel_filter_threshold = 1000\n",
    "\n",
    "    reader = o3d.io.AzureKinectMKVReader()\n",
    "    abspath = data_path\n",
    "    pcds = []\n",
    "    files_raw = glob.glob(data_path+'/*.mkv')\n",
    "    files = filter_file_names(files_raw)\n",
    "    files.sort()   \n",
    "\n",
    "   \n",
    "    list_size = len(files)\n",
    "    rgbd_frames = [None] * list_size\n",
    "    pcds_tsdf = []\n",
    "    \n",
    "    l1 = time.time()\n",
    "    for i in range(len(files)): # for each view\n",
    "   \n",
    "        inFile = files[i]\n",
    "        fname = inFile.split('/')[-1]\n",
    "        file_name = fname.split('.mkv')[0]\n",
    "        reader.open(inFile)\n",
    "        if not reader.is_opened():\n",
    "            raise RuntimeError(\"Unable to open file {}\".format(inFile))\n",
    "        metadata = reader.get_metadata()\n",
    "  \n",
    "        # write the metadata to a JSON file since that seems to be the only\n",
    "        # way to retrieve that data\n",
    "        o3d.io.write_azure_kinect_mkv_metadata(\n",
    "                    '{}/{}_intrinsic.json'.format(abspath,file_name), metadata)\n",
    "\n",
    "        # Open the file and load the JSON\n",
    "        with open(abspath+\"/\" + file_name + \"_intrinsic.json\") as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        height = data['height']\n",
    "        width = data['width']\n",
    "        intrinsics = data[\"intrinsic_matrix\"]\n",
    "        time_stamp = data[\"stream_length_usec\"]\n",
    "        #print(f\"Intrinsic Matrix {intrinsics}\")\n",
    "\n",
    "        camera_intrinsics = o3d.camera.PinholeCameraIntrinsic()\n",
    "        cx = intrinsics[6]\n",
    "        cy = intrinsics[7]\n",
    "        fx = intrinsics[0]\n",
    "        fy = intrinsics[4]\n",
    "        camera_intrinsics.set_intrinsics(width,height,fx,fy,cx,cy)\n",
    "\n",
    "        last_frame = None\n",
    "        while not reader.is_eof(): # go until hitting eof because of exposure issues in early color frames\n",
    "            rgbda = reader.next_frame();\n",
    "            if rgbda is None:\n",
    "                #print(\"Got nothing! \")\n",
    "                continue\n",
    "            last_frame = rgbda\n",
    "\n",
    "        if last_frame is not None:\n",
    "            #print(\"Got the last frame\")\n",
    "            rgbd_frames[i] = last_frame\n",
    "        else:\n",
    "            \n",
    "            print(\"************No valid frames found in the .mkv file.**********\")\n",
    "    \n",
    "        # filter the depth image for flying pixels\n",
    "        depth_image_array = np.asarray(last_frame.depth)\n",
    "        rgbdc = o3d.geometry.RGBDImage.create_from_color_and_depth(\n",
    "        last_frame.color, last_frame.depth, depth_trunc=4.0, convert_rgb_to_intensity=False)\n",
    "        volume = o3d.pipelines.integration.ScalableTSDFVolume(\n",
    "                    voxel_length= 4.0/ 512.0,\n",
    "                    sdf_trunc=0.4,\n",
    "                    color_type=o3d.pipelines.integration.TSDFVolumeColorType.RGB8)\n",
    "\n",
    "        volume.integrate(\n",
    "            rgbdc, # rgbdc originally - trying with masked_rgbd\n",
    "            camera_intrinsics,\n",
    "            np.eye(4),\n",
    "        )\n",
    "#         pcd_raw = backproject_o3d(last_frame,camera_intrinsics)\n",
    "        pcd_tsdf = volume.extract_point_cloud()\n",
    "        # First eliminate flying pixels before integrating the depth map\n",
    "        result_mask = numba_eliminate_flying_pixels(depth_image_array.copy(), ws, flying_pixel_filter_threshold)\n",
    "        depth_image_array[result_mask > flying_pixel_filter_threshold] = 0\n",
    "        # Re-insert filtered depth into the rgbd image\n",
    "        last_frame.depth = o3d.geometry.Image(depth_image_array)\n",
    "      \n",
    "        # Apply maskrcnn to filtered depth image\n",
    "        masked_rgbd = segment_images_modified(last_frame,i,data_path)\n",
    "        # necessary lol\n",
    "        rgbdc = o3d.geometry.RGBDImage.create_from_color_and_depth(\n",
    "        masked_rgbd.color, masked_rgbd.depth, depth_trunc=4.0, convert_rgb_to_intensity=False)\n",
    "        pcd_tmp = o3d.geometry.PointCloud.create_from_rgbd_image(rgbdc,\n",
    "                                                            camera_intrinsics)\n",
    "      \n",
    "        #print(\"Time was: \", w2-w1, \" s\")\n",
    "        pcds.append(copy.deepcopy(pcd_tmp).transform(np.eye(4)))\n",
    "        pcds_tsdf.append(copy.deepcopy(pcd_tsdf).transform(np.eye(4)))\n",
    "        reader.close()\n",
    "    l2 = time.time()  \n",
    "    print(\"Loading files: \", l2-l1, \" s\")\n",
    "    return pcds,pcds_tsdf\n",
    "\n",
    "\n",
    "def save_results(animal_id, data_path, mesh, pcd_downsampled, sa, v):\n",
    "    # Save the mesh and PCD\n",
    "    mesh_filename = os.path.join(data_path, f\"{animal_id}_mesh.ply\")\n",
    "    pcd_filename = os.path.join(data_path, f\"{animal_id}_pcd_downsampled.ply\")\n",
    "\n",
    "    o3d.io.write_triangle_mesh(mesh_filename, mesh)\n",
    "    \n",
    "    o3d.io.write_point_cloud(pcd_filename, pcd_downsampled)\n",
    "\n",
    "    CSV_PATH = '/home/vigir3d/Datasets/cattle_scans/cow_measurements.csv'\n",
    "    # Check if CSV file exists to decide whether to write headers\n",
    "    write_header = not os.path.exists(CSV_PATH)\n",
    "  # Save SA & V to the CSV file in append mode\n",
    "    with open(CSV_PATH, 'a', newline='') as csvfile:\n",
    "        fieldnames = ['Animal ID', 'SA', 'V']\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        \n",
    "        if write_header:\n",
    "            writer.writeheader()\n",
    "\n",
    "        writer.writerow({'Animal ID': animal_id, 'SA': sa, 'V': v})\n",
    "        \n",
    "def cluster_point_cloud_tensor(pcd) :\n",
    "    colors = pcd.point.colors\n",
    "    with o3d.utility.VerbosityContextManager(\n",
    "            o3d.utility.VerbosityLevel.Error) as cm:\n",
    "        labels = pcd.cluster_dbscan(eps=0.1, min_points=10, print_progress=False)\n",
    "        \n",
    "    \n",
    "    labels = labels.cpu()\n",
    "    # Identify the largest cluster\n",
    "    values, counts = np.unique(labels, return_counts=True)\n",
    "    ind = np.argmax(counts)\n",
    "    largest_cluster_label = values[ind]\n",
    "    #print(f\"Largest cluster label: {largest_cluster_label}\")\n",
    "\n",
    "    colors[labels < 0] = 0\n",
    "    pcd.point.colors = colors\n",
    "    return pcd\n",
    "\n",
    "\n",
    "# Main\n",
    "rgb_model_path = '/home/vigir3d/Datasets/cattle_scans/maskrcnn_data/maskrcnn_v2.pth'\n",
    "depth_model_path = '/home/vigir3d/Datasets/cattle_scans/maskrcnn_data/maskrcnn_depth_best.pth'\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Loads the maskrcnn trained for depth and rgb\n",
    "model_rgb = load_maskrcnn_model(rgb_model_path)\n",
    "model_depth = load_maskrcnn_model(depth_model_path)\n",
    "\n",
    "\n",
    "transform = T.ToTensor()\n",
    "# These two will need to be requested from command line\n",
    "# -i   | input data path\n",
    "# - t  | calibration data path \n",
    "data_path = '/home/vigir3d/Datasets/cattle_scans/Cattle_scan_11_17_22/Animal_1_1'\n",
    "tform_path = '/home/vigir3d/Datasets/cattle_scans/farm_07_24/Animal_calib/'\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Run things\n",
    "    tensor = False\n",
    "    if  tensor :\n",
    "        s = time.time()\n",
    "\n",
    "        l1 = time.time()\n",
    "        tforms = load_calibration(tform_path,5)\n",
    "        pcds, ptsdf = load_filter_pcds(data_path,tforms)\n",
    "        pcd_all, ptsdf_all = perform_pairwise_alignment(ptsdf,pcds)\n",
    "        l2 = time.time()\n",
    "\n",
    "        #place on the GPU\n",
    "        # Tensorize\n",
    "        # get the Device\n",
    "        p1 = time.time()\n",
    "        o3d_device = o3d.core.Device(\"CUDA:0\") \n",
    "        # convert segmented and full clouds to tensor\n",
    "        pcd_t = o3d.t.geometry.PointCloud.from_legacy(pcd_all).to(o3d_device)\n",
    "        #pcd_t_tsdf = o3d.t.geometry.PointCloud.from_legacy(ptsdf_all).to(o3d_device)\n",
    "        pcd_t.estimate_normals()\n",
    "        # Perform clustering to get largest cloud of points from segmented cloud\n",
    "        pcd_clustered = cluster_point_cloud_tensor(pcd_t)\n",
    "        # place on cpu\n",
    "        pcd_clustered_cpu = pcd_clustered.cpu().to_legacy()\n",
    "        p2 = time.time()\n",
    "\n",
    "        u1 = time.time()\n",
    "        # Upsample the single cluster cloud using the full cloud as reference\n",
    "        pcd_upsampled = upsample_using_reference_normals_new(pcd_clustered_cpu, ptsdf_all)\n",
    "        u2 = time.time()\n",
    "\n",
    "        tn1 = time.time()\n",
    "        # Downsample uniformly to ease compute\n",
    "        pcd_downsampled = pcd_upsampled.voxel_down_sample(0.01)\n",
    "        # Correct for the normal orientation problem\n",
    "        pcd_downsampled.orient_normals_consistent_tangent_plane(30)\n",
    "        tn2 = time.time()\n",
    "\n",
    "        m1 = time.time()\n",
    "        with o3d.utility.VerbosityContextManager(o3d.utility.VerbosityLevel.Error) as cm:\n",
    "                 mesh, densities = o3d.geometry.TriangleMesh.create_from_point_cloud_poisson(pcd_downsampled, depth=6)\n",
    "        m2 = time.time()\n",
    "        sa = mesh.get_surface_area()\n",
    "        if(mesh.is_watertight()):\n",
    "            #print(\"Is watertight 1\")\n",
    "            v =  mesh.get_volume()\n",
    "        else : \n",
    "            v = 0.0\n",
    "        animal_id = os.path.basename(os.path.normpath(data_path))\n",
    "        save_results(animal_id, data_path, mesh, pcd_downsampled, sa, v)\n",
    "        e = time.time()\n",
    "\n",
    "        print(\"Total time: \", e-s, \" s\")\n",
    "\n",
    "\n",
    "        print(\"Load and register: \", l2-l1, \" s\")\n",
    "\n",
    "        print(\"Preprocess: \", p2-p1, \" s\")\n",
    "\n",
    "        print(\"Upsampling: \", u2-u1, \" s\")\n",
    "        print(\"Normal orientation: \", tn2-tn1, \" s\")    \n",
    "        print(\"Meshing: \", m2-m1, \" s\")\n",
    "    \n",
    "    elif tensor :\n",
    "        # Run things\n",
    "        s = time.time()\n",
    "\n",
    "        l1 = time.time()\n",
    "        tforms = load_calibration(tform_path,5)\n",
    "        pcds, ptsdf = load_filter_pcds(data_path,tforms)\n",
    "        l2 = time.time()\n",
    "        pcd_all, ptsdf_all = perform_pairwise_alignment(ptsdf,pcds)\n",
    "        r2 = time.time()\n",
    "        \n",
    "        p1 = time.time()\n",
    "        pcd_all.estimate_normals()\n",
    "        # cluster first to remove extra noise\n",
    "        pcd_clustered = cluster_point_cloud_new(pcd_all)\n",
    "        # After clustering, we upsample from the initial\n",
    "        p2 = time.time()\n",
    "\n",
    "        u1 = time.time()\n",
    "        pcd_upsampled = upsample_using_reference_normals_new(pcd_clustered, ptsdf_all)\n",
    "        u2 = time.time()\n",
    "\n",
    "        tn1 = time.time()\n",
    "        pcd_downsampled = pcd_upsampled.voxel_down_sample(0.01)\n",
    "        #pcd_downsampled.orient_normals_towards_camera_location()\n",
    "        pcd_downsampled.orient_normals_consistent_tangent_plane(30)\n",
    "        tn2 = time.time()\n",
    "\n",
    "        m1 = time.time()\n",
    "        with o3d.utility.VerbosityContextManager(o3d.utility.VerbosityLevel.Error) as cm:\n",
    "                mesh, densities = o3d.geometry.TriangleMesh.create_from_point_cloud_poisson(pcd_downsampled, depth=6)\n",
    "\n",
    "        sa = mesh.get_surface_area()\n",
    "        if(mesh.is_watertight()):\n",
    "            #print(\"Is watertight 1\")\n",
    "            v =  mesh.get_volume()\n",
    "        else : \n",
    "            v = 0.0\n",
    "        m2 = time.time()\n",
    "        animal_id = os.path.basename(os.path.normpath(data_path))\n",
    "        save_results(animal_id, data_path, mesh, pcd_downsampled, sa, v)\n",
    "\n",
    "        e = time.time()\n",
    "        print(\"Load files: \", l2-l1, \" s\")\n",
    "        print(\"Register clouds: \", r2-l2, \" s\")\n",
    "\n",
    "        print(\"Remove extra points: \", p2-p1, \" s\")\n",
    "\n",
    "        print(\"Upsampling: \", u2-u1, \" s\")\n",
    "        print(\"Normal orientation: \", tn2-tn1, \" s\")    \n",
    "        print(\"Meshing: \", m2-m1, \" s\")\n",
    "        print(\"Total time: \", e-s, \" s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9c9166f",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "/home/vigir3d/Datasets/cattle_scans/Cattle_11_17_22/Animal_1_1/Animal_1_1_nano_11_intrinsics.txt not found.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 58\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# Generate a list of volumes using list comprehension\u001b[39;00m\n\u001b[1;32m     57\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 58\u001b[0m results \u001b[38;5;241m=\u001b[39m [process_file_list_comp(file_id, dpath) \u001b[38;5;28;01mfor\u001b[39;00m file_id \u001b[38;5;129;01min\u001b[39;00m file_ids]\n\u001b[1;32m     59\u001b[0m ptsdf, pcds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mresults)\n\u001b[1;32m     60\u001b[0m l \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[2], line 58\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# Generate a list of volumes using list comprehension\u001b[39;00m\n\u001b[1;32m     57\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 58\u001b[0m results \u001b[38;5;241m=\u001b[39m [\u001b[43mprocess_file_list_comp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdpath\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m file_id \u001b[38;5;129;01min\u001b[39;00m file_ids]\n\u001b[1;32m     59\u001b[0m ptsdf, pcds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mresults)\n\u001b[1;32m     60\u001b[0m l \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[2], line 21\u001b[0m, in \u001b[0;36mprocess_file_list_comp\u001b[0;34m(file_id, dpath)\u001b[0m\n\u001b[1;32m     18\u001b[0m color \u001b[38;5;241m=\u001b[39m o3d\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mread_image(color_file)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m#depth = o3d.io.read_image(dpath + 'Animal_box3_u_nano_11_depth.png')\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m#color = o3d.io.read_image(dpath + 'Animal_box3_u_nano_11.jpg')\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m K \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloadtxt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mintrinsics_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m camera_intrinsics \u001b[38;5;241m=\u001b[39m o3d\u001b[38;5;241m.\u001b[39mcamera\u001b[38;5;241m.\u001b[39mPinholeCameraIntrinsic()\n\u001b[1;32m     25\u001b[0m camera_intrinsics\u001b[38;5;241m.\u001b[39mset_intrinsics(\u001b[38;5;28mint\u001b[39m(K[\u001b[38;5;241m0\u001b[39m]), \u001b[38;5;28mint\u001b[39m(K[\u001b[38;5;241m1\u001b[39m]), K[\u001b[38;5;241m2\u001b[39m], K[\u001b[38;5;241m3\u001b[39m], K[\u001b[38;5;241m4\u001b[39m], K[\u001b[38;5;241m5\u001b[39m])\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/numpy/lib/npyio.py:1338\u001b[0m, in \u001b[0;36mloadtxt\u001b[0;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin, encoding, max_rows, quotechar, like)\u001b[0m\n\u001b[1;32m   1335\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(delimiter, \u001b[38;5;28mbytes\u001b[39m):\n\u001b[1;32m   1336\u001b[0m     delimiter \u001b[38;5;241m=\u001b[39m delimiter\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlatin1\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m-> 1338\u001b[0m arr \u001b[38;5;241m=\u001b[39m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcomment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcomment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdelimiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdelimiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1339\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconverters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconverters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskiplines\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskiprows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43musecols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43musecols\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1340\u001b[0m \u001b[43m            \u001b[49m\u001b[43munpack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munpack\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mndmin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mndmin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1341\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmax_rows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_rows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquote\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquotechar\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1343\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arr\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/numpy/lib/npyio.py:975\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(fname, delimiter, comment, quote, imaginary_unit, usecols, skiplines, max_rows, converters, ndmin, unpack, dtype, encoding)\u001b[0m\n\u001b[1;32m    973\u001b[0m     fname \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mfspath(fname)\n\u001b[1;32m    974\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fname, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m--> 975\u001b[0m     fh \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_datasource\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    976\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m encoding \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    977\u001b[0m         encoding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(fh, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlatin1\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/numpy/lib/_datasource.py:193\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(path, mode, destpath, encoding, newline)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;124;03mOpen `path` with `mode` and return the file object.\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    189\u001b[0m \n\u001b[1;32m    190\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    192\u001b[0m ds \u001b[38;5;241m=\u001b[39m DataSource(destpath)\n\u001b[0;32m--> 193\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnewline\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/numpy/lib/_datasource.py:533\u001b[0m, in \u001b[0;36mDataSource.open\u001b[0;34m(self, path, mode, encoding, newline)\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _file_openers[ext](found, mode\u001b[38;5;241m=\u001b[39mmode,\n\u001b[1;32m    531\u001b[0m                               encoding\u001b[38;5;241m=\u001b[39mencoding, newline\u001b[38;5;241m=\u001b[39mnewline)\n\u001b[1;32m    532\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 533\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: /home/vigir3d/Datasets/cattle_scans/Cattle_11_17_22/Animal_1_1/Animal_1_1_nano_11_intrinsics.txt not found."
     ]
    }
   ],
   "source": [
    "#dpath = '/home/vigir3d/Datasets/cattle_scans/farm_scan1/Animal_482_2/'\n",
    "def process_file_list_comp(file_id, dpath):\n",
    "    ws = 2\n",
    "    flying_pixel_filter_threshold = 0.1\n",
    "    # Format filenames\n",
    "    dpath = dpath.rstrip('/')\n",
    "\n",
    "    # Split by the directory separator and get the last part\n",
    "    suffix = os.path.basename(dpath)\n",
    "    \n",
    "    file_suffix = suffix + \"_nano_\" + str(file_id)\n",
    "    # Construct full file paths using os.path.join for better cross-platform compatibility\n",
    "    depth_file = os.path.join(dpath, file_suffix + \"_depth.png\")\n",
    "    color_file = os.path.join(dpath, file_suffix + \".jpg\")\n",
    "    intrinsics_file = os.path.join(dpath, file_suffix + \"_intrinsics.txt\")\n",
    "    # Read the files\n",
    "    depth = o3d.io.read_image(depth_file)\n",
    "    color = o3d.io.read_image(color_file)\n",
    "    #depth = o3d.io.read_image(dpath + 'Animal_box3_u_nano_11_depth.png')\n",
    "    #color = o3d.io.read_image(dpath + 'Animal_box3_u_nano_11.jpg')\n",
    "    K = np.loadtxt(intrinsics_file)\n",
    "      \n",
    "\n",
    "    camera_intrinsics = o3d.camera.PinholeCameraIntrinsic()\n",
    "    camera_intrinsics.set_intrinsics(int(K[0]), int(K[1]), K[2], K[3], K[4], K[5])\n",
    "\n",
    "    rgbdc = o3d.geometry.RGBDImage.create_from_color_and_depth(\n",
    "        color, depth, depth_trunc=4.0, convert_rgb_to_intensity=False\n",
    "    )\n",
    "\n",
    "    volume = o3d.pipelines.integration.ScalableTSDFVolume(\n",
    "        voxel_length=4.0 / 512.0, sdf_trunc=0.04, color_type=o3d.pipelines.integration.TSDFVolumeColorType.RGB8\n",
    "    )\n",
    "\n",
    "    volume.integrate(rgbdc, camera_intrinsics, np.eye(4))\n",
    "    pcd_tsdf = volume.extract_point_cloud()\n",
    "    depth_np = np.asarray(rgbdc.depth)\n",
    "    result_mask = numba_eliminate_flying_pixels(depth_np.copy(), ws, flying_pixel_filter_threshold)\n",
    "    depth_np[result_mask > flying_pixel_filter_threshold] = 0\n",
    "    # Re-insert filtered depth into the rgbd image\n",
    "    rgbdc.depth = o3d.geometry.Image(depth_np)\n",
    "    # Apply maskrcnn to filtered depth image\n",
    "    masked_rgbd = segment_images_modified(rgbdc)\n",
    "    # necessary lol\n",
    "    rgbdc_new = o3d.geometry.RGBDImage.create_from_color_and_depth(\n",
    "                    masked_rgbd.color, masked_rgbd.depth, depth_trunc=4.0, convert_rgb_to_intensity=False)\n",
    "    pcd_tmp = o3d.geometry.PointCloud.create_from_rgbd_image(rgbdc_new,\n",
    "                                                        camera_intrinsics)\n",
    "    return pcd_tsdf, pcd_tmp \n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    dpath = '/home/vigir3d/Datasets/cattle_scans/Cattle_11_17_22/Animal_1_1/'\n",
    "    file_ids = [11,12,14,16,17,18]  # exclude head cameras\n",
    "\n",
    "    # Generate a list of volumes using list comprehension\n",
    "    start = time.time()\n",
    "    results = [process_file_list_comp(file_id, dpath) for file_id in file_ids]\n",
    "    ptsdf, pcds = zip(*results)\n",
    "    l = False\n",
    "    if l :\n",
    "        pcd_all, ptsdf_all = perform_pairwise_alignment(ptsdf,pcds)\n",
    "        pcd_all.estimate_normals()\n",
    "        pcd_clustered = cluster_point_cloud_new(pcd_all)\n",
    "        pcd_upsampled = upsample_using_reference_normals_new(pcd_clustered, ptsdf_all)\n",
    "        pcd_downsampled = pcd_upsampled.voxel_down_sample(0.01)\n",
    "        pcd_downsampled.orient_normals_consistent_tangent_plane(30)\n",
    "        with o3d.utility.VerbosityContextManager(o3d.utility.VerbosityLevel.Error) as cm:\n",
    "            mesh, densities = o3d.geometry.TriangleMesh.create_from_point_cloud_poisson(pcd_downsampled, depth=6)\n",
    "\n",
    "        sa = mesh.get_surface_area()\n",
    "        if(mesh.is_watertight()):\n",
    "            #print(\"Is watertight 1\")\n",
    "            v =  mesh.get_volume()\n",
    "        else : \n",
    "            v = 0.0\n",
    "        animal_id = os.path.basename(os.path.normpath(data_path))\n",
    "        #save_results(animal_id, data_path, mesh, pcd_downsampled, sa, v)\n",
    "\n",
    "\n",
    "    end = time.time()\n",
    "\n",
    "    print(\"Duration was:\", end-start, \"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e1f856",
   "metadata": {},
   "outputs": [],
   "source": [
    "dpath = '/home/vigir3d/Datasets/cattle_scans/Cattle_11_17_22/Animal_1_1/'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
