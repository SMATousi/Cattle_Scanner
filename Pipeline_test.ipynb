{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48b44582",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-09-14 15:36:23.756] [error] [t=15170] /__w/1/s/extern/Azure-Kinect-Sensor-SDK/src/../include/k4ainternal/matroska_read.h (143): k4a_playback_t_get_context(). Invalid k4a_playback_t 0xa4b3cc80\n",
      "[2023-09-14 15:36:23.756] [error] [t=15170] /__w/1/s/extern/Azure-Kinect-Sensor-SDK/src/record/sdk/playback.cpp (658): Invalid argument to k4a_playback_close(). playback_handle (0xa4b3cc80) is not a valid handle of type k4a_playback_t\n",
      "[2023-09-14 15:36:28.627] [error] [t=15170] /__w/1/s/extern/Azure-Kinect-Sensor-SDK/src/../include/k4ainternal/matroska_read.h (143): k4a_playback_t_get_context(). Invalid k4a_playback_t 0xc1a9aa0\n",
      "[2023-09-14 15:36:28.627] [error] [t=15170] /__w/1/s/extern/Azure-Kinect-Sensor-SDK/src/record/sdk/playback.cpp (658): Invalid argument to k4a_playback_close(). playback_handle (0xc1a9aa0) is not a valid handle of type k4a_playback_t\n",
      "[2023-09-14 15:36:33.435] [error] [t=15170] /__w/1/s/extern/Azure-Kinect-Sensor-SDK/src/../include/k4ainternal/matroska_read.h (143): k4a_playback_t_get_context(). Invalid k4a_playback_t 0xc1a9aa0\n",
      "[2023-09-14 15:36:33.435] [error] [t=15170] /__w/1/s/extern/Azure-Kinect-Sensor-SDK/src/record/sdk/playback.cpp (658): Invalid argument to k4a_playback_close(). playback_handle (0xc1a9aa0) is not a valid handle of type k4a_playback_t\n",
      "[2023-09-14 15:36:38.302] [error] [t=15170] /__w/1/s/extern/Azure-Kinect-Sensor-SDK/src/../include/k4ainternal/matroska_read.h (143): k4a_playback_t_get_context(). Invalid k4a_playback_t 0xc1a9aa0\n",
      "[2023-09-14 15:36:38.302] [error] [t=15170] /__w/1/s/extern/Azure-Kinect-Sensor-SDK/src/record/sdk/playback.cpp (658): Invalid argument to k4a_playback_close(). playback_handle (0xc1a9aa0) is not a valid handle of type k4a_playback_t\n",
      "[2023-09-14 15:36:43.096] [error] [t=15170] /__w/1/s/extern/Azure-Kinect-Sensor-SDK/src/../include/k4ainternal/matroska_read.h (143): k4a_playback_t_get_context(). Invalid k4a_playback_t 0xc1a9aa0\n",
      "[2023-09-14 15:36:43.096] [error] [t=15170] /__w/1/s/extern/Azure-Kinect-Sensor-SDK/src/record/sdk/playback.cpp (658): Invalid argument to k4a_playback_close(). playback_handle (0xc1a9aa0) is not a valid handle of type k4a_playback_t\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "\u001b[1;31m[Open3D Error] (virtual Eigen::Matrix4d open3d::pipelines::registration::TransformationEstimationForColoredICP::ComputeTransformation(const open3d::geometry::PointCloud&, const open3d::geometry::PointCloud&, const CorrespondenceSet&) const) /root/Open3D/cpp/open3d/pipelines/registration/ColoredICP.cpp:104: No correspondences found between source and target pointcloud.\n\u001b[0;m",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 350\u001b[0m\n\u001b[1;32m    348\u001b[0m d \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/vigir3d/Datasets/cattle_scans/FirstOne/\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    349\u001b[0m t \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/vigir3d/Datasets/cattle_scans/farm_scan1/Animal_482_1/\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 350\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43md\u001b[49m\u001b[43m,\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[38;5;66;03m#pcds_all = load_filter_pcds(d, t)\u001b[39;00m\n\u001b[1;32m    352\u001b[0m o3d\u001b[38;5;241m.\u001b[39mvisualization\u001b[38;5;241m.\u001b[39mdraw_geometries(pcds_all)\n",
      "Cell \u001b[0;32mIn[5], line 325\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(data_path, tform_path)\u001b[0m\n\u001b[1;32m    322\u001b[0m pcds_all \u001b[38;5;241m=\u001b[39m load_filter_pcds(data_path, Tforms)\n\u001b[1;32m    323\u001b[0m o3d\u001b[38;5;241m.\u001b[39mvisualization\u001b[38;5;241m.\u001b[39mdraw_geometries(pcds_all)\n\u001b[0;32m--> 325\u001b[0m p0, p1, p3, p4, p5 \u001b[38;5;241m=\u001b[39m \u001b[43mapply_transformations\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpcds_all\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;66;03m# Combine point clouds\u001b[39;00m\n\u001b[1;32m    328\u001b[0m pcds \u001b[38;5;241m=\u001b[39m o3d\u001b[38;5;241m.\u001b[39mgeometry\u001b[38;5;241m.\u001b[39mPointCloud()\n",
      "Cell \u001b[0;32mIn[5], line 296\u001b[0m, in \u001b[0;36mapply_transformations\u001b[0;34m(pcds_all)\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_transformations\u001b[39m(pcds_all):\n\u001b[1;32m    295\u001b[0m     \u001b[38;5;124;03m\"\"\"Compute and apply transformations.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 296\u001b[0m     t01 \u001b[38;5;241m=\u001b[39m \u001b[43mcolored_ICP\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpcds_all\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpcds_all\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    297\u001b[0m     t52 \u001b[38;5;241m=\u001b[39m colored_ICP(pcds_all[\u001b[38;5;241m5\u001b[39m], pcds_all[\u001b[38;5;241m2\u001b[39m])\n\u001b[1;32m    298\u001b[0m     t43 \u001b[38;5;241m=\u001b[39m colored_ICP(pcds_all[\u001b[38;5;241m4\u001b[39m], pcds_all[\u001b[38;5;241m3\u001b[39m])\n",
      "Cell \u001b[0;32mIn[5], line 56\u001b[0m, in \u001b[0;36mcolored_ICP\u001b[0;34m(source, target)\u001b[0m\n\u001b[1;32m     52\u001b[0m target_down\u001b[38;5;241m.\u001b[39mestimate_normals(\n\u001b[1;32m     53\u001b[0m     o3d\u001b[38;5;241m.\u001b[39mgeometry\u001b[38;5;241m.\u001b[39mKDTreeSearchParamHybrid(radius\u001b[38;5;241m=\u001b[39mradius \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m, max_nn\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m))\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m#print(\"3-3. Applying colored point cloud registration\")\u001b[39;00m\n\u001b[0;32m---> 56\u001b[0m result_icp \u001b[38;5;241m=\u001b[39m \u001b[43mo3d\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpipelines\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mregistration\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mregistration_colored_icp\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m    \u001b[49m\u001b[43msource_down\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_down\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mradius\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcurrent_transformation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m    \u001b[49m\u001b[43mo3d\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpipelines\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mregistration\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTransformationEstimationForColoredICP\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m    \u001b[49m\u001b[43mo3d\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpipelines\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mregistration\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mICPConvergenceCriteria\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrelative_fitness\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-6\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m                                                      \u001b[49m\u001b[43mrelative_rmse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-6\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m                                                      \u001b[49m\u001b[43mmax_iteration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43miters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m current_transformation \u001b[38;5;241m=\u001b[39m result_icp\u001b[38;5;241m.\u001b[39mtransformation\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m current_transformation\n",
      "\u001b[0;31mRuntimeError\u001b[0m: \u001b[1;31m[Open3D Error] (virtual Eigen::Matrix4d open3d::pipelines::registration::TransformationEstimationForColoredICP::ComputeTransformation(const open3d::geometry::PointCloud&, const open3d::geometry::PointCloud&, const CorrespondenceSet&) const) /root/Open3D/cpp/open3d/pipelines/registration/ColoredICP.cpp:104: No correspondences found between source and target pointcloud.\n\u001b[0;m"
     ]
    }
   ],
   "source": [
    "import open3d as o3d\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import json\n",
    "import glob\n",
    "from PIL import Image\n",
    "import torchvision\n",
    "import torch\n",
    "from torchvision import transforms as T \n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n",
    "import time\n",
    "from numba import jit, prange\n",
    "import copy\n",
    "\n",
    "import argparse\n",
    "\n",
    "# Load MaskRCNN \n",
    "\n",
    "def load_maskrcnn_model(model_path):\n",
    "    model = torchvision.models.detection.maskrcnn_resnet50_fpn(weights=\"DEFAULT\")\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, 2)\n",
    "    in_features_mask = model.roi_heads.mask_predictor.conv5_mask.in_channels\n",
    "    hidden_layer = 256\n",
    "    model.roi_heads.mask_predictor = MaskRCNNPredictor(in_features_mask, hidden_layer, 2)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model.eval()\n",
    "\n",
    "    return model\n",
    "\n",
    "def colored_ICP(source, target):\n",
    "    \n",
    "    voxel_radius = [0.04, 0.02, 0.01]\n",
    "    max_iter = [50, 30, 14]\n",
    "    current_transformation = np.identity(4)\n",
    "    #print(\"3. Colored point cloud registration\")\n",
    "    for scale in range(3):\n",
    "        iters = max_iter[scale]\n",
    "        radius = voxel_radius[scale]\n",
    "        #print(\"iteration: \", iters, radius, scale)\n",
    "\n",
    "        #print(\"3-1. Downsample with a voxel size %.2f\" % radius)\n",
    "        source_down = source.voxel_down_sample(radius)\n",
    "        target_down = target.voxel_down_sample(radius)\n",
    "\n",
    "        #print(\"3-2. Estimate normal.\")\n",
    "        source_down.estimate_normals(\n",
    "            o3d.geometry.KDTreeSearchParamHybrid(radius=radius * 2, max_nn=30))\n",
    "        target_down.estimate_normals(\n",
    "            o3d.geometry.KDTreeSearchParamHybrid(radius=radius * 2, max_nn=30))\n",
    "\n",
    "        #print(\"3-3. Applying colored point cloud registration\")\n",
    "        result_icp = o3d.pipelines.registration.registration_colored_icp(\n",
    "            source_down, target_down, radius, current_transformation,\n",
    "            o3d.pipelines.registration.TransformationEstimationForColoredICP(),\n",
    "            o3d.pipelines.registration.ICPConvergenceCriteria(relative_fitness=1e-6,\n",
    "                                                              relative_rmse=1e-6,\n",
    "                                                              max_iteration=iters))\n",
    "        current_transformation = result_icp.transformation\n",
    "        return current_transformation\n",
    "    \n",
    "\n",
    "def get_model_mask(model_generic, image):\n",
    "    proba_threshold = 0.5\n",
    "    ig = transform(image)\n",
    "    with torch.no_grad():\n",
    "        prediction = model_generic([ig.to(device)])\n",
    "        \n",
    "    if(prediction[0]['masks'].nelement() == 0):\n",
    "        XX = torch.empty((0,0), dtype=torch.int64)\n",
    "        return XX\n",
    "    predicted_mask = prediction[0]\n",
    "    predicted_mask = predicted_mask['masks'][0] > proba_threshold\n",
    "    \n",
    "    predicted_mask = predicted_mask.squeeze(1)\n",
    "    mask = predicted_mask.cpu().detach()\n",
    "    return mask\n",
    "\n",
    "def segment_images(last_frame,fctr,path):\n",
    "    depth_PIL = Image.fromarray(np.asarray(last_frame.depth)).convert(\"RGB\")\n",
    "    rgb_image_array = np.asarray(last_frame.color)\n",
    "    depth_image_array = np.asarray(last_frame.depth)\n",
    "    rgb_PIL = Image.fromarray(rgb_image_array)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    rgb_mask = get_model_mask(model_rgb, rgb_PIL)\n",
    "    depth_mask = get_model_mask(model_depth, depth_PIL)\n",
    "\n",
    "    if depth_mask.nelement() == 0:\n",
    "        mask_combined = rgb_mask\n",
    "    else:\n",
    "        mask_combined = depth_mask | rgb_mask  # 1 vote arbitration (OR the masks)\n",
    "\n",
    "    # Convert tensor to numpy array and ensure the right datatype\n",
    "    mask_combined = mask_combined.numpy().astype(rgb_image_array.dtype)\n",
    "    mask_image = mask_combined.swapaxes(0, 2).swapaxes(0, 1)\n",
    "    mask_image = (mask_image > 0).astype(rgb_image_array.dtype)   \n",
    "\n",
    "    fg_image_rgb = rgb_image_array * mask_image\n",
    "\n",
    "    # For the depth image:\n",
    "    squeezed_mask = np.squeeze(mask_image)\n",
    "    fg_image_depth = depth_image_array * squeezed_mask\n",
    "    \n",
    "    last_frame.color = o3d.geometry.Image(fg_image_rgb)\n",
    "    last_frame.depth = o3d.geometry.Image(fg_image_depth)\n",
    "     # Take this out!!\n",
    "    o3d.io.write_image(path+\"color_\"+str(fctr)+\".jpg\",last_frame.color)\n",
    "    o3d.io.write_image(path+\"depth_\"+str(fctr)+\".png\",last_frame.depth)\n",
    "\n",
    "    return last_frame\n",
    "\n",
    "\n",
    "\n",
    "def eliminate_flying_pixels(depth_image, ws, threshold):\n",
    "   \n",
    "    # Get image size\n",
    "    height, width = depth_image.shape\n",
    "    # Create an empty array for the result\n",
    "    result = np.zeros_like(depth_image, dtype=float)\n",
    "\n",
    "    # Iterate over the entire image\n",
    "    for cy in range(height):\n",
    "        for cx in range(width):\n",
    "            # Set the range for the window\n",
    "            x_start, x_end = max(0, cx - ws), min(width, cx + ws + 1)\n",
    "            y_start, y_end = max(0, cy - ws), min(height, cy + ws + 1)\n",
    "            \n",
    "            # Get the window\n",
    "            window = depth_image[y_start:y_end, x_start:x_end]\n",
    "\n",
    "            # Calculate the sum of absolute differences\n",
    "            result[cy, cx] = np.sum(np.abs(window - depth_image[cy, cx]))\n",
    "    count = np.sum(result > threshold)\n",
    "\n",
    "    depth_image[result > threshold] = 0\n",
    "    return  depth_image\n",
    "\n",
    "def filter_file_names(file_list): # to avoid the two head cameras\n",
    "    new_file_list = []\n",
    "    for f in file_list:\n",
    "        tmp = f.split('.mkv')[0]\n",
    "        ID  = tmp.split('_')[-1]\n",
    "        if (ID == \"13\" or ID == \"15\"):\n",
    "            continue\n",
    "        else :\n",
    "            new_file_list.append(f)\n",
    "    return new_file_list\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def load_filter_pcds(data_path,Tforms):  # returns a list of  pcds\n",
    "    ws = 2\n",
    "    flying_pixel_filter_threshold = 100\n",
    "\n",
    "    reader = o3d.io.AzureKinectMKVReader()\n",
    "    abspath = data_path\n",
    "    pcds = []    \n",
    "        \n",
    "    files = glob.glob(data_path+'/*.mkv')\n",
    "    #files = filter_file_names(files_raw)\n",
    "    files.sort()\n",
    "    list_size = len(files)\n",
    "    rgbd_frames = [None] * list_size\n",
    "  \n",
    "    for i in range(len(files)): # for each view\n",
    "   \n",
    "        inFile = files[i]\n",
    "        fname = inFile.split('/')[-1]\n",
    "        file_name = fname.split('.mkv')[0]\n",
    "        reader.open(inFile)\n",
    "        if not reader.is_opened():\n",
    "            raise RuntimeError(\"Unable to open file {}\".format(inFile))\n",
    "        metadata = reader.get_metadata()\n",
    "  \n",
    "        # write the metadata to a JSON file since that seems to be the only\n",
    "        # way to retrieve that data\n",
    "        o3d.io.write_azure_kinect_mkv_metadata(\n",
    "                    '{}/{}_intrinsic.json'.format(abspath,file_name), metadata)\n",
    "\n",
    "        # Open the file and load the JSON\n",
    "        with open(abspath+\"/\" + file_name + \"_intrinsic.json\") as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        height = data['height']\n",
    "        width = data['width']\n",
    "        intrinsics = data[\"intrinsic_matrix\"]\n",
    "        #time_stamp = data[\"stream_length_usec\"]\n",
    "        #print(f\"Intrinsic Matrix {intrinsics}\")\n",
    "\n",
    "        camera_intrinsics = o3d.camera.PinholeCameraIntrinsic()\n",
    "        cx = intrinsics[6]\n",
    "        cy = intrinsics[7]\n",
    "        fx = intrinsics[0]\n",
    "        fy = intrinsics[4]\n",
    "        camera_intrinsics.set_intrinsics(width,height,fx,fy,cx,cy)\n",
    "            \n",
    "        last_frame = None\n",
    "        while not reader.is_eof(): # go until hitting eof because of exposure issues in early color frames\n",
    "            rgbda = reader.next_frame()\n",
    "            if rgbda is None:\n",
    "                #print(\"Got nothing! \")\n",
    "                continue\n",
    "            last_frame = rgbda\n",
    "\n",
    "        if last_frame is not None:\n",
    "            #print(\"Got the last frame\")\n",
    "            rgbd_frames[i] = last_frame\n",
    "        else:\n",
    "            \n",
    "            print(\"************No valid frames found in the .mkv file.**********\")\n",
    "    \n",
    "        # filter the depth image for flying pixels\n",
    "        \n",
    "        depth_image_array = np.asarray(last_frame.depth)\n",
    "        result_mask = numba_eliminate_flying_pixels(depth_image_array.copy(), ws, flying_pixel_filter_threshold)\n",
    "        depth_image_array[result_mask > flying_pixel_filter_threshold] = 0\n",
    "        # Re-insert filtered depth into the rgbd image\n",
    "        last_frame.depth = o3d.geometry.Image(depth_image_array)\n",
    "      \n",
    "        # Apply maskrcnn to filtered depth image\n",
    "        masked_rgbd = segment_images(last_frame,i,data_path)\n",
    "        rgbdc = o3d.geometry.RGBDImage.create_from_color_and_depth(\n",
    "        masked_rgbd.color, masked_rgbd.depth, depth_trunc=4.0, convert_rgb_to_intensity=False)\n",
    "        pcd = o3d.geometry.PointCloud.create_from_rgbd_image(rgbdc,\n",
    "                                                            camera_intrinsics) \n",
    "        \n",
    "        pcds.append(copy.deepcopy(pcd).transform(Tforms[i]))\n",
    "        reader.close()\n",
    "        \n",
    "    return pcds\n",
    "\n",
    "def backproject_o3d(rgbd_frame, intrinsics):\n",
    "    \n",
    "    rgbdc = o3d.geometry.RGBDImage.create_from_color_and_depth(\n",
    "        rgbd_frame.color, rgbd_frame.depth, depth_trunc=4.0, convert_rgb_to_intensity=False)\n",
    "\n",
    "\n",
    "    # Create a point cloud from the RGBD image\n",
    "    pcd = o3d.geometry.PointCloud.create_from_rgbd_image(rgbdc, intrinsics)\n",
    "    n_radius = 0.01*2.0\n",
    "    pcd.estimate_normals(\n",
    "    search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=n_radius, max_nn=30))\n",
    "    # Visualize the point cloud\n",
    "    #o3d.visualization.draw_geometries([pcd])\n",
    "    \n",
    "    return pcd\n",
    "\n",
    "\n",
    "@jit(nopython=True, parallel=True)\n",
    "def numba_eliminate_flying_pixels(depth_image, ws, threshold):\n",
    "    height, width = depth_image.shape\n",
    "    result = np.zeros_like(depth_image, dtype=np.float64)\n",
    "    \n",
    "    for cy in prange(height):\n",
    "        for cx in prange(width):\n",
    "            x_start, x_end = max(0, cx - ws), min(width, cx + ws + 1)\n",
    "            y_start, y_end = max(0, cy - ws), min(height, cy + ws + 1)\n",
    "            window = depth_image[y_start:y_end, x_start:x_end]\n",
    "            result[cy, cx] = np.sum(np.abs(window - depth_image[cy, cx]))\n",
    "    \n",
    "    #for i in prange(height):\n",
    "       # for j in prange(width):\n",
    "      #      if result[i, j] > threshold:\n",
    "     #           depth_image[i, j] = 0\n",
    "    #count = np.sum(result > threshold)\n",
    "    #print(\"Numba detected: #\", count)\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "# Main\n",
    "rgb_model_path = '/home/vigir3d/Datasets/cattle_scans/maskrcnn_data/maskrcnn_v2.pth'\n",
    "depth_model_path = '/home/vigir3d/Datasets/cattle_scans/maskrcnn_data/maskrcnn_depth_best.pth'\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Loads the maskrcnn trained for depth and rgb\n",
    "model_rgb = load_maskrcnn_model(rgb_model_path)\n",
    "model_depth = load_maskrcnn_model(depth_model_path)\n",
    "\n",
    "transform = T.ToTensor()\n",
    "def load_transformations(tform_path):\n",
    "    \"\"\"Load transformations from the given path.\"\"\"\n",
    "    htm_files = [\"htm_0_3.txt\", \"htm_1_3.txt\", \"htm_5_3.txt\", \"htm_6_3.txt\", \"htm_7_3.txt\"]\n",
    "    transformations = [np.loadtxt(tform_path + file) for file in htm_files]\n",
    "    transformations.insert(2, np.eye(4))\n",
    "    return transformations\n",
    "\n",
    "def apply_transformations(pcds_all):\n",
    "    \"\"\"Compute and apply transformations.\"\"\"\n",
    "    t01 = colored_ICP(pcds_all[0], pcds_all[1])\n",
    "    t52 = colored_ICP(pcds_all[5], pcds_all[2])\n",
    "    t43 = colored_ICP(pcds_all[4], pcds_all[3])\n",
    "    t12 = colored_ICP(pcds_all[1], pcds_all[2])\n",
    "    t32 = colored_ICP(pcds_all[3], pcds_all[2])\n",
    "\n",
    "    H0 = t12 @ t01\n",
    "    H1 = t12\n",
    "    H3 = t32\n",
    "    H4 = t32 @ t43\n",
    "    H5 = t52\n",
    "\n",
    "    # Transform the point clouds\n",
    "    p0 = copy.deepcopy(pcds_all[0]).transform(H0)\n",
    "    p1 = copy.deepcopy(pcds_all[1]).transform(H1)\n",
    "    p3 = copy.deepcopy(pcds_all[3]).transform(H3)\n",
    "    p4 = copy.deepcopy(pcds_all[4]).transform(H4)\n",
    "    p5 = copy.deepcopy(pcds_all[5]).transform(H5)\n",
    "\n",
    "    return p0, p1, p3, p4, p5\n",
    "\n",
    "def main(data_path, tform_path):\n",
    "    Tforms = load_transformations(tform_path)\n",
    "\n",
    "    o3d.utility.set_verbosity_level(o3d.utility.VerbosityLevel.Error)\n",
    "    start_time = time.time()\n",
    "    pcds_all = load_filter_pcds(data_path, Tforms)\n",
    "    o3d.visualization.draw_geometries(pcds_all)\n",
    "    \n",
    "    p0, p1, p3, p4, p5 = apply_transformations(pcds_all)\n",
    "\n",
    "    # Combine point clouds\n",
    "    pcds = o3d.geometry.PointCloud()\n",
    "    pcds = p0 + p1 + pcds_all[2] + p3 + p4 + p5\n",
    "    o3d.io.write_point_cloud(data_path+\"\")\n",
    "\n",
    "    # Mesh reconstruction\n",
    "    with o3d.utility.VerbosityContextManager(o3d.utility.VerbosityLevel.Error) as cm:\n",
    "        mesh, densities = o3d.geometry.TriangleMesh.create_from_point_cloud_poisson(pcds, depth=9)\n",
    "    sa = mesh.get_surface_area()\n",
    "    \n",
    "    end_time = time.time()\n",
    "    execution_time = end_time - start_time\n",
    "    print(f\"It took {execution_time:.2f}s to reconstruct mesh.\")\n",
    "    print(\"Surface area is:\", sa)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    #parser = argparse.ArgumentParser(description=\"Process and reconstruct mesh from data.\")\n",
    "    #parser.add_argument(\"-i\", \"--input\", required=True, help=\"Path to the data.\")\n",
    "    #parser.add_argument(\"-t\", \"--transform\", required=True, help=\"Path to the transformations.\")\n",
    "    #args = parser.parse_args()\n",
    "    #d = '/home/vigir3d/Datasets/cattle_scans/farm_scan1/Animal_482_2/'\n",
    "    d = '/home/vigir3d/Datasets/cattle_scans/FirstOne/'\n",
    "    t = '/home/vigir3d/Datasets/cattle_scans/farm_scan1/Animal_482_1/'\n",
    "    main(d,t)\n",
    "    #pcds_all = load_filter_pcds(d, t)\n",
    "    o3d.visualization.draw_geometries(pcds_all)\n",
    "\n",
    "# data_path = '/home/vigir3d/Datasets/cattle_scans/farm_scan1/Animal_482_2/'\n",
    "\n",
    "# tform_path = '/home/vigir3d/Datasets/cattle_scans/farm_scan1/Animal_482_1/'\n",
    "# h0 = np.loadtxt(tform_path+\"htm_0_3.txt\")\n",
    "# h1 = np.loadtxt(tform_path+\"htm_1_3.txt\")\n",
    "# h5 = np.loadtxt(tform_path+\"htm_5_3.txt\")\n",
    "# h6 = np.loadtxt(tform_path+\"htm_6_3.txt\")\n",
    "# h7 = np.loadtxt(tform_path+\"htm_7_3.txt\")\n",
    "\n",
    "# Tforms = [h0,h1,h5,h6,h7]\n",
    "\n",
    "\n",
    "# o3d.utility.set_verbosity_level(o3d.utility.VerbosityLevel.Error)\n",
    "# start_time = time.time()\n",
    "# pcds_all = load_filter_pcds(data_path,Tforms);\n",
    "# t01= colored_ICP(pcds_all[0],pcds_all[1])\n",
    "# t52= colored_ICP(pcds_all[5],pcds_all[2])\n",
    "# t43= colored_ICP(pcds_all[4],pcds_all[3])\n",
    "# t12= colored_ICP(pcds_all[1],pcds_all[2])\n",
    "# t32= colored_ICP(pcds_all[3],pcds_all[2])\n",
    "\n",
    "\n",
    "# H0 = t12 @ t01\n",
    "# H1 = t12\n",
    "# H3 = t32\n",
    "# H4 = t32 @ t43\n",
    "# H5 = t52\n",
    "\n",
    "\n",
    "# # np.savetxt(\"c_icp_0_2.txt\", H0)\n",
    "# # np.savetxt(\"c_icp_1_2.txt\", H1)\n",
    "# # np.savetxt(\"c_icp_3_2.txt\", H3)\n",
    "# # np.savetxt(\"c_icp_4_2.txt\", H4)\n",
    "# # np.savetxt(\"c_icp_5_2.txt\", H5)\n",
    "\n",
    "# p0 = copy.deepcopy(pcds_all[0]).transform(H0)\n",
    "# p1 = copy.deepcopy(pcds_all[1]).transform(H1)\n",
    "# p3 = copy.deepcopy(pcds_all[3]).transform(H3)\n",
    "# p4 = copy.deepcopy(pcds_all[4]).transform(H4)\n",
    "# p5 = copy.deepcopy(pcds_all[5]).transform(H5)\n",
    "# #end_time = time.time()\n",
    "# #execution_time = end_time - start_time\n",
    "# #print(\"It took :\", execution_time, \"s to process all frames\")\n",
    "\n",
    "# # combine pcds\n",
    "\n",
    "# #print('run Poisson surface reconstruction')\n",
    "\n",
    "# pcds = o3d.geometry.PointCloud()\n",
    "# pcds = p0+p1+pcds_all[2]+p3+p4+p5\n",
    "# #pcds = pcds_all[0]+pcds_all[1]+pcds_all[2]+pcds_all[3]+pcds_all[4]+pcds_all[5]\n",
    "# with o3d.utility.VerbosityContextManager(\n",
    "#         o3d.utility.VerbosityLevel.Error) as cm:\n",
    "#     mesh, densities = o3d.geometry.TriangleMesh.create_from_point_cloud_poisson(\n",
    "#         pcds, depth=9)\n",
    "# sa = mesh.get_surface_area()\n",
    "# end_time = time.time()\n",
    "# execution_time = end_time - start_time\n",
    "# print(\"It took :\", execution_time, \"s to reconstruct mesh\")\n",
    "# print(sa)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33dbd087",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96dc209f",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = '/home/vigir3d/Datasets/cattle_scans/farm_scan1/Animal_482_2/'\n",
    "\n",
    "t = '/home/vigir3d/Datasets/cattle_scans/farm_scan1/Animal_482_1/'\n",
    "#main(d,t)\n",
    "pcds_all = load_filter_pcds(d, t)\n",
    "o3d.visualization.draw_geometries(pcds_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff7effd",
   "metadata": {},
   "source": [
    "# Current Pipeline Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fffec608",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "import json\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import teaserpp_python\n",
    "from numpy.linalg import inv\n",
    "from scipy.spatial import cKDTree\n",
    "import time\n",
    "from PIL import Image\n",
    "import torchvision\n",
    "import torch\n",
    "from torchvision import transforms as T \n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n",
    "from numba import jit, prange\n",
    "import os\n",
    "import csv \n",
    "# Load MaskRCNN \n",
    "\n",
    "from multiprocessing import Pool\n",
    "\n",
    "def pad_depth_to_color(depth, color):\n",
    "    # Calculate differences in dimensions\n",
    "    height_diff = color.shape[0] - depth.shape[0]\n",
    "    width_diff = color.shape[1] - depth.shape[1]\n",
    "    \n",
    "    # Compute padding values for height and width\n",
    "    pad_top = height_diff // 2\n",
    "    pad_bottom = height_diff - pad_top\n",
    "    pad_left = width_diff // 2\n",
    "    pad_right = width_diff - pad_left\n",
    "    \n",
    "    # Apply padding\n",
    "    padded_depth = np.pad(depth, ((pad_top, pad_bottom), (pad_left, pad_right)), mode='constant', constant_values=0)\n",
    "    \n",
    "    return padded_depth\n",
    "\n",
    "def load_maskrcnn_model(model_path):\n",
    "    model = torchvision.models.detection.maskrcnn_resnet50_fpn(weights=\"DEFAULT\")\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, 2)\n",
    "    in_features_mask = model.roi_heads.mask_predictor.conv5_mask.in_channels\n",
    "    hidden_layer = 256\n",
    "    model.roi_heads.mask_predictor = MaskRCNNPredictor(in_features_mask, hidden_layer, 2)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model.eval()\n",
    "\n",
    "    return model\n",
    "\n",
    "def get_model_mask(model_generic, image):\n",
    "    proba_threshold = 0.5\n",
    "    ig = transform(image)\n",
    "    with torch.no_grad():\n",
    "        prediction = model_generic([ig.to(device)])\n",
    "        \n",
    "    if(prediction[0]['masks'].nelement() == 0):\n",
    "        XX = torch.empty((0,0), dtype=torch.int64)\n",
    "        return XX\n",
    "    predicted_mask = prediction[0]\n",
    "    predicted_mask = predicted_mask['masks'][0] > proba_threshold\n",
    "    \n",
    "    predicted_mask = predicted_mask.squeeze(1)\n",
    "    mask = predicted_mask.cpu().detach()\n",
    "    return mask\n",
    "\n",
    "\n",
    "def segment_images_modified(last_frame):\n",
    "    depth_PIL = Image.fromarray(np.asarray(last_frame.depth)).convert(\"RGB\")\n",
    "    rgb_image_array = np.asarray(last_frame.color)\n",
    "    depth_image_array = np.asarray(last_frame.depth)\n",
    "    rgb_PIL = Image.fromarray(rgb_image_array)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    rgb_mask = get_model_mask(model_rgb, rgb_PIL)\n",
    "    depth_mask = get_model_mask(model_depth, depth_PIL)\n",
    "\n",
    "    if depth_mask.nelement() == 0:\n",
    "        mask_combined = rgb_mask\n",
    "    else:\n",
    "        mask_combined = depth_mask | rgb_mask  # 1 vote arbitration (OR the masks)\n",
    "\n",
    "    # Convert tensor to numpy array and ensure the right datatype\n",
    "    mask_combined = mask_combined.numpy().astype(rgb_image_array.dtype)\n",
    "    mask_image = mask_combined.swapaxes(0, 2).swapaxes(0, 1)\n",
    "    mask_image = (mask_image > 0).astype(rgb_image_array.dtype)   \n",
    "\n",
    "    fg_image_rgb = rgb_image_array * mask_image\n",
    "\n",
    "    # For the depth image:\n",
    "    squeezed_mask = np.squeeze(mask_image)\n",
    "    fg_image_depth = depth_image_array * squeezed_mask\n",
    "    \n",
    "    \n",
    "    last_frame.color = o3d.geometry.Image(fg_image_rgb)\n",
    "    last_frame.depth = o3d.geometry.Image(fg_image_depth)\n",
    "   \n",
    "\n",
    "\n",
    "    return last_frame\n",
    "\n",
    "\n",
    "def filter_file_names(file_list): # to avoid the two head cameras\n",
    "    new_file_list = []\n",
    "    for f in file_list:\n",
    "        tmp = f.split('.mkv')[0]\n",
    "        ID  = tmp.split('_')[-1]\n",
    "        if (ID == \"13\" or ID == \"15\"):\n",
    "            continue\n",
    "        else :\n",
    "            new_file_list.append(f)\n",
    "    return new_file_list\n",
    "\n",
    "\n",
    "def draw_registration_result(source, target, transformation):\n",
    "    source_temp = copy.deepcopy(source)\n",
    "    target_temp = copy.deepcopy(target)\n",
    "    source_temp.paint_uniform_color([1, 0.706, 0])\n",
    "    target_temp.paint_uniform_color([0, 0.651, 0.929])\n",
    "    source_temp.transform(transformation)\n",
    "    o3d.visualization.draw_geometries([source_temp, target_temp])\n",
    "\n",
    "def cluster_point_cloud_new(outlier_cloud):\n",
    "    cloud_colors = copy.deepcopy(np.asarray(outlier_cloud.colors).T)\n",
    "    \n",
    "    with o3d.utility.VerbosityContextManager(o3d.utility.VerbosityLevel.Error) as cm:\n",
    "        labels = np.array(outlier_cloud.cluster_dbscan(eps=0.1, min_points=10, print_progress=False))\n",
    "\n",
    "    # Identify the largest cluster\n",
    "    values, counts = np.unique(labels, return_counts=True)\n",
    "    ind = np.argmax(counts)\n",
    "    largest_cluster_label = values[ind]\n",
    "    #print(f\"Largest cluster label: {largest_cluster_label}\")\n",
    "\n",
    "    # Filter points, normals, and colors for the largest cluster\n",
    "    cloud_xyz = pcd2xyz(outlier_cloud)\n",
    "    cloud_normals = pcd2normals(outlier_cloud)\n",
    "\n",
    "    cloud_filtered = cloud_xyz[:, labels == largest_cluster_label]\n",
    "    normals_filtered = cloud_normals[:, labels == largest_cluster_label]\n",
    "    colors_filtered = cloud_colors[:, labels == largest_cluster_label]\n",
    "\n",
    "    # Create a point cloud for the largest cluster\n",
    "    pcd_filtered_largest_cluster = o3d.geometry.PointCloud()\n",
    "    pcd_filtered_largest_cluster.points = o3d.utility.Vector3dVector(cloud_filtered.T)\n",
    "    pcd_filtered_largest_cluster.normals = o3d.utility.Vector3dVector(normals_filtered.T)\n",
    "    pcd_filtered_largest_cluster.colors = o3d.utility.Vector3dVector(colors_filtered.T)\n",
    "\n",
    "    #o3d.visualization.draw_geometries([pcd_filtered_largest_cluster])\n",
    "    return pcd_filtered_largest_cluster\n",
    "\n",
    "def upsample_using_reference_normals(sparse_pcd, dense_pcd, search_radius=0.02, angle_threshold=30):\n",
    "    \"\"\"\n",
    "    Efficiently upsample the sparse point cloud using the dense point cloud as reference.\n",
    "    Considers the normals to ensure added points are consistent with the sparse cloud.\n",
    "\n",
    "    Parameters:\n",
    "    - sparse_pcd: The sparse point cloud\n",
    "    - dense_pcd: The dense reference point cloud\n",
    "    - search_radius: Radius to search for neighbors\n",
    "    - angle_threshold: Maximum angle in degrees between normals to consider a point\n",
    "\n",
    "    Returns:\n",
    "    - A new upsampled point cloud\n",
    "    \"\"\"\n",
    "    # Ensure the point clouds have normals\n",
    "    if not sparse_pcd.has_normals():\n",
    "        sparse_pcd.estimate_normals()\n",
    "    if not dense_pcd.has_normals():\n",
    "        dense_pcd.estimate_normals()\n",
    "\n",
    "    kdtree = o3d.geometry.KDTreeFlann(dense_pcd)\n",
    "\n",
    "    sparse_points = np.asarray(sparse_pcd.points)\n",
    "    sparse_normals = np.asarray(sparse_pcd.normals)\n",
    "    added_points = set(map(tuple, sparse_points))\n",
    "\n",
    "    upsampled_points = list(sparse_points)\n",
    "\n",
    "    for i, point in enumerate(sparse_points):\n",
    "        [k, idx, _] = kdtree.search_radius_vector_3d(point, search_radius)\n",
    "        \n",
    "        neighbors = np.asarray(dense_pcd.points)[idx]\n",
    "        neighbor_normals = np.asarray(dense_pcd.normals)[idx]\n",
    "\n",
    "        # Calculate angles between sparse point's normal and all its neighbors' normals\n",
    "        angles = np.degrees(np.arccos(np.clip(np.dot(sparse_normals[i], neighbor_normals.T), -1.0, 1.0)))\n",
    "\n",
    "        # Filtering neighbors based on angle threshold\n",
    "        valid_neighbors = neighbors[angles < angle_threshold]\n",
    "\n",
    "        # Filtering out points that are already in the sparse cloud or have been added before\n",
    "        unique_valid_neighbors = [tuple(neighbor) for neighbor in valid_neighbors if tuple(neighbor) not in added_points]\n",
    "\n",
    "        upsampled_points.extend(unique_valid_neighbors)\n",
    "        added_points.update(unique_valid_neighbors)\n",
    "\n",
    "    upsampled_pcd = o3d.geometry.PointCloud()\n",
    "    upsampled_pcd.points = o3d.utility.Vector3dVector(upsampled_points)\n",
    "    upsampled_pcd.estimate_normals()\n",
    "\n",
    "    return upsampled_pcd\n",
    "\n",
    "\n",
    "def pcd2normals(pcd):\n",
    "    return np.asarray(pcd.normals).T\n",
    "def pcd2xyz(pcd):\n",
    "    return np.asarray(pcd.points).T\n",
    "\n",
    "\n",
    "@jit(nopython=True, parallel=True)\n",
    "def numba_eliminate_flying_pixels(depth_image, ws, threshold):\n",
    "    height, width = depth_image.shape\n",
    "    result = np.zeros_like(depth_image, dtype=np.float64)\n",
    "    \n",
    "    for cy in prange(height):\n",
    "        for cx in prange(width):\n",
    "            x_start, x_end = max(0, cx - ws), min(width, cx + ws + 1)\n",
    "            y_start, y_end = max(0, cy - ws), min(height, cy + ws + 1)\n",
    "            window = depth_image[y_start:y_end, x_start:x_end]\n",
    "            result[cy, cx] = np.sum(np.abs(window - depth_image[cy, cx]))\n",
    "    \n",
    "    return result\n",
    "\n",
    "def colored_ICP(source, target):\n",
    "    \n",
    "    voxel_radius = [0.04, 0.02, 0.01]\n",
    "    max_iter = [50, 30, 14]\n",
    "    current_transformation = np.identity(4)\n",
    "    #print(\"3. Colored point cloud registration\")\n",
    "    for scale in range(3):\n",
    "        iters = max_iter[scale]\n",
    "        radius = voxel_radius[scale]\n",
    "        #print(\"iteration: \", iters, radius, scale)\n",
    "\n",
    "        #print(\"3-1. Downsample with a voxel size %.2f\" % radius)\n",
    "        source_down = copy.deepcopy(source).voxel_down_sample(radius)\n",
    "        target_down = copy.deepcopy(target).voxel_down_sample(radius)\n",
    "\n",
    "        #print(\"3-2. Estimate normal.\")\n",
    "        source_down.estimate_normals(\n",
    "            o3d.geometry.KDTreeSearchParamHybrid(radius=radius * 2, max_nn=30))\n",
    "        target_down.estimate_normals(\n",
    "            o3d.geometry.KDTreeSearchParamHybrid(radius=radius * 2, max_nn=30))\n",
    "\n",
    "        #print(\"3-3. Applying colored point cloud registration\")\n",
    "        result_icp = o3d.pipelines.registration.registration_colored_icp(\n",
    "            source_down, target_down, radius, current_transformation,\n",
    "            o3d.pipelines.registration.TransformationEstimationForColoredICP(),\n",
    "            o3d.pipelines.registration.ICPConvergenceCriteria(relative_fitness=1e-6,\n",
    "                                                              relative_rmse=1e-6,\n",
    "                                                              max_iteration=iters))\n",
    "        current_transformation = result_icp.transformation\n",
    "    \n",
    "   \n",
    "        #draw_registration_result(source, target, current_transformation)\n",
    "    return current_transformation\n",
    "\n",
    "def backproject_o3d(rgbd_frame, intrinsics):\n",
    "    \n",
    "    rgbdc = o3d.geometry.RGBDImage.create_from_color_and_depth(\n",
    "        rgbd_frame.color, rgbd_frame.depth, depth_trunc=4.0, convert_rgb_to_intensity=False)\n",
    "    pcd = o3d.geometry.PointCloud.create_from_rgbd_image(rgbdc, intrinsics)\n",
    "    n_radius = 0.01*2.0\n",
    "    pcd.estimate_normals(\n",
    "    search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=n_radius, max_nn=30))\n",
    "    \n",
    "    return pcd\n",
    "\n",
    "def load_calibration(tform_path, num_transforms=5):\n",
    "    transforms = [np.eye(4)]  # Initialize with identity matrix\n",
    "    \n",
    "    # Load transformations from file\n",
    "    for i in range(1, num_transforms+1):\n",
    "        filename = tform_path + f\"H_0_{i}.txt\"\n",
    "        \n",
    "        if not os.path.exists(filename):\n",
    "            raise FileNotFoundError(f\"The file {filename} does not exist!\")\n",
    "        \n",
    "        transforms.append(np.loadtxt(filename))\n",
    "    \n",
    "    return transforms\n",
    "\n",
    "def perform_pairwise_alignment(pcds_tsdf,pcds_cropped):\n",
    "    #\"\"\"Compute and apply transformations.\"\"\"\n",
    "    t01 = colored_ICP(pcds_tsdf[0], pcds_tsdf[1])\n",
    "    t52 = colored_ICP(pcds_tsdf[5], pcds_tsdf[2])\n",
    "    t43 = colored_ICP(pcds_tsdf[4], pcds_tsdf[3])\n",
    "    t12 = colored_ICP(pcds_tsdf[1], pcds_tsdf[2])\n",
    "    t32 = colored_ICP(pcds_tsdf[3], pcds_tsdf[2])\n",
    "\n",
    "    H0 = t12 @ t01\n",
    "    H1 = t12\n",
    "    H3 = t32\n",
    "    H4 = t32 @ t43\n",
    "    H5 = t52\n",
    "\n",
    "    # Transform the point clouds\n",
    "    p0 = copy.deepcopy(pcds_cropped[0]).transform(H0)\n",
    "    p1 = copy.deepcopy(pcds_cropped[1]).transform(H1)\n",
    "    p3 = copy.deepcopy(pcds_cropped[3]).transform(H3)\n",
    "    p4 = copy.deepcopy(pcds_cropped[4]).transform(H4)\n",
    "    p5 = copy.deepcopy(pcds_cropped[5]).transform(H5)\n",
    "    \n",
    "    d0 = copy.deepcopy(pcds_tsdf[0]).transform(H0)\n",
    "    d1 = copy.deepcopy(pcds_tsdf[1]).transform(H1)\n",
    "    d3 = copy.deepcopy(pcds_tsdf[3]).transform(H3)\n",
    "    d4 = copy.deepcopy(pcds_tsdf[4]).transform(H4)\n",
    "    d5 = copy.deepcopy(pcds_tsdf[5]).transform(H5)\n",
    "    \n",
    "    pcd_combined = o3d.geometry.PointCloud()\n",
    "    pcd_combined = p0+p1+pcds_cropped[2]+p3+p4+p5\n",
    "    \n",
    "    ptsdf_combined = o3d.geometry.PointCloud()\n",
    "    ptsdf_combined = d0+d1+pcds_tsdf[2]+d3+d4+d5\n",
    "\n",
    "    return pcd_combined, ptsdf_combined\n",
    "\n",
    "def process_file(i):\n",
    "    inFile = files[i]\n",
    "    fname = inFile.split('/')[-1]\n",
    "    file_name = fname.split('.mkv')[0]\n",
    "    \n",
    "    reader = o3d.io.AzureKinectMKVReader()\n",
    "    reader.open(inFile)\n",
    "    \n",
    "    if not reader.is_opened():\n",
    "        raise RuntimeError(\"Unable to open file {}\".format(inFile))\n",
    "    \n",
    "    metadata = reader.get_metadata()\n",
    "\n",
    "    # write the metadata to a JSON file since that seems to be the only\n",
    "    # way to retrieve that data\n",
    "    o3d.io.write_azure_kinect_mkv_metadata('{}/{}_intrinsic.json'.format(abspath, file_name), metadata)\n",
    "\n",
    "    # Open the file and load the JSON\n",
    "    with open(abspath + \"/\" + file_name + \"_intrinsic.json\") as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    height = data['height']\n",
    "    width = data['width']\n",
    "    intrinsics = data[\"intrinsic_matrix\"]\n",
    "    time_stamp = data[\"stream_length_usec\"]\n",
    "\n",
    "    camera_intrinsics = o3d.camera.PinholeCameraIntrinsic()\n",
    "    cx = intrinsics[6]\n",
    "    cy = intrinsics[7]\n",
    "    fx = intrinsics[0]\n",
    "    fy = intrinsics[4]\n",
    "    camera_intrinsics.set_intrinsics(width, height, fx, fy, cx, cy)\n",
    "\n",
    "    last_frame = None\n",
    "    while not reader.is_eof():\n",
    "        rgbda = reader.next_frame()\n",
    "        if rgbda is None:\n",
    "            continue\n",
    "        last_frame = rgbda\n",
    "\n",
    "    if last_frame is not None:\n",
    "        return last_frame\n",
    "    else:\n",
    "        print(\"************No valid frames found in the .mkv file.**********\")\n",
    "        return None\n",
    "\n",
    "def upsample_using_reference_normals_new(sparse_pcd, dense_pcd, search_radius=0.02, angle_threshold=30):\n",
    "    # Ensure the point clouds have normals\n",
    "    if not sparse_pcd.has_normals():\n",
    "        sparse_pcd.estimate_normals()\n",
    "    if not dense_pcd.has_normals():\n",
    "        dense_pcd.estimate_normals()\n",
    "\n",
    "    dense_points = np.asarray(dense_pcd.points)\n",
    "    dense_tree = cKDTree(dense_points)\n",
    "\n",
    "    sparse_points = np.asarray(sparse_pcd.points)\n",
    "    sparse_normals = np.asarray(sparse_pcd.normals)\n",
    "    \n",
    "    # This retrieves the indices of all neighbors within the search_radius\n",
    "    neighbor_indices = dense_tree.query_ball_point(sparse_points, search_radius, workers=-1)\n",
    "    \n",
    "    valid_indices = []\n",
    "    for i, idx_row in enumerate(neighbor_indices):\n",
    "        neighbors = dense_points[idx_row]\n",
    "        neighbor_normals = np.asarray(dense_pcd.normals)[idx_row]\n",
    "\n",
    "        # Calculate angles between sparse point's normal and all its neighbors' normals\n",
    "        angles = np.degrees(np.arccos(np.clip(np.dot(sparse_normals[i], neighbor_normals.T), -1.0, 1.0)))\n",
    "\n",
    "        # Filtering neighbors based on angle threshold\n",
    "        valid_neighbor_indices = np.array(idx_row)[angles < angle_threshold]\n",
    "        valid_indices.extend(valid_neighbor_indices)\n",
    "#     valid_indices = []\n",
    "#     for i, idx_row in enumerate(neighbor_indices):\n",
    "#         neighbors = dense_points[idx_row]\n",
    "#         neighbor_normals = np.asarray(dense_pcd.normals)[idx_row]\n",
    "        \n",
    "#         # Calculate angles between sparse point's normal and all its neighbors' normals\n",
    "#         angles = np.degrees(np.arccos(np.clip(np.dot(sparse_normals[i], neighbor_normals.T), -1.0, 1.0)))\n",
    "\n",
    "#         # Filtering neighbors based on angle threshold\n",
    "#         valid_for_current = idx_row[angles < angle_threshold]\n",
    "#         valid_indices.extend(valid_for_current)\n",
    "\n",
    "    unique_valid_indices = np.unique(valid_indices)\n",
    "    final_valid_neighbors = dense_points[unique_valid_indices]\n",
    "    \n",
    "    upsampled_points = np.vstack([sparse_points, final_valid_neighbors])\n",
    "\n",
    "    upsampled_pcd = o3d.geometry.PointCloud()\n",
    "    upsampled_pcd.points = o3d.utility.Vector3dVector(upsampled_points)\n",
    "    upsampled_pcd.estimate_normals()\n",
    "\n",
    "    return upsampled_pcd\n",
    "\n",
    "\n",
    "def load_filter_pcds(data_path, ctform):  # returns a list of  pcds\n",
    "    ws = 2\n",
    "    flying_pixel_filter_threshold = 1000\n",
    "\n",
    "    reader = o3d.io.AzureKinectMKVReader()\n",
    "    abspath = data_path\n",
    "    pcds = []\n",
    "    files_raw = glob.glob(data_path+'/*.mkv')\n",
    "    files = filter_file_names(files_raw)\n",
    "    files.sort()\n",
    "   \n",
    "    list_size = len(files)\n",
    "    rgbd_frames = [None] * list_size\n",
    "    pcds_tsdf = []\n",
    "    \n",
    "    l1 = time.time()\n",
    "    for i in range(len(files)): # for each view\n",
    "   \n",
    "        inFile = files[i]\n",
    "        fname = inFile.split('/')[-1]\n",
    "        file_name = fname.split('.mkv')[0]\n",
    "        reader.open(inFile)\n",
    "        if not reader.is_opened():\n",
    "            raise RuntimeError(\"Unable to open file {}\".format(inFile))\n",
    "        metadata = reader.get_metadata()\n",
    "  \n",
    "        # write the metadata to a JSON file since that seems to be the only\n",
    "        # way to retrieve that data\n",
    "        o3d.io.write_azure_kinect_mkv_metadata(\n",
    "                    '{}/{}_intrinsic.json'.format(abspath,file_name), metadata)\n",
    "\n",
    "        # Open the file and load the JSON\n",
    "        with open(abspath+\"/\" + file_name + \"_intrinsic.json\") as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        height = data['height']\n",
    "        width = data['width']\n",
    "        intrinsics = data[\"intrinsic_matrix\"]\n",
    "        time_stamp = data[\"stream_length_usec\"]\n",
    "        #print(f\"Intrinsic Matrix {intrinsics}\")\n",
    "\n",
    "        camera_intrinsics = o3d.camera.PinholeCameraIntrinsic()\n",
    "        cx = intrinsics[6]\n",
    "        cy = intrinsics[7]\n",
    "        fx = intrinsics[0]\n",
    "        fy = intrinsics[4]\n",
    "        camera_intrinsics.set_intrinsics(width,height,fx,fy,cx,cy)\n",
    "\n",
    "        last_frame = None\n",
    "        while not reader.is_eof(): # go until hitting eof because of exposure issues in early color frames\n",
    "            rgbda = reader.next_frame();\n",
    "            if rgbda is None:\n",
    "                #print(\"Got nothing! \")\n",
    "                continue\n",
    "            last_frame = rgbda\n",
    "\n",
    "        if last_frame is not None:\n",
    "            #print(\"Got the last frame\")\n",
    "            rgbd_frames[i] = last_frame\n",
    "        else:\n",
    "            \n",
    "            print(\"************No valid frames found in the .mkv file.**********\")\n",
    "    \n",
    "        # filter the depth image for flying pixels\n",
    "        depth_image_array = np.asarray(last_frame.depth)\n",
    "        rgbdc = o3d.geometry.RGBDImage.create_from_color_and_depth(\n",
    "        last_frame.color, last_frame.depth, depth_trunc=4.0, convert_rgb_to_intensity=False)\n",
    "        volume = o3d.pipelines.integration.ScalableTSDFVolume(\n",
    "                    voxel_length= 4.0/ 512.0,\n",
    "                    sdf_trunc=0.4,\n",
    "                    color_type=o3d.pipelines.integration.TSDFVolumeColorType.RGB8)\n",
    "\n",
    "        volume.integrate(\n",
    "            rgbdc, # rgbdc originally - trying with masked_rgbd\n",
    "            camera_intrinsics,\n",
    "            np.eye(4),\n",
    "        )\n",
    "#         pcd_raw = backproject_o3d(last_frame,camera_intrinsics)\n",
    "        pcd_tsdf = volume.extract_point_cloud()\n",
    "        # First eliminate flying pixels before integrating the depth map\n",
    "        result_mask = numba_eliminate_flying_pixels(depth_image_array.copy(), ws, flying_pixel_filter_threshold)\n",
    "        depth_image_array[result_mask > flying_pixel_filter_threshold] = 0\n",
    "        # Re-insert filtered depth into the rgbd image\n",
    "        last_frame.depth = o3d.geometry.Image(depth_image_array)\n",
    "      \n",
    "        # Apply maskrcnn to filtered depth image\n",
    "        masked_rgbd = segment_images_modified(last_frame,i,data_path)\n",
    "        # necessary lol\n",
    "        rgbdc = o3d.geometry.RGBDImage.create_from_color_and_depth(\n",
    "        masked_rgbd.color, masked_rgbd.depth, depth_trunc=4.0, convert_rgb_to_intensity=False)\n",
    "        pcd_tmp = o3d.geometry.PointCloud.create_from_rgbd_image(rgbdc,\n",
    "                                                            camera_intrinsics)\n",
    "      \n",
    "        #print(\"Time was: \", w2-w1, \" s\")\n",
    "        pcds.append(copy.deepcopy(pcd_tmp).transform(ctform[i]))\n",
    "        pcds_tsdf.append(copy.deepcopy(pcd_tsdf).transform(ctform[i]))\n",
    "        reader.close()\n",
    "    l2 = time.time()  \n",
    "    print(\"Loading files: \", l2-l1, \" s\")\n",
    "    return pcds,pcds_tsdf\n",
    "\n",
    "\n",
    "def save_results(animal_id, data_path, mesh, pcd_downsampled, sa, v):\n",
    "    # Save the mesh and PCD\n",
    "    mesh_filename = os.path.join(data_path, f\"{animal_id}_mesh.ply\")\n",
    "    pcd_filename = os.path.join(data_path, f\"{animal_id}_pcd_downsampled.ply\")\n",
    "\n",
    "    o3d.io.write_triangle_mesh(mesh_filename, mesh)\n",
    "    \n",
    "    o3d.io.write_point_cloud(pcd_filename, pcd_downsampled)\n",
    "\n",
    "    CSV_PATH = '/home/vigir3d/Datasets/cattle_scans/cow_measurements.csv'\n",
    "    # Check if CSV file exists to decide whether to write headers\n",
    "    write_header = not os.path.exists(CSV_PATH)\n",
    "  # Save SA & V to the CSV file in append mode\n",
    "    with open(CSV_PATH, 'a', newline='') as csvfile:\n",
    "        fieldnames = ['Animal ID', 'SA', 'V']\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        \n",
    "        if write_header:\n",
    "            writer.writeheader()\n",
    "\n",
    "        writer.writerow({'Animal ID': animal_id, 'SA': sa, 'V': v})\n",
    "        \n",
    "def cluster_point_cloud_tensor(pcd) :\n",
    "    colors = pcd.point.colors\n",
    "    with o3d.utility.VerbosityContextManager(\n",
    "            o3d.utility.VerbosityLevel.Error) as cm:\n",
    "        labels = pcd.cluster_dbscan(eps=0.1, min_points=10, print_progress=False)\n",
    "        \n",
    "    \n",
    "    labels = labels.cpu()\n",
    "    # Identify the largest cluster\n",
    "    values, counts = np.unique(labels, return_counts=True)\n",
    "    ind = np.argmax(counts)\n",
    "    largest_cluster_label = values[ind]\n",
    "    #print(f\"Largest cluster label: {largest_cluster_label}\")\n",
    "\n",
    "    colors[labels < 0] = 0\n",
    "    pcd.point.colors = colors\n",
    "    return pcd\n",
    "\n",
    "\n",
    "# Main\n",
    "rgb_model_path = '/home/vigir3d/Datasets/cattle_scans/maskrcnn_data/maskrcnn_v2.pth'\n",
    "depth_model_path = '/home/vigir3d/Datasets/cattle_scans/maskrcnn_data/maskrcnn_depth_best.pth'\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Loads the maskrcnn trained for depth and rgb\n",
    "model_rgb = load_maskrcnn_model(rgb_model_path)\n",
    "model_depth = load_maskrcnn_model(depth_model_path)\n",
    "\n",
    "\n",
    "transform = T.ToTensor()\n",
    "# These two will need to be requested from command line\n",
    "# -i   | input data path\n",
    "# - t  | calibration data path \n",
    "data_path = '/home/vigir3d/Datasets/cattle_scans/Cattle_scan_11_17_22/Animal_5_2'\n",
    "tform_path = '/home/vigir3d/Datasets/cattle_scans/farm_07_24/Animal_calib/'\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Run things\n",
    "    tensor = False\n",
    "    if  tensor :\n",
    "        s = time.time()\n",
    "\n",
    "        l1 = time.time()\n",
    "        tforms = load_calibration(tform_path,5)\n",
    "        pcds, ptsdf = load_filter_pcds(data_path,tforms)\n",
    "        pcd_all, ptsdf_all = perform_pairwise_alignment(ptsdf,pcds)\n",
    "        l2 = time.time()\n",
    "\n",
    "        #place on the GPU\n",
    "        # Tensorize\n",
    "        # get the Device\n",
    "        p1 = time.time()\n",
    "        o3d_device = o3d.core.Device(\"CUDA:0\") \n",
    "        # convert segmented and full clouds to tensor\n",
    "        pcd_t = o3d.t.geometry.PointCloud.from_legacy(pcd_all).to(o3d_device)\n",
    "        #pcd_t_tsdf = o3d.t.geometry.PointCloud.from_legacy(ptsdf_all).to(o3d_device)\n",
    "        pcd_t.estimate_normals()\n",
    "        # Perform clustering to get largest cloud of points from segmented cloud\n",
    "        pcd_clustered = cluster_point_cloud_tensor(pcd_t)\n",
    "        # place on cpu\n",
    "        pcd_clustered_cpu = pcd_clustered.cpu().to_legacy()\n",
    "        p2 = time.time()\n",
    "\n",
    "        u1 = time.time()\n",
    "        # Upsample the single cluster cloud using the full cloud as reference\n",
    "        pcd_upsampled = upsample_using_reference_normals_new(pcd_clustered_cpu, ptsdf_all)\n",
    "        u2 = time.time()\n",
    "\n",
    "        tn1 = time.time()\n",
    "        # Downsample uniformly to ease compute\n",
    "        pcd_downsampled = pcd_upsampled.voxel_down_sample(0.01)\n",
    "        # Correct for the normal orientation problem\n",
    "        pcd_downsampled.orient_normals_consistent_tangent_plane(30)\n",
    "        tn2 = time.time()\n",
    "\n",
    "        m1 = time.time()\n",
    "        with o3d.utility.VerbosityContextManager(o3d.utility.VerbosityLevel.Error) as cm:\n",
    "                 mesh, densities = o3d.geometry.TriangleMesh.create_from_point_cloud_poisson(pcd_downsampled, depth=6)\n",
    "        m2 = time.time()\n",
    "        sa = mesh.get_surface_area()\n",
    "        if(mesh.is_watertight()):\n",
    "            #print(\"Is watertight 1\")\n",
    "            v =  mesh.get_volume()\n",
    "        else : \n",
    "            v = 0.0\n",
    "        animal_id = os.path.basename(os.path.normpath(data_path))\n",
    "        save_results(animal_id, data_path, mesh, pcd_downsampled, sa, v)\n",
    "        e = time.time()\n",
    "\n",
    "        print(\"Total time: \", e-s, \" s\")\n",
    "\n",
    "\n",
    "        print(\"Load and register: \", l2-l1, \" s\")\n",
    "\n",
    "        print(\"Preprocess: \", p2-p1, \" s\")\n",
    "\n",
    "        print(\"Upsampling: \", u2-u1, \" s\")\n",
    "        print(\"Normal orientation: \", tn2-tn1, \" s\")    \n",
    "        print(\"Meshing: \", m2-m1, \" s\")\n",
    "    \n",
    "    elif tensor :\n",
    "        # Run things\n",
    "        s = time.time()\n",
    "\n",
    "        l1 = time.time()\n",
    "        tforms = load_calibration(tform_path,5)\n",
    "        pcds, ptsdf = load_filter_pcds(data_path,tforms)\n",
    "        l2 = time.time()\n",
    "        pcd_all, ptsdf_all = perform_pairwise_alignment(ptsdf,pcds)\n",
    "        r2 = time.time()\n",
    "        \n",
    "        p1 = time.time()\n",
    "        pcd_all.estimate_normals()\n",
    "        # cluster first to remove extra noise\n",
    "        pcd_clustered = cluster_point_cloud_new(pcd_all)\n",
    "        # After clustering, we upsample from the initial\n",
    "        p2 = time.time()\n",
    "\n",
    "        u1 = time.time()\n",
    "        pcd_upsampled = upsample_using_reference_normals_new(pcd_clustered, ptsdf_all)\n",
    "        u2 = time.time()\n",
    "\n",
    "        tn1 = time.time()\n",
    "        pcd_downsampled = pcd_upsampled.voxel_down_sample(0.01)\n",
    "        #pcd_downsampled.orient_normals_towards_camera_location()\n",
    "        pcd_downsampled.orient_normals_consistent_tangent_plane(30)\n",
    "        tn2 = time.time()\n",
    "\n",
    "        m1 = time.time()\n",
    "        with o3d.utility.VerbosityContextManager(o3d.utility.VerbosityLevel.Error) as cm:\n",
    "                mesh, densities = o3d.geometry.TriangleMesh.create_from_point_cloud_poisson(pcd_downsampled, depth=6)\n",
    "\n",
    "        sa = mesh.get_surface_area()\n",
    "        if(mesh.is_watertight()):\n",
    "            #print(\"Is watertight 1\")\n",
    "            v =  mesh.get_volume()\n",
    "        else : \n",
    "            v = 0.0\n",
    "        m2 = time.time()\n",
    "        animal_id = os.path.basename(os.path.normpath(data_path))\n",
    "        save_results(animal_id, data_path, mesh, pcd_downsampled, sa, v)\n",
    "\n",
    "        e = time.time()\n",
    "        print(\"Load files: \", l2-l1, \" s\")\n",
    "        print(\"Register clouds: \", r2-l2, \" s\")\n",
    "\n",
    "        print(\"Remove extra points: \", p2-p1, \" s\")\n",
    "\n",
    "        print(\"Upsampling: \", u2-u1, \" s\")\n",
    "        print(\"Normal orientation: \", tn2-tn1, \" s\")    \n",
    "        print(\"Meshing: \", m2-m1, \" s\")\n",
    "        print(\"Total time: \", e-s, \" s\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb4bbfb5",
   "metadata": {},
   "source": [
    "# Non tensor version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60774818",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run things\n",
    "data_path = '/home/vigir3d/Datasets/cattle_scans/Cattle_scan_11_17_22/Animal_5_2'\n",
    "tform_path = '/home/vigir3d/Datasets/cattle_scans/farm_07_24/Animal_calib/'\n",
    "s = time.time()\n",
    "\n",
    "l1 = time.time()\n",
    "tforms = load_calibration(tform_path,5)\n",
    "pcds, ptsdf = load_filter_pcds(data_path,tforms)\n",
    "pcd_all, ptsdf_all = perform_pairwise_alignment(ptsdf,pcds)\n",
    "l2 = time.time()\n",
    "\n",
    "p1 = time.time()\n",
    "pcd_all.estimate_normals()\n",
    "# cluster first to remove extra noise\n",
    "pcd_clustered = cluster_point_cloud_new(pcd_all)\n",
    "# After clustering, we upsample from the initial\n",
    "p2 = time.time()\n",
    "\n",
    "u1 = time.time()\n",
    "pcd_upsampled = upsample_using_reference_normals_new(pcd_clustered, ptsdf_all)\n",
    "u2 = time.time()\n",
    "\n",
    "tn1 = time.time()\n",
    "pcd_downsampled = pcd_upsampled.voxel_down_sample(0.01)\n",
    "#pcd_downsampled.orient_normals_towards_camera_location()\n",
    "pcd_downsampled.orient_normals_consistent_tangent_plane(30)\n",
    "tn2 = time.time()\n",
    "\n",
    "m1 = time.time()\n",
    "with o3d.utility.VerbosityContextManager(o3d.utility.VerbosityLevel.Error) as cm:\n",
    "        mesh, densities = o3d.geometry.TriangleMesh.create_from_point_cloud_poisson(pcd_downsampled, depth=6)\n",
    "\n",
    "sa = mesh.get_surface_area()\n",
    "if(mesh.is_watertight()):\n",
    "    #print(\"Is watertight 1\")\n",
    "    v =  mesh.get_volume()\n",
    "else : \n",
    "    v = 0.0\n",
    "m2 = time.time()\n",
    "animal_id = os.path.basename(os.path.normpath(data_path))\n",
    "save_results(animal_id, data_path, mesh, pcd_downsampled, sa, v)\n",
    "\n",
    "e = time.time()\n",
    "\n",
    "print(\"Total time: \", e-s, \" s\")\n",
    "\n",
    "\n",
    "print(\"Load and register: \", l2-l1, \" s\")\n",
    "\n",
    "print(\"Preprocess: \", p2-p1, \" s\")\n",
    "\n",
    "print(\"Upsampling: \", u2-u1, \" s\")\n",
    "print(\"Normal orientation: \", tn2-tn1, \" s\")    \n",
    "print(\"Meshing: \", m2-m1, \" s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4879d44a",
   "metadata": {},
   "source": [
    "# Playing with the tensor class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e23857a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d.core as o3c\n",
    "\n",
    "def load_filter_pcds_tensor(data_path, ctform):  # returns a list of  pcds\n",
    "    ws = 2\n",
    "    flying_pixel_filter_threshold = 1000\n",
    "\n",
    "    reader = o3d.io.AzureKinectMKVReader()\n",
    "    abspath = data_path\n",
    "    pcds = []\n",
    "    files_raw = glob.glob(data_path+'/*.mkv')\n",
    "    files = filter_file_names(files_raw)\n",
    "    files.sort()\n",
    "   \n",
    "    list_size = len(files)\n",
    "    rgbd_frames = [None] * list_size\n",
    "    pcds_tsdf = []\n",
    "    \n",
    "    \n",
    "    for i in range(len(files)): # for each view\n",
    "   \n",
    "        inFile = files[i]\n",
    "        fname = inFile.split('/')[-1]\n",
    "        file_name = fname.split('.mkv')[0]\n",
    "        print(file_name)\n",
    "        reader.open(inFile)\n",
    "        if not reader.is_opened():\n",
    "            raise RuntimeError(\"Unable to open file {}\".format(inFile))\n",
    "        metadata = reader.get_metadata()\n",
    "  \n",
    "        # write the metadata to a JSON file since that seems to be the only\n",
    "        # way to retrieve that data\n",
    "        o3d.io.write_azure_kinect_mkv_metadata(\n",
    "                    '{}/{}_intrinsic.json'.format(abspath,file_name), metadata)\n",
    "\n",
    "        # Open the file and load the JSON\n",
    "        with open(abspath+\"/\" + file_name + \"_intrinsic.json\") as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        height = data['height']\n",
    "        width = data['width']\n",
    "        intrinsics = data[\"intrinsic_matrix\"]\n",
    "        time_stamp = data[\"stream_length_usec\"]\n",
    "        #print(f\"Intrinsic Matrix {intrinsics}\")\n",
    "\n",
    "        camera_intrinsics = o3d.camera.PinholeCameraIntrinsic()\n",
    "        cx = intrinsics[6]\n",
    "        cy = intrinsics[7]\n",
    "        fx = intrinsics[0]\n",
    "        fy = intrinsics[4]\n",
    "        camera_intrinsics.set_intrinsics(width,height,fx,fy,cx,cy)\n",
    "\n",
    "        last_frame = None\n",
    "        while not reader.is_eof(): # go until hitting eof because of exposure issues in early color frames\n",
    "            rgbda = reader.next_frame();\n",
    "            if rgbda is None:\n",
    "                #print(\"Got nothing! \")\n",
    "                continue\n",
    "            last_frame = rgbda\n",
    "\n",
    "        if last_frame is not None:\n",
    "            #print(\"Got the last frame\")\n",
    "            rgbd_frames[i] = last_frame\n",
    "        else:\n",
    "            \n",
    "            print(\"************No valid frames found in the .mkv file.**********\")\n",
    "        \n",
    "        cname = data_path+\"/\"+file_name+\"_color.png\"\n",
    "        dname = data_path+\"/\"+file_name+\"_depth.jpg\"\n",
    "        o3d.io.write_image(cname, last_frame.color)\n",
    "        o3d.io.write_image(dname, last_frame.depth)\n",
    "        \n",
    "        \n",
    "        color = o3d.t.io.read_image(cname).to(\n",
    "        o3d.core.Device(\"CUDA:0\")\n",
    "        )\n",
    "        depth = o3d.t.io.read_image(dname).to(\n",
    "            o3d.core.Device(\"CUDA:0\")\n",
    "        )\n",
    "        \n",
    "#         # filter the depth image for flying pixels\n",
    "#         cimage_tensor = o3d.core.Tensor.from_numpy(np.asarray(last_frame.color))\n",
    "#         dimage_tensor = o3d.core.Tensor.from_numpy(np.asarray(last_frame.depth))        \n",
    "        \n",
    "#         # Create an Open3D tensor image\n",
    "#         color_image = o3d.t.geometry.Image(cimage_tensor).to( o3d.core.Device(\"CUDA:0\"))\n",
    "#         depth_image = o3d.t.geometry.Image(dimage_tensor).to( o3d.core.Device(\"CUDA:0\"))\n",
    "#         #bf_depth_image = o3d.t.geometry.Image.filter_bilateral(depth_image,3,20,10)\n",
    "        #rgbd_t = o3d.t.geometry.RGBDImage(color_image,bf_depth_image, True)\n",
    "        \n",
    "        K = o3d.core.Tensor(camera_intrinsics.intrinsic_matrix,)\n",
    "        extrinsics = o3d.core.Tensor(np.linalg.inv(np.eye(4)),)\n",
    "        # integrate on the GPU\n",
    "        device = o3d.core.Device('CUDA:0')\n",
    "       \n",
    "        \n",
    "        volume = o3d.t.geometry.VoxelBlockGrid(\n",
    "            attr_names=(\"tsdf\", \"weight\", \"color\"),\n",
    "            attr_dtypes=(o3c.float32, o3c.float32, o3c.float32),\n",
    "            attr_channels=((1), (1), (3)),\n",
    "            voxel_size=3.0 / 512,\n",
    "            block_resolution=16,\n",
    "            block_count=50000,\n",
    "            device=o3d.core.Device(\"CUDA:0\"),\n",
    "        )\n",
    "\n",
    "        \n",
    "        depth_max = 4\n",
    "        depth_scale = 1000.0\n",
    "        \n",
    "        frustum_block_coords = volume.compute_unique_block_coordinates(\n",
    "            depth, K, extrinsics, depth_max=4.0\n",
    "            )\n",
    "\n",
    "        volume.integrate(\n",
    "            frustum_block_coords,\n",
    "            depth,\n",
    "            color,\n",
    "            K,\n",
    "            extrinsics,\n",
    "            depth_max=4.0,\n",
    "            )\n",
    "        pcd = volume.extract_point_cloud()\n",
    "        print(pcd)\n",
    "        p = pcd.to_legacy()\n",
    "        #o3d.visualization.draw_geometries([pcd.to_legacy()])\n",
    "\n",
    "           \n",
    "        #vbg.integrate(frustum_block_coords, depth_image, color_image, K, K, ext, depth_scale, depth_max)\n",
    "        \n",
    "        \n",
    "        #pcd = vbg.extract_point_cloud()\n",
    "        #o3d.visualization.draw([pcd])\n",
    "        \n",
    "        print(\"Done Integrating ...!\")\n",
    "\n",
    "        pcds.append(p)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    return pcds,pcds_tsdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a064472",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/home/vigir3d/Datasets/cattle_scans/Cattle_scan_11_17_22/Animal_5_2'\n",
    "tform_path = '/home/vigir3d/Datasets/cattle_scans/farm_07_24/Animal_calib/'\n",
    "tforms = load_calibration(tform_path,5)\n",
    "\n",
    "s1 = time.time()\n",
    "p1,t1 = load_filter_pcds_tensor(data_path,tforms)\n",
    "s2 = time.time()\n",
    "\n",
    "print(\"Duration is: \", s2-s1)\n",
    "\n",
    "\n",
    "s3 = time.time()\n",
    "p2,t2 = load_filter_pcds(data_path,tforms)\n",
    "s4 = time.time()\n",
    "\n",
    "print(\"Duration is: \", s4-s3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cde4b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4235e929",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "\n",
    "def process_file(i):\n",
    "    #ws = 2\n",
    "    #flying_pixel_filter_threshold = 1000\n",
    "    #print(multiaprocessing.current_process())\n",
    "    inFile = files[i]\n",
    "    fname = inFile.split('/')[-1]\n",
    "    file_name = fname.split('.mkv')[0]\n",
    "    \n",
    "    reader = o3d.io.AzureKinectMKVReader()\n",
    "    reader.open(inFile)\n",
    "    \n",
    "    if not reader.is_opened():\n",
    "        raise RuntimeError(\"Unable to open file {}\".format(inFile))\n",
    "    \n",
    "    metadata = reader.get_metadata()\n",
    "\n",
    "    # write the metadata to a JSON file since that seems to be the only\n",
    "    # way to retrieve that data\n",
    "    o3d.io.write_azure_kinect_mkv_metadata('{}/{}_intrinsic.json'.format(abspath, file_name), metadata)\n",
    "\n",
    "    # Open the file and load the JSON\n",
    "    with open(abspath + \"/\" + file_name + \"_intrinsic.json\") as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    height = data['height']\n",
    "    width = data['width']\n",
    "    intrinsics = data[\"intrinsic_matrix\"]\n",
    "    time_stamp = data[\"stream_length_usec\"]\n",
    "\n",
    "    camera_intrinsics = o3d.camera.PinholeCameraIntrinsic()\n",
    "    cx = intrinsics[6]\n",
    "    cy = intrinsics[7]\n",
    "    fx = intrinsics[0]\n",
    "    fy = intrinsics[4]\n",
    "    camera_intrinsics.set_intrinsics(width, height, fx, fy, cx, cy)\n",
    "    #K = np.array([width,height,fx,fy,cx,cy])\n",
    "    last_frame = None\n",
    "    while not reader.is_eof():\n",
    "        rgbda = reader.next_frame()\n",
    "        if rgbda is None:\n",
    "            continue\n",
    "        last_frame = rgbda\n",
    "\n",
    "    if last_frame is not None:\n",
    "        #print(\"************No valid frames found in the .mkv file.**********\")\n",
    "    \n",
    "        print(\"Got last_frame\")\n",
    "        #return last_frame\n",
    "    else:\n",
    "        print(\"************No valid frames found in the .mkv file.**********\")\n",
    "        #return None\n",
    "    \n",
    "    reader.close()\n",
    "    rgbd_frames_glob[i] = last_frame\n",
    "    camera_intrinsics_glob[i] = camera_intrinsics\n",
    "    #return [np.asarray(last_ = frame.color), np.asarray(last_frame.depth), K]\n",
    "\n",
    "\n",
    "\n",
    "def load_filter_pcds_par(data_path, ctform):  # returns a list of  pcds\n",
    "    ws = 2\n",
    "    flying_pixel_filter_threshold = 1000\n",
    "\n",
    "    reader = o3d.io.AzureKinectMKVReader()\n",
    "    pcds = []\n",
    "    files_raw = glob.glob(data_path+'/*.mkv')\n",
    "    files = filter_file_names(files_raw)\n",
    "    files.sort()\n",
    "   \n",
    "    list_size = len(files)\n",
    "    rgbd_frames = [None] * list_size\n",
    "    pcds_tsdf = []\n",
    "    # Define the number of processes you want to spawn\n",
    "\n",
    "    NUM_PROCESSES =4\n",
    "    with Pool(processes=NUM_PROCESSES) as pool:\n",
    "        pool.map(process_file, range(len(files)))\n",
    "        \n",
    "    \n",
    "    print(\"Returned: \", len(rgbd_frames_glob))\n",
    "    for i in range(len(rgbd_frames_glob)):\n",
    "       \n",
    "        last_frame = rgbd_frames_glob[i]\n",
    "        camera_intrinsics = camera_intrinsics_glob[i]\n",
    "        depth_image_array = np.asarray(last_frame.depth)\n",
    "\n",
    "        rgbdc = o3d.geometry.RGBDImage.create_from_color_and_depth(\n",
    "        last_frame.color, last_frame.depth, depth_trunc=4.0, convert_rgb_to_intensity=False)\n",
    "      \n",
    "        volume = o3d.pipelines.integration.ScalableTSDFVolume(\n",
    "                    voxel_length= 4.0/ 512.0,\n",
    "                    sdf_trunc=0.4,\n",
    "                    color_type=o3d.pipelines.integration.TSDFVolumeColorType.RGB8)\n",
    "\n",
    "        volume.integrate(\n",
    "            rgbdc, # rgbdc originally - trying with masked_rgbd\n",
    "            camera_intrinsics,\n",
    "            np.eye(4),\n",
    "        )\n",
    "    #         pcd_raw = backproject_o3d(last_frame,camera_intrinsics)\n",
    "        pcd_tsdf = volume.extract_point_cloud()\n",
    "        # First eliminate flying pixels before integrating the depth map\n",
    "        result_mask = numba_eliminate_flying_pixels(depth_image_array.copy(), ws, flying_pixel_filter_threshold)\n",
    "        depth_image_array[result_mask > flying_pixel_filter_threshold] = 0\n",
    "        # Re-insert filtered depth into the rgbd image\n",
    "        last_frame.depth = o3d.geometry.Image(depth_image_array)\n",
    "\n",
    "        # Apply maskrcnn to filtered depth image\n",
    "        masked_rgbd = segment_images_modified(last_frame)\n",
    "        # necessary lol\n",
    "        rgbdc = o3d.geometry.RGBDImage.create_from_color_and_depth(\n",
    "        masked_rgbd.color, masked_rgbd.depth, depth_trunc=4.0, convert_rgb_to_intensity=False)\n",
    "        pcd_tmp = o3d.geometry.PointCloud.create_from_rgbd_image(rgbdc,\n",
    "                                                            camera_intrinsics)\n",
    "        pcds.append(pcd_tmp)\n",
    "        pcds_tsdf.append(pcd_tsdf)\n",
    "\n",
    "\n",
    "    return pcds,pcds_tsdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6afe7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_filter_pcds_par(data_path, ctform):  # returns a list of  pcds\n",
    "    ws = 2\n",
    "    flying_pixel_filter_threshold = 1000\n",
    "\n",
    "    reader = o3d.io.AzureKinectMKVReader()\n",
    "    pcds = []\n",
    "    files_raw = glob.glob(data_path+'/*.mkv')\n",
    "    files = filter_file_names(files_raw)\n",
    "    files.sort()\n",
    "   \n",
    "    list_size = len(files)\n",
    "    rgbd_frames = [None] * list_size\n",
    "    pcds_tsdf = []\n",
    "    # Define the number of processes you want to spawn\n",
    "\n",
    "    NUM_PROCESSES =4\n",
    "    with Pool(processes=NUM_PROCESSES) as pool:\n",
    "        pool.map(process_file, range(len(files)))\n",
    "        \n",
    "    \n",
    "    print(\"Returned: \", len(rgbd_frames_glob))\n",
    "    for i in range(len(rgbd_frames_glob)):\n",
    "       \n",
    "        last_frame = rgbd_frames_glob[i]\n",
    "        camera_intrinsics = camera_intrinsics_glob[i]\n",
    "        depth_image_array = np.asarray(last_frame.depth)\n",
    "\n",
    "        rgbdc = o3d.geometry.RGBDImage.create_from_color_and_depth(\n",
    "        last_frame.color, last_frame.depth, depth_trunc=4.0, convert_rgb_to_intensity=False)\n",
    "      \n",
    "        volume = o3d.pipelines.integration.ScalableTSDFVolume(\n",
    "                    voxel_length= 4.0/ 512.0,\n",
    "                    sdf_trunc=0.4,\n",
    "                    color_type=o3d.pipelines.integration.TSDFVolumeColorType.RGB8)\n",
    "\n",
    "        volume.integrate(\n",
    "            rgbdc, # rgbdc originally - trying with masked_rgbd\n",
    "            camera_intrinsics,\n",
    "            np.eye(4),\n",
    "        )\n",
    "    #         pcd_raw = backproject_o3d(last_frame,camera_intrinsics)\n",
    "        pcd_tsdf = volume.extract_point_cloud()\n",
    "        # First eliminate flying pixels before integrating the depth map\n",
    "        result_mask = numba_eliminate_flying_pixels(depth_image_array.copy(), ws, flying_pixel_filter_threshold)\n",
    "        depth_image_array[result_mask > flying_pixel_filter_threshold] = 0\n",
    "        # Re-insert filtered depth into the rgbd image\n",
    "        last_frame.depth = o3d.geometry.Image(depth_image_array)\n",
    "\n",
    "        # Apply maskrcnn to filtered depth image\n",
    "        masked_rgbd = segment_images_modified(last_frame)\n",
    "        # necessary lol\n",
    "        rgbdc = o3d.geometry.RGBDImage.create_from_color_and_depth(\n",
    "        masked_rgbd.color, masked_rgbd.depth, depth_trunc=4.0, convert_rgb_to_intensity=False)\n",
    "        pcd_tmp = o3d.geometry.PointCloud.create_from_rgbd_image(rgbdc,\n",
    "                                                            camera_intrinsics)\n",
    "        pcds.append(pcd_tmp)\n",
    "        pcds_tsdf.append(pcd_tsdf)\n",
    "\n",
    "\n",
    "    return pcds,pcds_tsdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e937a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(pcds)):\n",
    "    o3d.visualization.draw_geometries([ptsdf1[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f7b32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d.visualization.draw_geometries(pcds1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c941325",
   "metadata": {},
   "outputs": [],
   "source": [
    "tform_path = '/home/vigir3d/Datasets/cattle_scans/farm_07_24/Animal_calib/'\n",
    "tforms = load_calibration(tform_path,5)\n",
    "\n",
    "files_raw = glob.glob(data_path+'/*.mkv')\n",
    "abspath = data_path\n",
    "files = filter_file_names(files_raw)\n",
    "files.sort()\n",
    "\n",
    "list_size = len(files)\n",
    "rgbd_frames_glob = [None] * list_size\n",
    "camera_intrinsics_glob = [None] * list_size\n",
    "NUM_PROCESSES =4\n",
    "with Pool(processes=NUM_PROCESSES) as pool:\n",
    "    pool.map(process_file, range(len(files)))\n",
    "s1 = time.time()\n",
    "pcds, ptsdf = load_filter_pcds_par(data_path,tforms)\n",
    "s2 = time.time()\n",
    "\n",
    "\n",
    "s3 = time.time()\n",
    "pcds1, ptsdf1 = load_filter_pcds(data_path,tforms)\n",
    "s4 = time.time()\n",
    "\n",
    "print(\"par took: \", s2-s1, \"s\")\n",
    "print(\"regular took: \", s4-s3, \"s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e61b56e",
   "metadata": {},
   "source": [
    "# This works!!! 5:19AM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5c7650",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "def process_file(i):\n",
    "    #ws = 2\n",
    "    #flying_pixel_filter_threshold = 1000\n",
    "    #print(multiprocessing.current_process())\n",
    "    inFile = files[i]\n",
    "    fname = inFile.split('/')[-1]\n",
    "    file_name = fname.split('.mkv')[0]\n",
    "    \n",
    "    reader = o3d.io.AzureKinectMKVReader()\n",
    "    reader.open(inFile)\n",
    "    \n",
    "    if not reader.is_opened():\n",
    "        raise RuntimeError(\"Unable to open file {}\".format(inFile))\n",
    "    \n",
    "    metadata = reader.get_metadata()\n",
    "\n",
    "    # write the metadata to a JSON file since that seems to be the only\n",
    "    # way to retrieve that data\n",
    "    o3d.io.write_azure_kinect_mkv_metadata('{}/{}_intrinsic.json'.format(abspath, file_name), metadata)\n",
    "\n",
    "    # Open the file and load the JSON\n",
    "    with open(abspath + \"/\" + file_name + \"_intrinsic.json\") as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    height = data['height']\n",
    "    width = data['width']\n",
    "    intrinsics = data[\"intrinsic_matrix\"]\n",
    "    time_stamp = data[\"stream_length_usec\"]\n",
    "\n",
    "    camera_intrinsics = o3d.camera.PinholeCameraIntrinsic()\n",
    "    cx = intrinsics[6]\n",
    "    cy = intrinsics[7]\n",
    "    fx = intrinsics[0]\n",
    "    fy = intrinsics[4]\n",
    "    camera_intrinsics.set_intrinsics(width, height, fx, fy, cx, cy)\n",
    "    K = np.array([width,height,fx,fy,cx,cy])\n",
    "    last_frame = None\n",
    "    while not reader.is_eof():\n",
    "        rgbda = reader.next_frame()\n",
    "        if rgbda is None:\n",
    "            continue\n",
    "        last_frame = rgbda\n",
    "\n",
    "    if last_frame is not None:\n",
    "        #print(\"************No valid frames found in the .mkv file.**********\")\n",
    "    \n",
    "        print(\"Got last_frame\")\n",
    "        #return last_frame\n",
    "    else:\n",
    "        print(\"************No valid frames found in the .mkv file.**********\")\n",
    "        #return None\n",
    "    \n",
    "    reader.close()\n",
    "    #print(last_frame)\n",
    "    #print((np.array(last_frame.color)).dtype)\n",
    "    #print((np.array(last_frame.depth)).dtype)\n",
    "    return [np.array(last_frame.color), np.array(last_frame.depth), K]\n",
    "\n",
    "def process_single_frame(single_frame):\n",
    "    ws = 2\n",
    "    flying_pixel_filter_threshold = 1000\n",
    "    color_np = single_frame[0]\n",
    "    depth_np = single_frame[1]\n",
    "    K = single_frame[2]\n",
    "    \n",
    "    depth_np = pad_depth_to_color(depth_np, color_np)\n",
    "\n",
    "    depth_o3d = o3d.geometry.Image(np.ascontiguousarray(depth_np))\n",
    "    color_o3d = o3d.geometry.Image(np.ascontiguousarray(color_np))\n",
    "\n",
    "    rgbdc = o3d.geometry.RGBDImage.create_from_color_and_depth(\n",
    "                color_o3d, depth_o3d, depth_trunc=4.0, convert_rgb_to_intensity=False)\n",
    "    \n",
    "    camera_intrinsics = o3d.camera.PinholeCameraIntrinsic()\n",
    "    camera_intrinsics.set_intrinsics(int(K[0]),int(K[1]),K[2],K[3],K[4],K[5])\n",
    "\n",
    "    volume = o3d.pipelines.integration.ScalableTSDFVolume(\n",
    "                    voxel_length= 4.0/ 512.0,\n",
    "                    sdf_trunc=0.4,\n",
    "                    color_type=o3d.pipelines.integration.TSDFVolumeColorType.RGB8)\n",
    "\n",
    "    volume.integrate(\n",
    "        rgbdc, \n",
    "        camera_intrinsics,\n",
    "        np.eye(4),\n",
    "    )\n",
    "    pcd_tsdf = volume.extract_point_cloud()\n",
    "    result_mask = numba_eliminate_flying_pixels(depth_np.copy(), ws, flying_pixel_filter_threshold)\n",
    "    depth_np[result_mask > flying_pixel_filter_threshold] = 0\n",
    "    # Re-insert filtered depth into the rgbd image\n",
    "    rgbdc.depth = o3d.geometry.Image(depth_np)\n",
    "\n",
    "    # Apply maskrcnn to filtered depth image\n",
    "    masked_rgbd = segment_images_modified(rgbdc)\n",
    "    # necessary lol\n",
    "    rgbdc_new = o3d.geometry.RGBDImage.create_from_color_and_depth(\n",
    "                    masked_rgbd.color, masked_rgbd.depth, depth_trunc=4.0, convert_rgb_to_intensity=False)\n",
    "    pcd_tmp = o3d.geometry.PointCloud.create_from_rgbd_image(rgbdc_new,\n",
    "                                                        camera_intrinsics)\n",
    "\n",
    "    return pcd_tmp, pcd_tsdf\n",
    "\n",
    "tform_path = '/home/vigir3d/Datasets/cattle_scans/farm_07_24/Animal_calib/'\n",
    "tforms = load_calibration(tform_path,5)\n",
    "\n",
    "files_raw = glob.glob(data_path+'/*.mkv')\n",
    "abspath = data_path\n",
    "files = filter_file_names(files_raw)\n",
    "files.sort()\n",
    "o3d.utility.set_verbosity_level(o3d.utility.VerbosityLevel.Error)\n",
    "\n",
    "NUM_PROCESSES = 4\n",
    "s = time.time()\n",
    "\n",
    "\n",
    "# Read the mkv\n",
    "read1 = time.time()\n",
    "with Pool(processes=NUM_PROCESSES) as pool:\n",
    "    rgbd_np =  pool.map(process_file, range(len(files)))\n",
    "\n",
    "read2 = time.time()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Assuming rgbd_np is a list of frames\n",
    "t1 = time.time()\n",
    "pcds, pcds_tsdf = zip(*[process_single_frame(frame) for frame in rgbd_np])\n",
    "t2 = time.time()\n",
    "\n",
    "# registration\n",
    "r1 = time.time()\n",
    "pcd_all, ptsdf_all = perform_pairwise_alignment_par(ptsdf,pcds)\n",
    "r2 = time.time()\n",
    "\n",
    "p1 = time.time()\n",
    "pcd_all.estimate_normals()\n",
    "# cluster first to remove extra noise\n",
    "pcd_clustered = cluster_point_cloud_new(pcd_all)\n",
    "# After clustering, we upsample from the initial\n",
    "p2 = time.time()\n",
    "\n",
    "u1 = time.time()\n",
    "pcd_upsampled = upsample_using_reference_normals_new(pcd_clustered, ptsdf_all)\n",
    "u2 = time.time()\n",
    "\n",
    "tn1 = time.time()\n",
    "pcd_downsampled = pcd_upsampled.voxel_down_sample(0.01)\n",
    "#pcd_downsampled.orient_normals_towards_camera_location()\n",
    "pcd_downsampled.orient_normals_consistent_tangent_plane(30)\n",
    "tn2 = time.time()\n",
    "\n",
    "m1 = time.time()\n",
    "with o3d.utility.VerbosityContextManager(o3d.utility.VerbosityLevel.Error) as cm:\n",
    "        mesh, densities = o3d.geometry.TriangleMesh.create_from_point_cloud_poisson(pcd_downsampled, depth=6)\n",
    "\n",
    "sa = mesh.get_surface_area()\n",
    "if(mesh.is_watertight()):\n",
    "    #print(\"Is watertight 1\")\n",
    "    v =  mesh.get_volume()\n",
    "else : \n",
    "    v = 0.0\n",
    "m2 = time.time()\n",
    "animal_id = os.path.basename(os.path.normpath(data_path))\n",
    "save_results(animal_id, data_path, mesh, pcd_downsampled, sa, v)\n",
    "\n",
    "e = time.time()\n",
    "\n",
    "print(\"Total time: \", e-s, \" s\")\n",
    "\n",
    "\n",
    "print(\"Read mkvs: \", read2-read1, \" s\")\n",
    "print(\"Create and segment PCDS: \", t2-t1, \" s\")\n",
    "\n",
    "print(\"Register: \", l2-l1, \" s\")\n",
    "\n",
    "print(\"Preprocess: \", p2-p1, \" s\")\n",
    "\n",
    "print(\"Upsampling: \", u2-u1, \" s\")\n",
    "print(\"Normal orientation: \", tn2-tn1, \" s\")    \n",
    "print(\"Meshing: \", m2-m1, \" s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b309e3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = o3d.io.read_point_cloud(\"/home/vigir3d/Datasets/cattle_scans/farm_07_28/Animal_c1/c1_cleaned.ply\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba76ace5",
   "metadata": {},
   "outputs": [],
   "source": [
    "p.orient_normals_consistent_tangent_plane(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d975c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d.io.write_point_cloud(\"/home/vigir3d/Datasets/cattle_scans/farm_07_28/Animal_c1/c1_cleaned_normals_oriented.ply\",p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d31200",
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d.visualization.draw_geometries([p])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ffc9bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pcd_demo_cow_path  = '/home/vigir3d/Datasets/cattle_scans/FirstOne/'\n",
    "pcd_demo_cow = o3d.io.read_point_cloud(pcd_demo_cow_path+'registered_cow_cleaned.ply')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92fea78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pcd_demo_cow.estimate_normals()\n",
    "pcd_demo_cow.orient_normals_consistent_tangent_plane(30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce42b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d.io.write_point_cloud(pcd_demo_cow_path+\"registered_cow_corrected_normals.ply\", pcd_demo_cow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f882b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d.visualization.draw_geometries([pcd_demo_cow])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41b76c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "intrinsics[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906ca12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dpath = '/home/vigir3d/Datasets/cattle_scans/farm_scan1/Animal_482_2/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46799e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#dpath = '/home/vigir3d/Datasets/cattle_scans/farm_07_28/Animal_box3_u/'\n",
    "depth = o3d.io.read_image(dpath + 'Animal_box3_u_nano_11_depth.png')\n",
    "color = o3d.io.read_image(dpath + 'Animal_box3_u_nano_11.jpg')\n",
    "K = np.loadtxt(dpath+\"Animal_box3_u_nano_11_intrinsics.txt\")\n",
    "\n",
    "camera_intrinsics = o3d.camera.PinholeCameraIntrinsic()\n",
    "camera_intrinsics.set_intrinsics(int(K[0]),int(K[1]),K[2],K[3],K[4],K[5])\n",
    "\n",
    "rgbdc = o3d.geometry.RGBDImage.create_from_color_and_depth(\n",
    "        color, depth, depth_trunc=4.0, convert_rgb_to_intensity=False)\n",
    "\n",
    "volume = o3d.pipelines.integration.ScalableTSDFVolume(\n",
    "            voxel_length= 4.0/ 512.0,\n",
    "            sdf_trunc=0.04,\n",
    "            color_type=o3d.pipelines.integration.TSDFVolumeColorType.RGB8)\n",
    "\n",
    "volume.integrate(\n",
    "    rgbdc,\n",
    "    camera_intrinsics,\n",
    "    np.eye(4),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177c232e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dpath = '/home/vigir3d/Datasets/cattle_scans/farm_scan1/Animal_482_2/'\n",
    "\n",
    "# Remove the trailing slash if it exists\n",
    "\n",
    "\n",
    "\n",
    "depth_image_array = np.asarray(last_frame.depth)\n",
    "        rgbdc = o3d.geometry.RGBDImage.create_from_color_and_depth(\n",
    "        last_frame.color, last_frame.depth, depth_trunc=4.0, convert_rgb_to_intensity=False)\n",
    "        volume = o3d.pipelines.integration.ScalableTSDFVolume(\n",
    "                    voxel_length= 4.0/ 512.0,\n",
    "                    sdf_trunc=0.4,\n",
    "                    color_type=o3d.pipelines.integration.TSDFVolumeColorType.RGB8)\n",
    "\n",
    "        volume.integrate(\n",
    "            rgbdc, # rgbdc originally - trying with masked_rgbd\n",
    "            camera_intrinsics,\n",
    "            np.eye(4),\n",
    "        )\n",
    "#         pcd_raw = backproject_o3d(last_frame,camera_intrinsics)\n",
    "        pcd_tsdf = volume.extract_point_cloud()\n",
    "        # First eliminate flying pixels before integrating the depth map\n",
    "        result_mask = numba_eliminate_flying_pixels(depth_image_array.copy(), ws, flying_pixel_filter_threshold)\n",
    "        depth_image_array[result_mask > flying_pixel_filter_threshold] = 0\n",
    "        # Re-insert filtered depth into the rgbd image\n",
    "        last_frame.depth = o3d.geometry.Image(depth_image_array)\n",
    "      \n",
    "        # Apply maskrcnn to filtered depth image\n",
    "        masked_rgbd = segment_images_modified(last_frame)\n",
    "        # necessary lol\n",
    "        rgbdc = o3d.geometry.RGBDImage.create_from_color_and_depth(\n",
    "        masked_rgbd.color, masked_rgbd.depth, depth_trunc=4.0, convert_rgb_to_intensity=False)\n",
    "        pcd_tmp = o3d.geometry.PointCloud.create_from_rgbd_image(rgbdc,\n",
    "                                                            camera_intrinsics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4232164",
   "metadata": {},
   "source": [
    "# Latest Working Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9456e2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dpath = '/home/vigir3d/Datasets/cattle_scans/farm_scan1/Animal_482_2/'\n",
    "def process_file_list_comp(file_id, dpath):\n",
    "    ws = 2\n",
    "    flying_pixel_filter_threshold = 0.1\n",
    "    # Format filenames\n",
    "    dpath = dpath.rstrip('/')\n",
    "\n",
    "    # Split by the directory separator and get the last part\n",
    "    suffix = os.path.basename(dpath)\n",
    "    \n",
    "    file_suffix = suffix + \"_nano_\" + str(file_id)\n",
    "    # Construct full file paths using os.path.join for better cross-platform compatibility\n",
    "    depth_file = os.path.join(dpath, file_suffix + \"_depth.png\")\n",
    "    color_file = os.path.join(dpath, file_suffix + \".jpg\")\n",
    "    intrinsics_file = os.path.join(dpath, file_suffix + \"_intrinsics.txt\")\n",
    "    # Read the files\n",
    "    depth = o3d.io.read_image(depth_file)\n",
    "    color = o3d.io.read_image(color_file)\n",
    "    #depth = o3d.io.read_image(dpath + 'Animal_box3_u_nano_11_depth.png')\n",
    "    #color = o3d.io.read_image(dpath + 'Animal_box3_u_nano_11.jpg')\n",
    "    K = np.loadtxt(intrinsics_file)\n",
    "      \n",
    "\n",
    "    camera_intrinsics = o3d.camera.PinholeCameraIntrinsic()\n",
    "    camera_intrinsics.set_intrinsics(int(K[0]), int(K[1]), K[2], K[3], K[4], K[5])\n",
    "\n",
    "    rgbdc = o3d.geometry.RGBDImage.create_from_color_and_depth(\n",
    "        color, depth, depth_trunc=4.0, convert_rgb_to_intensity=False\n",
    "    )\n",
    "\n",
    "    volume = o3d.pipelines.integration.ScalableTSDFVolume(\n",
    "        voxel_length=4.0 / 512.0, sdf_trunc=0.04, color_type=o3d.pipelines.integration.TSDFVolumeColorType.RGB8\n",
    "    )\n",
    "\n",
    "    volume.integrate(rgbdc, camera_intrinsics, np.eye(4))\n",
    "    pcd_tsdf = volume.extract_point_cloud()\n",
    "    depth_np = np.asarray(rgbdc.depth)\n",
    "    result_mask = numba_eliminate_flying_pixels(depth_np.copy(), ws, flying_pixel_filter_threshold)\n",
    "    depth_np[result_mask > flying_pixel_filter_threshold] = 0\n",
    "    # Re-insert filtered depth into the rgbd image\n",
    "    rgbdc.depth = o3d.geometry.Image(depth_np)\n",
    "    # Apply maskrcnn to filtered depth image\n",
    "    masked_rgbd = segment_images_modified(rgbdc)\n",
    "    # necessary lol\n",
    "    rgbdc_new = o3d.geometry.RGBDImage.create_from_color_and_depth(\n",
    "                    masked_rgbd.color, masked_rgbd.depth, depth_trunc=4.0, convert_rgb_to_intensity=False)\n",
    "    pcd_tmp = o3d.geometry.PointCloud.create_from_rgbd_image(rgbdc_new,\n",
    "                                                        camera_intrinsics)\n",
    "    return pcd_tsdf, pcd_tmp \n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    dpath = '/home/vigir3d/Datasets/cattle_scans/farm_scan1/Animal_482_2/'\n",
    "    file_ids = [11,12,14,16,17,18]  # exclude head cameras\n",
    "\n",
    "    # Generate a list of volumes using list comprehension\n",
    "    start = time.time()\n",
    "    results = [process_file_list_comp(file_id, dpath) for file_id in file_ids]\n",
    "    ptsdf, pcds = zip(*results)\n",
    "    l = False\n",
    "    if l :\n",
    "        pcd_all, ptsdf_all = perform_pairwise_alignment(ptsdf,pcds)\n",
    "        pcd_all.estimate_normals()\n",
    "        pcd_clustered = cluster_point_cloud_new(pcd_all)\n",
    "        pcd_upsampled = upsample_using_reference_normals_new(pcd_clustered, ptsdf_all)\n",
    "        pcd_downsampled = pcd_upsampled.voxel_down_sample(0.01)\n",
    "        pcd_downsampled.orient_normals_consistent_tangent_plane(30)\n",
    "        with o3d.utility.VerbosityContextManager(o3d.utility.VerbosityLevel.Error) as cm:\n",
    "            mesh, densities = o3d.geometry.TriangleMesh.create_from_point_cloud_poisson(pcd_downsampled, depth=6)\n",
    "\n",
    "        sa = mesh.get_surface_area()\n",
    "        if(mesh.is_watertight()):\n",
    "            #print(\"Is watertight 1\")\n",
    "            v =  mesh.get_volume()\n",
    "        else : \n",
    "            v = 0.0\n",
    "        animal_id = os.path.basename(os.path.normpath(data_path))\n",
    "        save_results(animal_id, data_path, mesh, pcd_downsampled, sa, v)\n",
    "\n",
    "\n",
    "    end = time.time()\n",
    "\n",
    "    print(\"Duration was:\", end-start, \"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa5c2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(pcds)):\n",
    "    o3d.visualization.draw_geometries([pcds[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6893f4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = time.time()\n",
    "pcd_all, ptsdf_all = perform_pairwise_alignment(ptsdf,pcds)\n",
    "pcd_all.estimate_normals()\n",
    "pcd_clustered = cluster_point_cloud_new(pcd_all)\n",
    "\n",
    "s2 = time.time()\n",
    "\n",
    "print(\"duration: \", s2-s1, \"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aba2287",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(pcds)):\n",
    "    o3d.visualization.draw_geometries([ptsdf[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9698ff77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_pairwise_alignment(pcds_tsdf,pcds_cropped):\n",
    "    #\"\"\"Compute and apply transformations.\"\"\"\n",
    "    t01 = colored_ICP(pcds_tsdf[0], pcds_tsdf[1])\n",
    "    t52 = colored_ICP(pcds_tsdf[5], pcds_tsdf[2])\n",
    "    t43 = colored_ICP(pcds_tsdf[4], pcds_tsdf[3])\n",
    "    t12 = colored_ICP(pcds_tsdf[1], pcds_tsdf[2])\n",
    "    t32 = colored_ICP(pcds_tsdf[3], pcds_tsdf[2])\n",
    "\n",
    "    H0 = t12 @ t01\n",
    "    H1 = t12\n",
    "    H3 = t32\n",
    "    H4 = t32 @ t43\n",
    "    H5 = t52\n",
    "\n",
    "    # Transform the point clouds\n",
    "    p0 = copy.deepcopy(pcds_cropped[0]).transform(H0)\n",
    "    p1 = copy.deepcopy(pcds_cropped[1]).transform(H1)\n",
    "    p3 = copy.deepcopy(pcds_cropped[3]).transform(H3)\n",
    "    p4 = copy.deepcopy(pcds_cropped[4]).transform(H4)\n",
    "    p5 = copy.deepcopy(pcds_cropped[5]).transform(H5)\n",
    "    \n",
    "    d0 = copy.deepcopy(pcds_tsdf[0]).transform(H0)\n",
    "    d1 = copy.deepcopy(pcds_tsdf[1]).transform(H1)\n",
    "    d3 = copy.deepcopy(pcds_tsdf[3]).transform(H3)\n",
    "    d4 = copy.deepcopy(pcds_tsdf[4]).transform(H4)\n",
    "    d5 = copy.deepcopy(pcds_tsdf[5]).transform(H5)\n",
    "    \n",
    "    pcd_combined = o3d.geometry.PointCloud()\n",
    "    pcd_combined = p0+p1+pcds_cropped[2]+p3+p4+p5\n",
    "    \n",
    "    ptsdf_combined = o3d.geometry.PointCloud()\n",
    "    ptsdf_combined = d0+d1+pcds_tsdf[2]+d3+d4+d5\n",
    "\n",
    "    return pcd_combined, ptsdf_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f1b3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming rgbd_np is a list of frames\n",
    "t1 = time.time()\n",
    "pcds, pcds_tsdf = zip(*[process_single_frame(frame) for frame in rgbd_np])\n",
    "t2 = time.time()\n",
    "\n",
    "# registration\n",
    "r1 = time.time()\n",
    "pcd_all, ptsdf_all = perform_pairwise_alignment_par(ptsdf,pcds)\n",
    "r2 = time.time()\n",
    "\n",
    "p1 = time.time()\n",
    "pcd_all.estimate_normals()\n",
    "# cluster first to remove extra noise\n",
    "pcd_clustered = cluster_point_cloud_new(pcd_all)\n",
    "# After clustering, we upsample from the initial\n",
    "p2 = time.time()\n",
    "\n",
    "u1 = time.time()\n",
    "pcd_upsampled = upsample_using_reference_normals_new(pcd_clustered, ptsdf_all)\n",
    "u2 = time.time()\n",
    "\n",
    "tn1 = time.time()\n",
    "pcd_downsampled = pcd_upsampled.voxel_down_sample(0.01)\n",
    "#pcd_downsampled.orient_normals_towards_camera_location()\n",
    "pcd_downsampled.orient_normals_consistent_tangent_plane(30)\n",
    "tn2 = time.time()\n",
    "\n",
    "m1 = time.time()\n",
    "with o3d.utility.VerbosityContextManager(o3d.utility.VerbosityLevel.Error) as cm:\n",
    "        mesh, densities = o3d.geometry.TriangleMesh.create_from_point_cloud_poisson(pcd_downsampled, depth=6)\n",
    "\n",
    "sa = mesh.get_surface_area()\n",
    "if(mesh.is_watertight()):\n",
    "    #print(\"Is watertight 1\")\n",
    "    v =  mesh.get_volume()\n",
    "else : \n",
    "    v = 0.0\n",
    "m2 = time.time()\n",
    "animal_id = os.path.basename(os.path.normpath(data_path))\n",
    "save_results(animal_id, data_path, mesh, pcd_downsampled, sa, v)\n",
    "\n",
    "e = time.time()\n",
    "\n",
    "print(\"Total time: \", e-s, \" s\")\n",
    "\n",
    "\n",
    "print(\"Read mkvs: \", read2-read1, \" s\")\n",
    "print(\"Create and segment PCDS: \", t2-t1, \" s\")\n",
    "\n",
    "print(\"Register: \", l2-l1, \" s\")\n",
    "\n",
    "print(\"Preprocess: \", p2-p1, \" s\")\n",
    "\n",
    "print(\"Upsampling: \", u2-u1, \" s\")\n",
    "print(\"Normal orientation: \", tn2-tn1, \" s\")    \n",
    "print(\"Meshing: \", m2-m1, \" s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d9960a",
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d.visualization.draw_geometries([pcds[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e4d2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pcds_tsdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2680e883",
   "metadata": {},
   "outputs": [],
   "source": [
    " file_ids = range(11, 17) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4e261b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "p = segment_images_modified(rgbadc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949d4b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_images_modified(last_frame):\n",
    "    depth_PIL = Image.fromarray(np.asarray(last_frame.depth)).convert(\"RGB\")\n",
    "    rgb_image_array = np.asarray(last_frame.color)\n",
    "    depth_image_array = np.asarray(last_frame.depth)\n",
    "    rgb_PIL = Image.fromarray(rgb_image_array)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    rgb_mask = get_model_mask(model_rgb, rgb_PIL)\n",
    "    depth_mask = get_model_mask(model_depth, depth_PIL)\n",
    "\n",
    "    if depth_mask.nelement() == 0:\n",
    "        mask_combined = rgb_mask\n",
    "    else:\n",
    "        mask_combined = depth_mask | rgb_mask  # 1 vote arbitration (OR the masks)\n",
    "\n",
    "    # Convert tensor to numpy array and ensure the right datatype\n",
    "\n",
    "    mask_combined = mask_combined.numpy().astype(rgb_image_array.dtype)\n",
    "    mask_image = mask_combined.swapaxes(0, 2).swapaxes(0, 1)\n",
    "    mask_image = (mask_image > 0).astype(rgb_image_array.dtype)   \n",
    "\n",
    "    fg_image_rgb = rgb_image_array * mask_image\n",
    "\n",
    "    # For the depth image:\n",
    "    squeezed_mask = np.squeeze(mask_image)\n",
    "    fg_image_depth = depth_image_array * squeezed_mask\n",
    "    \n",
    "    last_frame.color = o3d.geometry.Image(fg_image_rgb)\n",
    "    last_frame.depth = o3d.geometry.Image(fg_image_depth)\n",
    "\n",
    "    return last_frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3aa630",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2715bc2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pcd = volume.extract_point_cloud()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8243ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pcd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3d3dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d.visualization.draw_geometries([pcd])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93e0275",
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "#import numpy as np\n",
    "#import open3d as o3d\n",
    "from functools import partial\n",
    "\n",
    "\n",
    "def wrapper_colored_ICP(args, function):\n",
    "    return function(args[0], args[1], args[2], args[3])\n",
    "\n",
    "def perform_pairwise_alignment_par(pcds_tsdf, pcds_cropped):\n",
    "    \"\"\"Compute and apply transformations.\"\"\"\n",
    "\n",
    "    # Extracting points and colors as numpy arrays\n",
    "    points = [np.asarray(p.points) for p in pcds_tsdf]\n",
    "    colors = [np.asarray(p.colors) for p in pcds_tsdf]\n",
    "\n",
    "    # Passing tuples to the executor.map function\n",
    "    with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "        # Use partial to pass colored_ICP as the function to be called by wrapper_colored_ICP\n",
    "        wrapped_func = partial(wrapper_colored_ICP, function=colored_ICP_par)\n",
    "        \n",
    "        transformations = list(executor.map(wrapped_func, [(points[0], colors[0], points[1], colors[1]),\n",
    "                                                           (points[5], colors[5], points[2], colors[2]),\n",
    "                                                           (points[4], colors[4], points[3], colors[3]),\n",
    "                                                           (points[1], colors[1], points[2], colors[2]),\n",
    "                                                           (points[3], colors[3], points[2], colors[2])]))\n",
    "\n",
    "    t01, t52, t43, t12, t32 = transformations\n",
    "\n",
    "    H0 = np.dot(t12, t01)\n",
    "    H1 = t12\n",
    "    H3 = t32\n",
    "    H4 = np.dot(t32, t43)\n",
    "    H5 = t52\n",
    "\n",
    "    # Transform the point clouds directly using Open3D\n",
    "    p0 = pcds_cropped[0].transform(H0)\n",
    "    p1 = pcds_cropped[1].transform(H1)\n",
    "    p3 = pcds_cropped[3].transform(H3)\n",
    "    p4 = pcds_cropped[4].transform(H4)\n",
    "    p5 = pcds_cropped[5].transform(H5)\n",
    "    \n",
    "    d0 = pcds_tsdf[0].transform(H0)\n",
    "    d1 = pcds_tsdf[1].transform(H1)\n",
    "    d3 = pcds_tsdf[3].transform(H3)\n",
    "    d4 = pcds_tsdf[4].transform(H4)\n",
    "    d5 = pcds_tsdf[5].transform(H5)\n",
    "    \n",
    "    pcd_combined = p0 + p1 + pcds_cropped[2] + p3 + p4 + p5\n",
    "    ptsdf_combined = d0 + d1 + pcds_tsdf[2] + d3 + d4 + d5\n",
    "\n",
    "    return pcd_combined, ptsdf_combined\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7626f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "import copy\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "\n",
    "def colored_ICP_par(src_pts, src_c, tgt_pts, tgt_c):\n",
    "    \n",
    "    source = o3d.geometry.PointCloud()\n",
    "    source.points = o3d.utility.Vector3dVector(src_pts)\n",
    "    source.colors =  o3d.utility.Vector3dVector(src_c)\n",
    "    \n",
    "    target = o3d.geometry.PointCloud()\n",
    "\n",
    "    target.points = o3d.utility.Vector3dVector(tgt_pts)\n",
    "    target.colors =  o3d.utility.Vector3dVector(tgt_c)\n",
    "    \n",
    "    voxel_radius = [0.04, 0.02, 0.01]\n",
    "    max_iter = [50, 30, 14]\n",
    "    current_transformation = np.identity(4)\n",
    "    #print(\"3. Colored point cloud registration\")\n",
    "    for scale in range(3):\n",
    "        iters = max_iter[scale]\n",
    "        radius = voxel_radius[scale]\n",
    "        #print(\"iteration: \", iters, radius, scale)\n",
    "\n",
    "        #print(\"3-1. Downsample with a voxel size %.2f\" % radius)\n",
    "        source_down = source.voxel_down_sample(radius)\n",
    "        target_down = target.voxel_down_sample(radius)\n",
    "\n",
    "        #print(\"3-2. Estimate normal.\")\n",
    "        source_down.estimate_normals(\n",
    "            o3d.geometry.KDTreeSearchParamHybrid(radius=radius * 2, max_nn=30))\n",
    "        target_down.estimate_normals(\n",
    "            o3d.geometry.KDTreeSearchParamHybrid(radius=radius * 2, max_nn=30))\n",
    "\n",
    "        #print(\"3-3. Applying colored point cloud registration\")\n",
    "        result_icp = o3d.pipelines.registration.registration_colored_icp(\n",
    "            source_down, target_down, radius, current_transformation,\n",
    "            o3d.pipelines.registration.TransformationEstimationForColoredICP(),\n",
    "            o3d.pipelines.registration.ICPConvergenceCriteria(relative_fitness=1e-6,\n",
    "                                                              relative_rmse=1e-6,\n",
    "                                                              max_iteration=iters))\n",
    "        current_transformation = np.array(result_icp.transformation)\n",
    "        \n",
    "        return current_transformation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d672a56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_pairwise_alignment_par(pcds_tsdf, pcds_cropped):\n",
    "    \"\"\"Compute and apply transformations.\"\"\"\n",
    "\n",
    "    # Extracting points and colors as numpy arrays\n",
    "    points = [np.asarray(p.points) for p in pcds_tsdf]\n",
    "    colors = [np.asarray(p.colors) for p in pcds_tsdf]\n",
    "\n",
    "    # Defining a helper function to unpack and call colored_ICP\n",
    "    def wrapper(args):\n",
    "        return colored_ICP(args[0], args[1], args[2], args[3])\n",
    "\n",
    "    # Passing tuples to the executor.map function\n",
    "    with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "        transformations = list(executor.map(wrapper, [(points[0], colors[0], points[1], colors[1]),\n",
    "                                                      (points[5], colors[5], points[2], colors[2]),\n",
    "                                                      (points[4], colors[4], points[3], colors[3]),\n",
    "                                                      (points[1], colors[1], points[2], colors[2]),\n",
    "                                                      (points[3], colors[3], points[2], colors[2])]))\n",
    "\n",
    "    t01, t52, t43, t12, t32 = transformations\n",
    "\n",
    "    H0 = np.dot(t12, t01)\n",
    "    H1 = t12\n",
    "    H3 = t32\n",
    "    H4 = np.dot(t32, t43)\n",
    "    H5 = t52\n",
    "\n",
    "    # Transform the point clouds directly using Open3D\n",
    "    p0 = pcds_cropped[0].transform(H0)\n",
    "    p1 = pcds_cropped[1].transform(H1)\n",
    "    p3 = pcds_cropped[3].transform(H3)\n",
    "    p4 = pcds_cropped[4].transform(H4)\n",
    "    p5 = pcds_cropped[5].transform(H5)\n",
    "    \n",
    "    d0 = pcds_tsdf[0].transform(H0)\n",
    "    d1 = pcds_tsdf[1].transform(H1)\n",
    "    d3 = pcds_tsdf[3].transform(H3)\n",
    "    d4 = pcds_tsdf[4].transform(H4)\n",
    "    d5 = pcds_tsdf[5].transform(H5)\n",
    "    \n",
    "    pcd_combined = p0 + p1 + pcds_cropped[2] + p3 + p4 + p5\n",
    "    ptsdf_combined = d0 + d1 + pcds_tsdf[2] + d3 + d4 + d5\n",
    "\n",
    "    return pcd_combined, ptsdf_combined\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2294b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rgbd_frames_glob[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73f9036",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_point_cloud_new(outlier_cloud):\n",
    "    cloud_colors = copy.deepcopy(np.asarray(outlier_cloud.colors).T)\n",
    "    \n",
    "    with o3d.utility.VerbosityContextManager(o3d.utility.VerbosityLevel.Error) as cm:\n",
    "        labels = np.array(outlier_cloud.cluster_dbscan(eps=0.1, min_points=10, print_progress=False))\n",
    "\n",
    "    # Identify the largest cluster\n",
    "    values, counts = np.unique(labels, return_counts=True)\n",
    "    ind = np.argmax(counts)\n",
    "    largest_cluster_label = values[ind]\n",
    "    #print(f\"Largest cluster label: {largest_cluster_label}\")\n",
    "\n",
    "    # Filter points, normals, and colors for the largest cluster\n",
    "    cloud_xyz = pcd2xyz(outlier_cloud)\n",
    "    cloud_normals = pcd2normals(outlier_cloud)\n",
    "\n",
    "    cloud_filtered = cloud_xyz[:, labels == largest_cluster_label]\n",
    "    normals_filtered = cloud_normals[:, labels == largest_cluster_label]\n",
    "    colors_filtered = cloud_colors[:, labels == largest_cluster_label]\n",
    "\n",
    "    # Create a point cloud for the largest cluster\n",
    "    pcd_filtered_largest_cluster = o3d.geometry.PointCloud()\n",
    "    pcd_filtered_largest_cluster.points = o3d.utility.Vector3dVector(cloud_filtered.T)\n",
    "    pcd_filtered_largest_cluster.normals = o3d.utility.Vector3dVector(normals_filtered.T)\n",
    "    pcd_filtered_largest_cluster.colors = o3d.utility.Vector3dVector(colors_filtered.T)\n",
    "\n",
    "    #o3d.visualization.draw_geometries([pcd_filtered_largest_cluster])\n",
    "    return pcd_filtered_largest_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdaa689b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(pp.is_cuda)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36da0830",
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d.visualization.draw_geometries([pp.to_legacy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0486ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f51d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pp.orient_normals_consistent_tangent_plane(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd93271",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = time.time()\n",
    "pp.orient_normals_consistent_tangent_plane(30)\n",
    "t2 = time.time()\n",
    "\n",
    "t3 = time.time()\n",
    "pcd_all.orient_normals_consistent_tangent_plane(30)\n",
    "t4 = time.time()\n",
    "\n",
    "print(\"Tensor: \", t2-t1, \" s | legacy: \", t4-t3, \" s\" )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2886e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_point_cloud_tensor(pcd) :\n",
    "    colors = pcd.point.colors\n",
    "    with o3d.utility.VerbosityContextManager(\n",
    "            o3d.utility.VerbosityLevel.Debug) as cm:\n",
    "        labels = pcd.cluster_dbscan(eps=0.02, min_points=10, print_progress=False)\n",
    "        \n",
    "    \n",
    "    labels = labels.cpu()\n",
    "    # Identify the largest cluster\n",
    "    values, counts = np.unique(labels, return_counts=True)\n",
    "    ind = np.argmax(counts)\n",
    "    largest_cluster_label = values[ind]\n",
    "    #print(f\"Largest cluster label: {largest_cluster_label}\")\n",
    "\n",
    "    colors[labels < 0] = 0\n",
    "    pcd.point.colors = colors\n",
    "    return pcd\n",
    "#     o3d.visualization.draw_geometries([pcd.to_legacy()],\n",
    "#                                       zoom=0.455,\n",
    "#                                       front=[-0.4999, -0.1659, -0.8499],\n",
    "#                                       lookat=[2.1813, 2.0619, 2.0999],\n",
    "#                                       up=k[0.1204, -0.9852, 0.1215])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5307c0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsample_using_reference_normals_t(sparse_pcd_t, dense_pcd_t, search_radius=0.02, angle_threshold=30):\n",
    "    #device = o3d.core.Device(\"CUDA:0\")  # Assuming you have a CUDA GPU. Adjust as needed.\n",
    "\n",
    "    # Convert point clouds to tensor-based format and move to GPU\n",
    "    #sparse_pcd_t = o3d.t.geometry.PointCloud.from_legacy(sparse_pcd).to(device)\n",
    "    #dense_pcd_t = o3d.t.geometry.PointCloud.from_legacy(dense_pcd).to(device)\n",
    "\n",
    "    # Ensure point clouds have normals\n",
    "    #if sparse_pcd_t.point.normals is None:\n",
    "    sparse_pcd_t.estimate_normals()\n",
    "    #if dense_pcd_t.point.normals is None:\n",
    "    dense_pcd_t.estimate_normals()\n",
    "\n",
    "    kdtree_t = o3d.t.geometry.KDTreeFlann(dense_pcd_t)\n",
    "\n",
    "    upsampled_points = sparse_pcd_t.points.clone()\n",
    "\n",
    "    for i, point in enumerate(sparse_pcd_t.points):\n",
    "        [k, idx, _] = kdtree_t.search_radius_vector_3d(point, search_radius)\n",
    "        \n",
    "        neighbors = dense_pcd_t.points[idx]\n",
    "        neighbor_normals = dense_pcd_t.normals[idx]\n",
    "\n",
    "        # Calculate angles\n",
    "        dot_products = sparse_pcd_t.normals[i].dot(neighbor_normals.T)\n",
    "        angles = dot_products.acos().to(o3d.core.Dtype.Float32).asin() * (180.0 / np.pi)\n",
    "\n",
    "        # Filtering neighbors\n",
    "        valid_neighbors = neighbors[angles < angle_threshold]\n",
    "\n",
    "        upsampled_points = upsampled_points.append(valid_neighbors)\n",
    "\n",
    "    upsampled_pcd_t = o3d.t.geometry.PointCloud(device)\n",
    "    upsampled_pcd_t.point.positions = upsampled_points\n",
    "    upsampled_pcd_t.estimate_normals()\n",
    "\n",
    "    # Convert back to legacy format if needed\n",
    "    upsampled_pcd = upsampled_pcd_t.to_legacy()\n",
    "\n",
    "    return upsampled_pcd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd512fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_point_cloud_tensor(pcd) :\n",
    "    # Clustering the points\n",
    "    with o3d.utility.VerbosityContextManager(\n",
    "            o3d.utility.VerbosityLevel.Debug) as cm:\n",
    "        labels = pcd.cluster_dbscan(eps=0.02, min_points=10, print_progress=False)\n",
    "    \n",
    "    labels = labels.cpu().numpy()\n",
    "    \n",
    "    # Identify the largest cluster\n",
    "    values, counts = np.unique(labels, return_counts=True)\n",
    "    ind = np.argmax(counts)\n",
    "    largest_cluster_label = values[ind]\n",
    "\n",
    "    # Filter points belonging to the largest cluster\n",
    "    largest_cluster_points = pcd.point.positions[labels == largest_cluster_label]\n",
    "    \n",
    "\n",
    "    # Create a new point cloud tensor for the largest cluster\n",
    "    largest_cluster_pcd = o3d.t.geometry.PointCloud(largest_cluster_points)\n",
    "    largest_cluster_pcd.point.colors = pcd.point.colors[labels == largest_cluster_label]     \n",
    "    return largest_cluster_pcd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895f5f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "pcd_t.point.positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1577421f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial import cKDTree\n",
    "\n",
    "\n",
    "def upsample_using_reference_normals_new(sparse_pcd, dense_pcd, search_radius=0.02, angle_threshold=30):\n",
    "    # Ensure the point clouds have normals\n",
    "    if not sparse_pcd.has_normals():\n",
    "        sparse_pcd.estimate_normals()\n",
    "    if not dense_pcd.has_normals():\n",
    "        dense_pcd.estimate_normals()\n",
    "\n",
    "    dense_points = np.asarray(dense_pcd.points)\n",
    "    dense_tree = cKDTree(dense_points)\n",
    "\n",
    "    sparse_points = np.asarray(sparse_pcd.points)\n",
    "    sparse_normals = np.asarray(sparse_pcd.normals)\n",
    "    \n",
    "    # This retrieves the indices of all neighbors within the search_radius\n",
    "    neighbor_indices = dense_tree.query_ball_point(sparse_points, search_radius, workers=-1)\n",
    "    \n",
    "    valid_indices = []\n",
    "    for i, idx_row in enumerate(neighbor_indices):\n",
    "        neighbors = dense_points[idx_row]\n",
    "        neighbor_normals = np.asarray(dense_pcd.normals)[idx_row]\n",
    "\n",
    "        # Calculate angles between sparse point's normal and all its neighbors' normals\n",
    "        angles = np.degrees(np.arccos(np.clip(np.dot(sparse_normals[i], neighbor_normals.T), -1.0, 1.0)))\n",
    "\n",
    "        # Filtering neighbors based on angle threshold\n",
    "        valid_neighbor_indices = np.array(idx_row)[angles < angle_threshold]\n",
    "        valid_indices.extend(valid_neighbor_indices)\n",
    "#     valid_indices = []\n",
    "#     for i, idx_row in enumerate(neighbor_indices):\n",
    "#         neighbors = dense_points[idx_row]\n",
    "#         neighbor_normals = np.asarray(dense_pcd.normals)[idx_row]\n",
    "        \n",
    "#         # Calculate angles between sparse point's normal and all its neighbors' normals\n",
    "#         angles = np.degrees(np.arccos(np.clip(np.dot(sparse_normals[i], neighbor_normals.T), -1.0, 1.0)))\n",
    "\n",
    "#         # Filtering neighbors based on angle threshold\n",
    "#         valid_for_current = idx_row[angles < angle_threshold]\n",
    "#         valid_indices.extend(valid_for_current)\n",
    "\n",
    "    unique_valid_indices = np.unique(valid_indices)\n",
    "    final_valid_neighbors = dense_points[unique_valid_indices]\n",
    "    \n",
    "    upsampled_points = np.vstack([sparse_points, final_valid_neighbors])\n",
    "\n",
    "    upsampled_pcd = o3d.geometry.PointCloud()\n",
    "    upsampled_pcd.points = o3d.utility.Vector3dVector(upsampled_points)\n",
    "    upsampled_pcd.estimate_normals()\n",
    "\n",
    "    return upsampled_pcd\n",
    "\n",
    "\n",
    "def upsample_using_reference_normals(sparse_pcd, dense_pcd, search_radius=0.02, angle_threshold=30):\n",
    "    \"\"\"\n",
    "    Efficiently upsample the sparse point cloud using the dense point cloud as reference.\n",
    "    Considers the normals to ensure added points are consistent with the sparse cloud.\n",
    "\n",
    "    Parameters:\n",
    "    - sparse_pcd: The sparse point cloud\n",
    "    - dense_pcd: The dense reference point cloud\n",
    "    - search_radius: Radius to search for neighbors\n",
    "    - angle_threshold: Maximum angle in degrees between normals to consider a point\n",
    "\n",
    "    Returns:\n",
    "    - A new upsampled point cloud\n",
    "    \"\"\"\n",
    "    # Ensure the point clouds have normals\n",
    "    if not sparse_pcd.has_normals():\n",
    "        sparse_pcd.estimate_normals()\n",
    "    if not dense_pcd.has_normals():\n",
    "        dense_pcd.estimate_normals()\n",
    "\n",
    "    kdtree = o3d.geometry.KDTreeFlann(dense_pcd)\n",
    "\n",
    "    sparse_points = np.asarray(sparse_pcd.points)\n",
    "    sparse_normals = np.asarray(sparse_pcd.normals)\n",
    "    added_points = set(map(tuple, sparse_points))\n",
    "\n",
    "    upsampled_points = list(sparse_points)\n",
    "\n",
    "    for i, point in enumerate(sparse_points):\n",
    "        [k, idx, _] = kdtree.search_radius_vector_3d(point, search_radius)\n",
    "        \n",
    "        neighbors = np.asarray(dense_pcd.points)[idx]\n",
    "        neighbor_normals = np.asarray(dense_pcd.normals)[idx]\n",
    "\n",
    "        # Calculate angles between sparse point's normal and all its neighbors' normals\n",
    "        angles = np.degrees(np.arccos(np.clip(np.dot(sparse_normals[i], neighbor_normals.T), -1.0, 1.0)))\n",
    "\n",
    "        # Filtering neighbors based on angle threshold\n",
    "        valid_neighbors = neighbors[angles < angle_threshold]\n",
    "\n",
    "        # Filtering out points that are already in the sparse cloud or have been added before\n",
    "        unique_valid_neighbors = [tuple(neighbor) for neighbor in valid_neighbors if tuple(neighbor) not in added_points]\n",
    "\n",
    "        upsampled_points.extend(unique_valid_neighbors)\n",
    "        added_points.update(unique_valid_neighbors)\n",
    "\n",
    "    upsampled_pcd = o3d.geometry.PointCloud()\n",
    "    upsampled_pcd.points = o3d.utility.Vector3dVector(upsampled_points)\n",
    "    upsampled_pcd.estimate_normals()\n",
    "\n",
    "    return upsampled_pcd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f68f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d.visuablization.draw_geometries([pp2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad213965",
   "metadata": {},
   "outputs": [],
   "source": [
    "pp1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a198625d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pp2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b85b689",
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d.visualization.draw_geometries([pp1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e992dd88",
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d.visualization.draw_geometries([pcd_all])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9180fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d.visualization.draw_geometries([ptsdf_all])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8fb5a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "t1 = time.time()\n",
    "#pp1  = upsample_using_reference_normals(pcd_all, ptsdf_all)\n",
    "t2 = time.time()\n",
    "\n",
    "t3 = time.time()\n",
    "pp2  = upsample_using_reference_normals_new(pcd_all, ptsdf_all)\n",
    "\n",
    "t4 = time.time()\n",
    "\n",
    "\n",
    "print(\"orig: \", t2-t1, \" s | new: \", t4-t3, \" s\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60be65fa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "t1 = time.time()\n",
    "pcd_clustered = cluster_point_cloud_new(pcd_all)\n",
    "t2 = time.time()\n",
    "\n",
    "t3 = time.time()\n",
    "o3d_device = o3d.core.Device(\"CUDA:0\") \n",
    "pcd_t = o3d.t.geometry.PointCloud.from_legacy(pcd_all).to(o3d_device)\n",
    "pcd_t_tsdf = o3d.t.geometry.PointCloud.from_legacy(ptsdf_all).to(o3d_device)\n",
    "pt = cluster_point_cloud_tensor(pcd_t)\n",
    "p_up_t = upsample_using_reference_normals_t(pt,pcd_t_tsdf)\n",
    "#pt.estimate_normals()\n",
    "#pt.orient_normals_consistent_tangent_plane(30)\n",
    "#pcd_cpu = pt.cpu()\n",
    "#o3d.visualization.draw_geometries([pcd_cpu.to_legacy()])\n",
    "t4 = time.time()\n",
    "print(\"legacy: \", t2-t1, \" s | Tensor: \", t4-t3, \" s\" )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2186e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "jit(nopython=True)\n",
    "# def compute_neighbors_and_angles(sparse_normal, neighbors, neighbor_normals, added_points, angle_threshold):\n",
    "#     angles = np.degrees(np.arccos(np.clip(np.dot(sparse_normal, neighbor_normals.T), -1.0, 1.0)))\n",
    "#     valid_neighbors = neighbors[angles < angle_threshold]\n",
    "#     unique_valid_neighbors = [neighbor for neighbor in valid_neighbors if tuple(neighbor) not in added_points]\n",
    "#     return unique_valid_neighbors\n",
    "\n",
    "@jit(nopython=True)\n",
    "def compute_neighbors_and_angles(sparse_normal, neighbors, neighbor_normals, added_points, angle_threshold):\n",
    "    angles = np.degrees(np.arccos(np.clip(np.dot(sparse_normal, neighbor_normals.T), -1.0, 1.0)))\n",
    "    valid_neighbors = neighbors[angles < angle_threshold]\n",
    "    unique_valid_neighbors = [tuple(neighbor) for neighbor in valid_neighbors if tuple(neighbor) not in added_points]\n",
    "    return unique_valid_neighbors\n",
    "\n",
    "def upsample_using_reference_normals_new(sparse_pcd, dense_pcd, search_radius=0.02, angle_threshold=30):\n",
    "    # Ensure the point clouds have normals\n",
    "    if not sparse_pcd.has_normals():\n",
    "        sparse_pcd.estimate_normals()\n",
    "    if not dense_pcd.has_normals():\n",
    "        dense_pcd.estimate_normals()\n",
    "\n",
    "    kdtree = o3d.geometry.KDTreeFlann(dense_pcd)\n",
    "\n",
    "    sparse_points = np.asarray(sparse_pcd.points)\n",
    "    sparse_normals = np.asarray(sparse_pcd.normals)\n",
    "    added_points = set(map(tuple, sparse_points))\n",
    "\n",
    "    upsampled_points = list(sparse_points)\n",
    "\n",
    "    for i, point in enumerate(sparse_points):\n",
    "        [k, idx, _] = kdtree.search_radius_vector_3d(point, search_radius)\n",
    "        neighbors = np.asarray(dense_pcd.points)[idx]\n",
    "        neighbor_normals = np.asarray(dense_pcd.normals)[idx]\n",
    "\n",
    "        unique_valid_neighbors = compute_neighbors_and_angles(\n",
    "            sparse_normals[i], neighbors, neighbor_normals, added_points, angle_threshold\n",
    "        )\n",
    "\n",
    "        upsampled_points.extend(unique_valid_neighbors)\n",
    "        added_points.update(unique_valid_neighbors)\n",
    "\n",
    "    upsampled_pcd = o3d.geometry.PointCloud()\n",
    "    upsampled_pcd.points = o3d.utility.Vector3dVector(upsampled_points)\n",
    "    upsampled_pcd.estimate_normals()\n",
    "\n",
    "    return upsampled_pcd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0b935d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pcds, ptsdf = load_filter_pcds(data_path,tforms)\n",
    "pcd_all, ptsdf_all = perform_pairwise_alignment(ptsdf,pcds)\n",
    "pcd_all.estimate_normals()\n",
    "# cluster first to remove extra noise\n",
    "pcd_clustered = cluster_point_cloud_new(pcd_all)\n",
    "# After clustering, we upsample from the initial\n",
    "pcd_upsampled = upsample_using_reference_normals(pcd_clustered, ptsdf_all)\n",
    "pcd_downsampled = pcd_upsampled.voxel_down_sample(0.01)\n",
    "pcd_downsampled.orient_normals_consistent_tangent_plane(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58dc9669",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsample_using_reference_normals_new(sparse_pcd, dense_pcd, search_radius=0.02, angle_threshold=30):\n",
    "    # Ensure the point clouds have normals\n",
    "    if not sparse_pcd.has_normals():\n",
    "        sparse_pcd.estimate_normals()\n",
    "    if not dense_pcd.has_normals():\n",
    "        dense_pcd.estimate_normals()\n",
    "\n",
    "    kdtree = o3d.geometry.KDTreeFlann(dense_pcd)\n",
    "\n",
    "    sparse_points = np.asarray(sparse_pcd.points)\n",
    "    sparse_normals = np.asarray(sparse_pcd.normals)\n",
    "    added_points = set(map(tuple, sparse_points))\n",
    "\n",
    "    upsampled_points = list(sparse_points)\n",
    "\n",
    "    for i, point in enumerate(sparse_points):\n",
    "        [k, idx, _] = kdtree.search_radius_vector_3d(point, search_radius)\n",
    "        neighbors = np.asarray(dense_pcd.points)[idx]\n",
    "        neighbor_normals = np.asarray(dense_pcd.normals)[idx]\n",
    "\n",
    "        unique_valid_neighbors = compute_neighbors_and_angles(\n",
    "            sparse_normals[i], neighbors, neighbor_normals, added_points, angle_threshold\n",
    "        )\n",
    "\n",
    "        upsampled_points.extend(unique_valid_neighbors)\n",
    "        added_points.update(unique_valid_neighbors)\n",
    "\n",
    "    upsampled_pcd = o3d.geometry.PointCloud()\n",
    "    upsampled_pcd.points = o3d.utility.Vector3dVector(upsampled_points)\n",
    "    upsampled_pcd.estimate_normals()\n",
    "\n",
    "    return upsampled_pcd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4e567e",
   "metadata": {},
   "outputs": [],
   "source": [
    "r12,t12  = register_two_views_teaser(ptsdf[1],ptsdf[2],0.035)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1814be",
   "metadata": {},
   "outputs": [],
   "source": [
    "t01 = demo_manual_registration(ptsdf[0], ptsdf[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e8d096",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in np.arange(0.02, 0.1, 0.005):\n",
    "    print(i)\n",
    "    r01,t01  = register_two_views_teaser(ptsdf[0],ptsdf[1],i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3ef040",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 to 5 works\n",
    "r45,t45  = register_two_views_teaser(ptsdf[4],ptsdf[5],0.035)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7fe152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 to 5 works\n",
    "r35,t35  = register_two_views_teaser(ptsdf[3],ptsdf[5],0.04)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c91494",
   "metadata": {},
   "outputs": [],
   "source": [
    "r52,t52  = register_two_views_teaser(ptsdf[5],ptsdf[2],0.06)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b27ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pcd_all, ptsdf_all = perform_pairwise_alignment(ptsdf,pcds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211a0a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(ptsdf)):\n",
    "    o3d.visualization.draw_geometries([ptsdf[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ab5e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(pcds)):\n",
    "    o3d.visualization.draw_geometries([pcds[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4bc4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d.visualization.draw_geometries(pcds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2817f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d.visualization.draw_geometries(ptsdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7736736f",
   "metadata": {},
   "outputs": [],
   "source": [
    "d0 = t02\n",
    "d1 = h12[1]\n",
    "d3 = r32\n",
    "d4 = r32@t43\n",
    "d5 = r52\n",
    "\n",
    "dt0 = copy.deepcopy(ptsdf[0]).transform(d0)\n",
    "dt1 = copy.deepcopy(ptsdf[1]).transform(d1)\n",
    "dt3 = copy.deepcopy(ptsdf[3]).transform(d3)\n",
    "dt4 = copy.deepcopy(ptsdf[4]).transform(d4)\n",
    "dt5 = copy.deepcopy(ptsdf[5]).transform(d5)\n",
    "o3d.visualization.draw_geometries([dt0,dt1,dt3,dt4,dt5,ptsdf[2]])\n",
    "pcd_comb = o3d.geometry.PointCloud()\n",
    "pcd_comb = dt0+dt1+dt3+dt4+dt5+ptsdf[2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ca28df",
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d.visualization.draw_geometries([pcd_comb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe8f1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdt0 = copy.deepcopy(pcds[0]).transform(d0)\n",
    "pdt1 = copy.deepcopy(pcds[1]).transform(d1)\n",
    "pdt3 = copy.deepcopy(pcds[3]).transform(d3)\n",
    "pdt4 = copy.deepcopy(pcds[4]).transform(d4)\n",
    "pdt5 = copy.deepcopy(pcds[5]).transform(d5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9628e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dpcd_comb = o3d.geometry.PointCloud()\n",
    "dpcd_comb = pdt0+pdt1+pdt3+pdt4+pdt5+pcds[2]\n",
    "o3d.visualization.draw_geometries([dpcd_comb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7150baa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dpcd_comb.estimate_normals()\n",
    "dpcd_comb.orient_normals_consistent_tangent_plane(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b048205",
   "metadata": {},
   "outputs": [],
   "source": [
    "with o3d.utility.VerbosityContextManager(o3d.utility.VerbosityLevel.Error) as cm:\n",
    "        meshd, densities = o3d.geometry.TriangleMesh.create_from_point_cloud_poisson(dpcd_comb, depth=6)\n",
    "\n",
    "o3d.visualization.draw_geometries([meshd])\n",
    "sa1 = meshd.get_surface_area()\n",
    "if(meshd.is_watertight()):\n",
    "    print(\"Is watertight 1\")\n",
    "    v1 =  meshd.get_volume()\n",
    "print(sa1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79034df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "t02 = demo_manual_registration(ptsdf[0],pcd_comb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be967a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in np.arange(0.05,0.08,0.001):\n",
    "    t02,r02 = register_two_views_teaser(ptsdf[0],pcd_comb,i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c278c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "t01 = register_tw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c77784",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in np.arange(0.02,0.1,0.001):\n",
    "    t01,r01  = register_two_views_teaser(ptsdf[0],ptsdf[3],i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb120ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "t52, r52 = register_two_views_teaser(ptsdf[5],ptsdf[2],0.03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fad441e",
   "metadata": {},
   "outputs": [],
   "source": [
    "t43 = demo_manual_registration(ptsdf[4],ptsdf[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6856e7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "t45,r45 = register_two_views_teaser(ptsdf[4],ptsdf[5],0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77df4a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perturb_transformation(T, rotation_angle_range=0.05, translation_range=0.01):\n",
    "    # Extract rotation and translation\n",
    "    R = T[:3, :3]\n",
    "    t = T[:3, 3]\n",
    "    \n",
    "    # Perturb rotation\n",
    "    axis = np.random.randn(3)\n",
    "    axis /= np.linalg.norm(axis)\n",
    "    angle = np.random.uniform(-rotation_angle_range, rotation_angle_range)\n",
    "    small_rotation = o3d.geometry.get_rotation_matrix_from_axis_angle(axis * angle)\n",
    "    R_perturbed = np.dot(R, small_rotation)\n",
    "    \n",
    "    # Perturb translation\n",
    "    t_perturbed = t + np.random.uniform(-translation_range, translation_range, size=3)\n",
    "    \n",
    "    # Create perturbed transformation\n",
    "    T_perturbed = np.eye(4)\n",
    "    T_perturbed[:3, :3] = R_perturbed\n",
    "    T_perturbed[:3, 3] = t_perturbed\n",
    "    \n",
    "    return T_perturbed\n",
    "\n",
    "# Example usage:\n",
    "T_original = np.array([\n",
    "    [0.866, -0.5, 0, 0.5],\n",
    "    [0.5, 0.866, 0, 0.5],\n",
    "    [0, 0, 1, 0],\n",
    "    [0, 0, 0, 1]\n",
    "])\n",
    "T_perturbed = perturb_transformation(T_original)\n",
    "print(T_perturbed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d275748",
   "metadata": {},
   "outputs": [],
   "source": [
    "r12_m = perturb_transformation(r12,0.2,0.2)\n",
    "draw_registration_result(ptsdf[1],ptsdf[2],r12_m)\n",
    "\n",
    "p12 = copy.deepcopy(ptsdf[1]).transform(r12_m)\n",
    "\n",
    "o3d.visualization.draw_geometries([p12,ptsdf[2]])\n",
    "r12_c = colored_ICP(p12,ptsdf[2])\n",
    "draw_registration_result(p12,ptsdf[2],r12_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834a6889",
   "metadata": {},
   "outputs": [],
   "source": [
    "r32_m = perturb_transformation(r32,0.2,0.2)\n",
    "draw_registration_result(ptsdf[3],ptsdf[2],r32_m)\n",
    "\n",
    "p = copy.deepcopy(ptsdf[3]).transform(r32_m)\n",
    "\n",
    "o3d.visualization.draw_geometries([p,ptsdf[2]])\n",
    "r = colored_ICP(p,ptsdf[2])\n",
    "draw_registration_result(p,ptsdf[2],r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af93c182",
   "metadata": {},
   "outputs": [],
   "source": [
    "#h43 = register_two_views_teaser(ptsdf[4],ptsdf[3],0.04)\n",
    "\n",
    "draw_registration_result(ptsdf[4],ptsdf[3],h43[1])\n",
    "\n",
    "p4tf = copy.deepcopy(ptsdf[4]).transform(h43[1])\n",
    "\n",
    "o3d.visualization.draw_geometries([p4tf,ptsdf[3]])\n",
    "r4_3 = colored_ICP(p4tf,ptsdf[3])\n",
    "draw_registration_result(p4tf,ptsdf[3],r4_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2672fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "t32,r32 = register_two_views_teaser(ptsdf[3],ptsdf[2],0.035)\n",
    "\n",
    "#t32 = demo_manual_registration(ptsdf[3],ptsdf[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbb1912",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in np.arange(0.03,0.1,0.001):\n",
    "    h52 = register_two_views_teaser(ptsdf[4],ptsdf[3],i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2d58d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "h43 = register_two_views_teaser(ptsdf[4],ptsdf[3],0.04)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e844db91",
   "metadata": {},
   "outputs": [],
   "source": [
    "h12,r12 = register_two_views_teaser(ptsdf[1],ptsdf[2],0.04)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d97ce65",
   "metadata": {},
   "outputs": [],
   "source": [
    "t01 = demo_manual_registration(ptsdf[0],ptsdf[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61bedac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "t12= demo_manual_registration(ptsdf[1],ptsdf[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7c24d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "t52 = demo_manual_registration(ptsdf[5],ptsdf[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1302f458",
   "metadata": {},
   "outputs": [],
   "source": [
    "t34,r34 = register_two_views_teaser(ptsdf[3],ptsdf[4],0.03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54801dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "t45, r45 = register_two_views_teaser(ptsdf[4],ptsdf[5],0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96024b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tforms = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caff0f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "h0 = t12@t01\n",
    "h1 = t12\n",
    "h3 = t52@r45@r34\n",
    "h4 = t52@r45\n",
    "h5 = t52"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cbdcbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "p0 = copy.deepcopy(ptsdf[0]).transform(h0)\n",
    "p1 = copy.deepcopy(ptsdf[1]).transform(h1)\n",
    "p3 = copy.deepcopy(ptsdf[3]).transform(h3)\n",
    "p4 = copy.deepcopy(ptsdf[4]).transform(h4)\n",
    "p5 = copy.deepcopy(ptsdf[5]).transform(h5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0dc544f",
   "metadata": {},
   "outputs": [],
   "source": [
    "c0 = copy.deepcopy(pcds[0]).transform(h0)\n",
    "c1 = copy.deepcopy(pcds[1]).transform(h1)\n",
    "c3 = copy.deepcopy(pcds[3]).transform(h3)\n",
    "c4 = copy.deepcopy(pcds[4]).transform(h4)\n",
    "c5 = copy.deepcopy(pcds[5]).transform(h5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a4b8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def register_two_views_teaser(A_pcd_raw,B_pcd_raw,VOXEL_SIZE):\n",
    "    \n",
    "    VISUALIZE = True\n",
    "    A_pcd = A_pcd_raw.voxel_down_sample(voxel_size=VOXEL_SIZE)\n",
    "    B_pcd = B_pcd_raw.voxel_down_sample(voxel_size=VOXEL_SIZE)\n",
    "    #if VISUALIZE:\n",
    "     #   o3d.visualization.draw_geometries([A_pcd,B_pcd]) # plot downsampled A and B \n",
    "\n",
    "    A_xyz = pcd2xyz(A_pcd) # np array of size 3 by N\n",
    "    B_xyz = pcd2xyz(B_pcd) # np array of size 3 by M\n",
    "\n",
    "    print(\"Extracting FPFH features\")\n",
    "    # extract FPFH features\n",
    "    A_feats = extract_fpfh(A_pcd,VOXEL_SIZE)\n",
    "    B_feats = extract_fpfh(B_pcd,VOXEL_SIZE)\n",
    "    print(A_feats.shape)\n",
    "    print(\"Computing FPFH correspondences\")\n",
    "    # establish correspondences by nearest neighbour search in feature space\n",
    "    corrs_A, corrs_B = find_correspondences(\n",
    "        A_feats, B_feats, mutual_filter=True)\n",
    "    A_corr = A_xyz[:,corrs_A] # np array of size 3 by num_corrs\n",
    "    B_corr = B_xyz[:,corrs_B] # np array of size 3 by num_corrs\n",
    "\n",
    "    num_corrs = A_corr.shape[1]\n",
    "    print(f'FPFH generates {num_corrs} putative correspondences.')\n",
    "\n",
    "    # visualize the point clouds together with feature correspondenc\n",
    "    # robust global registration using TEASER++\n",
    "    NOISE_BOUND = VOXEL_SIZE\n",
    "    teaser_solver = get_teaser_solver(NOISE_BOUND)\n",
    "    teaser_solver.solve(A_corr,B_corr)\n",
    "    solution = teaser_solver.getSolution()\n",
    "    R_teaser = solution.rotation\n",
    "    t_teaser = solution.translation\n",
    "    T_teaser = Rt2T(R_teaser,t_teaser)\n",
    "\n",
    "    # Visualize the registration results\n",
    "    A_pcd_T_teaser = copy.deepcopy(A_pcd).transform(T_teaser)\n",
    "    #o3d.visualization.draw_geometries([A_pcd_T_teaser,B_pcd])\n",
    "\n",
    "    # local refinement using ICP\n",
    "    icp_sol = o3d.pipelines.registration.registration_icp(\n",
    "          A_pcd, B_pcd, NOISE_BOUND, T_teaser,\n",
    "          o3d.pipelines.registration.TransformationEstimationPointToPoint(),\n",
    "          o3d.pipelines.registration.ICPConvergenceCriteria(max_iteration=100))\n",
    "    T_icp = icp_sol.transformation\n",
    "\n",
    "    # visualize the registration after ICP refinement\n",
    "    A_pcd_T_icp = copy.deepcopy(A_pcd).transform(T_icp)\n",
    "    if VISUALIZE:\n",
    "        Acopy = copy.deepcopy(A_pcd_T_icp).paint_uniform_color([0.0,0.0,1])\n",
    "        Bcopy = copy.deepcopy(B_pcd).paint_uniform_color([1.0,0.0,0.0])\n",
    "        o3d.visualization.draw_geometries([Acopy,Bcopy])\n",
    "    tformed_A = copy.deepcopy(A_pcd_raw).transform(T_icp)\n",
    "    res = o3d.geometry.PointCloud()\n",
    "    res = tformed_A + B_pcd_raw\n",
    "    \n",
    "    return res,T_icp\n",
    "\n",
    "def pcd2xyz(pcd):\n",
    "    return np.asarray(pcd.points).T\n",
    "\n",
    "def extract_fpfh(pcd, voxel_size):\n",
    "    radius_normal = voxel_size * 2\n",
    "    pcd.estimate_normals(\n",
    "      o3d.geometry.KDTreeSearchParamHybrid(radius=radius_normal, max_nn=30))\n",
    "\n",
    "    radius_feature = voxel_size * 5\n",
    "    fpfh = o3d.pipelines.registration.compute_fpfh_feature(\n",
    "      pcd, o3d.geometry.KDTreeSearchParamHybrid(radius=radius_feature, max_nn=100))\n",
    "    return np.array(fpfh.data).T\n",
    "\n",
    "def find_knn_cpu(feat0, feat1, knn=1, return_distance=False):\n",
    "    feat1tree = cKDTree(feat1)\n",
    "    dists, nn_inds = feat1tree.query(feat0, k=knn, workers=10)\n",
    "    if return_distance:\n",
    "        return nn_inds, dists\n",
    "    else:\n",
    "        return nn_inds\n",
    "\n",
    "def find_correspondences(feats0, feats1, mutual_filter=True):\n",
    "    nns01 = find_knn_cpu(feats0, feats1, knn=1, return_distance=False)\n",
    "    corres01_idx0 = np.arange(len(nns01))\n",
    "    corres01_idx1 = nns01\n",
    "\n",
    "    if not mutual_filter:\n",
    "        return corres01_idx0, corres01_idx1\n",
    "\n",
    "    nns10 = find_knn_cpu(feats1, feats0, knn=1, return_distance=False)\n",
    "    corres10_idx1 = np.arange(len(nns10))\n",
    "    corres10_idx0 = nns10\n",
    "\n",
    "    mutual_filter = (corres10_idx0[corres01_idx1] == corres01_idx0)\n",
    "    corres_idx0 = corres01_idx0[mutual_filter]\n",
    "    corres_idx1 = corres01_idx1[mutual_filter]\n",
    "\n",
    "    return corres_idx0, corres_idx1\n",
    "\n",
    "def get_teaser_solver(noise_bound):\n",
    "    solver_params = teaserpp_python.RobustRegistrationSolver.Params()\n",
    "    solver_params.cbar2 = 1.0\n",
    "    solver_params.noise_bound = noise_bound\n",
    "    solver_params.estimate_scaling = False\n",
    "    solver_params.inlier_selection_mode = \\\n",
    "        teaserpp_python.RobustRegistrationSolver.INLIER_SELECTION_MODE.PMC_EXACT\n",
    "    solver_params.rotation_tim_graph = \\\n",
    "        teaserpp_python.RobustRegistrationSolver.INLIER_GRAPH_FORMULATION.CHAIN\n",
    "    solver_params.rotation_estimation_algorithm = \\\n",
    "        teaserpp_python.RobustRegistrationSolver.ROTATION_ESTIMATION_ALGORITHM.GNC_TLS\n",
    "    solver_params.rotation_gnc_factor = 1.4\n",
    "    solver_params.rotation_max_iterations = 10000\n",
    "    solver_params.rotation_cost_threshold = 1e-16\n",
    "    solver = teaserpp_python.RobustRegistrationSolver(solver_params)\n",
    "    return solver\n",
    "\n",
    "def Rt2T(R,t):\n",
    "    T = np.identity(4)\n",
    "    T[:3,:3] = R\n",
    "    T[:3,3] = t\n",
    "    return T \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481b4cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d.visualization.draw_geometries([c0,c1,pcds[2],c3,c4,c5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00474981",
   "metadata": {},
   "outputs": [],
   "source": [
    "pcds_all = o3d.geometry.PointCloud()\n",
    "pcds_all = c0+c1+pcds[2]+c3+c4+c5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5583ddb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d.visualization.draw_geometries([pcds_all])\n",
    "o3d.visualization.draw_geometries([pcds_all_tsdf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4157c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d.visualization.draw_geometries([pcds_all])\n",
    "o3d.io.write_point_cloud(spath+\"pcd_animal_482_2_no_ds.ply\",pcds_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44deb751",
   "metadata": {},
   "outputs": [],
   "source": [
    "pcds_all_tsdf = o3d.geometry.PointCloud()\n",
    "pcds_all_tsdf = p0+p1+ptsdf[2]+p3+p4+p5\n",
    "o3d.io.write_point_cloud(spath+\"pcd_animal_482_2_tsdf.ply\",pcds_all_tsdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703e4890",
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d.io.write_point_cloud(spath+\"pcd_animal_482_2_no_normals.ply\",pcds_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f677d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "spath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa0cf9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def upsample_using_reference(sparse_pcd, dense_pcd, search_radius=0.05):\n",
    "    \"\"\"\n",
    "    Efficiently upsample the sparse point cloud using the dense point cloud as reference.\n",
    "\n",
    "    Parameters:\n",
    "    - sparse_pcd: The sparse point cloud\n",
    "    - dense_pcd: The dense reference point cloud\n",
    "    - search_radius: Radius to search for neighbors\n",
    "\n",
    "    Returns:\n",
    "    - A new upsampled point cloud\n",
    "    \"\"\"\n",
    "    kdtree = o3d.geometry.KDTreeFlann(dense_pcd)\n",
    "\n",
    "    sparse_points = np.asarray(sparse_pcd.points)\n",
    "    added_points = set(map(tuple, sparse_points))\n",
    "\n",
    "    upsampled_points = list(sparse_points)\n",
    "\n",
    "    for point in sparse_points:\n",
    "        [k, idx, _] = kdtree.search_radius_vector_3d(point, search_radius)\n",
    "        \n",
    "        # Convert indices to points\n",
    "        neighbors = np.asarray(dense_pcd.points)[idx]\n",
    "        \n",
    "        # Filtering out points that are already in the sparse cloud or have been added before\n",
    "        unique_neighbors = [tuple(neighbor) for neighbor in neighbors if tuple(neighbor) not in added_points]\n",
    "        \n",
    "        upsampled_points.extend(unique_neighbors)\n",
    "        added_points.update(unique_neighbors)\n",
    "\n",
    "    upsampled_pcd = o3d.geometry.PointCloud()\n",
    "    upsampled_pcd.points = o3d.utility.Vector3dVector(upsampled_points)\n",
    "\n",
    "    return upsampled_pcd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73823c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d.visualization.draw_geometries([upcdn])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55806362",
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d.visualization.draw_geometries([upcdn])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305f59de",
   "metadata": {},
   "outputs": [],
   "source": [
    "upcdn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dace4a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "upcd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df21c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d.visualization.draw_geometries([pcds_all])\n",
    "o3d.visualization.draw_geometries([pcds_all_tsdf])\n",
    "o3d.visualization.draw_geometries([upcd])\n",
    "o3d.visualization.draw_geometries([upcdn])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b229ff70",
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = time.time()\n",
    "upcd = upsample_using_reference(pcds_all,pcds_all_tsdf,0.01)\n",
    "upcd.estimate_normals()\n",
    "upcd.orient_normals_consistent_tangent_plane(30)\n",
    "#o3d.geometry.PointCloud.orient_normals_consistent_tangent_plane(upcd,30)\n",
    "e1 = time.time()\n",
    "\n",
    "s2 = time.time()\n",
    "upcdn = upsample_using_reference_normals(pcds_all,pcds_all_tsdf,0.01, 30)\n",
    "upcdn.orient_normals_consistent_tangent_plane(30)\n",
    "#o3d.geometry.PointCloud.orient_normals_consistent_tangent_plane(upcdn,30)\n",
    "e2 = time.time()\n",
    "\n",
    "d1 = e1-s1\n",
    "d2 = e2-s2\n",
    "\n",
    "print(\"first: \", d1, \"s\")\n",
    "\n",
    "print(\"second: \", d2, \"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd647782",
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d.io.write_point_cloud(spath+\"upsampled_cloud.ply\", upcd)\n",
    "o3d.io.write_point_cloud(spath+\"upsampled_normal_based_cloud.ply\", upcdn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da60cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with o3d.utility.VerbosityContextManager(o3d.utility.VerbosityLevel.Error) as cm:\n",
    "        mesh1, densities = o3d.geometry.TriangleMesh.create_from_point_cloud_poisson(upcd, depth=6)\n",
    "\n",
    "o3d.visualization.draw_geometries([mesh1])\n",
    "sa1 = mesh1.get_surface_area()\n",
    "if(mesh1.is_watertight()):\n",
    "    print(\"Is watertight 1\")\n",
    "    v1 =  mesh1.get_volume()\n",
    "\n",
    "\n",
    "with o3d.utility.VerbosityContextManager(o3d.utility.VerbosityLevel.Error) as cm:\n",
    "        mesh2, densities = o3d.geometry.TriangleMesh.create_from_point_cloud_poisson(upcdn, depth=6)\n",
    "\n",
    "o3d.visualization.draw_geometries([mesh2])\n",
    "sa2 = mesh2.get_surface_area()\n",
    "if(mesh2.is_watertight()):\n",
    "    print(\"Is watertight 2\")\n",
    "    v2 =  mesh2.get_volume()\n",
    "\n",
    "with o3d.utility.VerbosityContextManager(o3d.utility.VerbosityLevel.Error) as cm:\n",
    "        mesh3, densities = o3d.geometry.TriangleMesh.create_from_point_cloud_poisson(pcds_all, depth=6)\n",
    "\n",
    "o3d.visualization.draw_geometries([mesh3])\n",
    "sa3 = mesh3.get_surface_area()\n",
    "if(mesh3.is_watertight()):\n",
    "    print(\"Is watertight 3\")\n",
    "    v3 =  mesh3.get_volume()\n",
    "\n",
    "print(\"SA: \", sa1, \", \", sa2, \", \", sa3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b025ce36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#o3d.visualization.draw_geometries([upcdn])\n",
    "o3d.geometry.PointCloud.orient_normals_consistent_tangent_plane(upcdn,30)\n",
    "o3d.visualization.draw_geometries([upcdn])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80beb218",
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d.visualization.draw_geometries([pcds_all])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b982b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd = pcds_all.voxel_down_sample(voxel_sizbe=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8dcce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d.visualization.draw_geometries([pd])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c2fd01",
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d.geometry.PointCloud.orient_normals_consistent_tangent_plane(pd,30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62abfb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#o3d.geometry.PointCloud.orient_normals_consistent_tangent_plane(pcds_all,30)\n",
    "with o3d.utility.VerbosityContextManager(o3d.utility.VerbosityLevel.Error) as cm:\n",
    "        mesh, densities = o3d.geometry.TriangleMesh.create_from_point_cloud_poisson(pcds_all, depth=6)\n",
    "\n",
    "o3d.visualization.draw_geometries([mesh])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f5e60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#upcd.estimate_normals()\n",
    "with o3d.utility.VerbosityContextManager(o3d.utility.VerbosityLevel.Error) as cm:\n",
    "        mesh, densities = o3d.geometry.TriangleMesh.create_from_point_cloud_poisson(upcdn, depth=6)\n",
    "\n",
    "o3d.visualization.draw_geometries([mesh])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f861d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def upsample_using_reference_normals(sparse_pcd, dense_pcd, search_radius=0.02, angle_threshold=30):\n",
    "    \"\"\"\n",
    "    Efficiently upsample the sparse point cloud using the dense point cloud as reference.\n",
    "    Considers the normals to ensure added points are consistent with the sparse cloud.\n",
    "\n",
    "    Parameters:\n",
    "    - sparse_pcd: The sparse point cloud\n",
    "    - dense_pcd: The dense reference point cloud\n",
    "    - search_radius: Radius to search for neighbors\n",
    "    - angle_threshold: Maximum angle in degrees between normals to consider a point\n",
    "\n",
    "    Returns:\n",
    "    - A new upsampled point cloud\n",
    "    \"\"\"\n",
    "    # Ensure the point clouds have normals\n",
    "    if not sparse_pcd.has_normals():\n",
    "        sparse_pcd.estimate_normals()\n",
    "    if not dense_pcd.has_normals():\n",
    "        dense_pcd.estimate_normals()\n",
    "\n",
    "    kdtree = o3d.geometry.KDTreeFlann(dense_pcd)\n",
    "\n",
    "    sparse_points = np.asarray(sparse_pcd.points)\n",
    "    sparse_normals = np.asarray(sparse_pcd.normals)\n",
    "    added_points = set(map(tuple, sparse_points))\n",
    "\n",
    "    upsampled_points = list(sparse_points)\n",
    "\n",
    "    for i, point in enumerate(sparse_points):\n",
    "        [k, idx, _] = kdtree.search_radius_vector_3d(point, search_radius)\n",
    "        \n",
    "        neighbors = np.asarray(dense_pcd.points)[idx]\n",
    "        neighbor_normals = np.asarray(dense_pcd.normals)[idx]\n",
    "\n",
    "        # Calculate angles between sparse point's normal and all its neighbors' normals\n",
    "        angles = np.degrees(np.arccos(np.clip(np.dot(sparse_normals[i], neighbor_normals.T), -1.0, 1.0)))\n",
    "\n",
    "        # Filtering neighbors based on angle threshold\n",
    "        valid_neighbors = neighbors[angles < angle_threshold]\n",
    "\n",
    "        # Filtering out points that are already in the sparse cloud or have been added before\n",
    "        unique_valid_neighbors = [tuple(neighbor) for neighbor in valid_neighbors if tuple(neighbor) not in added_points]\n",
    "\n",
    "        upsampled_points.extend(unique_valid_neighbors)\n",
    "        added_points.update(unique_valid_neighbors)\n",
    "\n",
    "    upsampled_pcd = o3d.geometry.PointCloud()\n",
    "    upsampled_pcd.points = o3d.utility.Vector3dVector(upsampled_points)\n",
    "    upsampled_pcd.estimate_normals()\n",
    "\n",
    "    return upsampled_pcd\n",
    "\n",
    "# Sample usage\n",
    "# sparse_cloud = o3d.io.read_point_cloud(\"path_to_sparse_point_cloud.ply\")\n",
    "# dense_cloud = o3d.io.read_point_cloud(\"path_to_dense_point_cloud.ply\")\n",
    "# upsampled_cloud = upsample_using_reference(sparse_cloud, dense_cloud)\n",
    "# o3d.visualization.draw_geometries([upsampled_cloud])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea165d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsample_using_reference(sparse_pcd, dense_pcd, search_radius=0.05):\n",
    "    \"\"\"\n",
    "    Upsamples the sparse point cloud using the dense point cloud as reference.\n",
    "\n",
    "    Parameters:\n",
    "    - sparse_pcd: The sparse point cloud\n",
    "    - dense_pcd: The dense reference point cloud\n",
    "    - search_radius: Radius to search for neighbors\n",
    "\n",
    "    Returns:\n",
    "    - A new upsampled point cloud\n",
    "    \"\"\"\n",
    "    # Construct KDTree for dense point cloud\n",
    "    kdtree = o3d.geometry.KDTreeFlann(dense_pcd)\n",
    "\n",
    "    # Convert sparse point cloud to numpy array\n",
    "    sparse_points = np.asarray(sparse_pcd.points)\n",
    "\n",
    "    # List to store upsampled points\n",
    "    upsampled_points = list(sparse_points)\n",
    "\n",
    "    # For each point in the sparse cloud\n",
    "    for point in sparse_points:\n",
    "        # Search for neighbors from the dense cloud within the search_radius\n",
    "        [k, idx, _] = kdtree.search_radius_vector_3d(point, search_radius)\n",
    "\n",
    "        # If we found any neighbors, add them to the upsampled list\n",
    "        if k > 1:\n",
    "            # Convert indices to points\n",
    "            neighbors = np.asarray(dense_pcd.points)[idx]\n",
    "            \n",
    "            # Add neighbors to the upsampled list\n",
    "            # We filter out points that are already in the sparse cloud\n",
    "            for neighbor in neighbors:\n",
    "                if not np.any(np.all(sparse_points == neighbor, axis=1)):\n",
    "                    upsampled_points.append(neighbor)\n",
    "\n",
    "    # Create a new point cloud for the upsampled points\n",
    "    upsampled_pcd = o3d.geometry.PointCloud()\n",
    "    upsampled_pcd.points = o3d.utility.Vector3dVector(upsampled_points)\n",
    "\n",
    "    return upsampled_pcd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b5b191",
   "metadata": {},
   "outputs": [],
   "source": [
    "pcds_all.estimate_normals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a2880d",
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d.visualization.draw_geometries([pcd])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae164ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "spath = '/home/vigir3d/Datasets/cattle_scans/farm_scan1/Animal_482_2/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f70def4",
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d.io.write_point_cloud(spath+\"pcd_animal_482_2.ply\",pcd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2fcc08",
   "metadata": {},
   "outputs": [],
   "source": [
    "pcd_raw = o3d.io.read_point_cloud(spath+\"pcd_animal_482_2.ply\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94987aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "pcd_raw2 = o3d.io.read_point_cloud(spath+\"pcd_animal_482_2_no_normals.ply\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82d4b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pcd_raw.orient_normals_consistent_tangent_plane(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51252634",
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d.visualization.draw_geometries([pcd_raw2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae99661",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = o3d.geometry.KDTreeSearchParamKNN(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e152e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "pcd_raw2.estimate_normals(knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b271a742",
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d.visualization.draw_geometries([pcd_raw2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f27944",
   "metadata": {},
   "outputs": [],
   "source": [
    "pcd_raw2.orient_normals_consistent_tangent_plane(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be8708a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#pcd = pcds_all.voxel_down_sample(voxel_size=0.05)\n",
    "#o3d.visualization.draw_geometries([pcd])\n",
    "with o3d.utility.VerbosityContextManager(o3d.utility.VerbosityLevel.Error) as cm:\n",
    "        mesh, densities = o3d.geometry.TriangleMesh.create_from_point_cloud_poisson(pcd_raw, depth=6)\n",
    "\n",
    "o3d.visualization.draw_geometries([mesh])\n",
    "\n",
    "sa = mesh.get_surface_area()\n",
    "print(\"Downsampled: \", sa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19cba7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#pcd = pcds_all.voxel_down_sample(voxel_size=0.05)\n",
    "#o3d.visuaalization.draw_geometries([pcd])\n",
    "with o3d.utility.VerbosityContextManager(o3d.utility.VerbosityLevel.Error) as cm:\n",
    "        mesh, densities = o3d.geometry.TriangleMesh.create_from_point_cloud_poisson(pcd_raw2, depth=6)\n",
    "\n",
    "o3d.visualization.draw_geometries([mesh])\n",
    "\n",
    "sa = mesh.get_surface_area()\n",
    "print(sa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0fbe427",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_cl_1 = cluster_point_cloud_new(pcd_raw)\n",
    "p_cl_2 = cluster_point_cloud_new(pcd_raw2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70501559",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_cl_2.voxel_down_sample(voxel_size=0.01)\n",
    "o3d.visualization.draw_geometries([p_cl_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e31044",
   "metadata": {},
   "outputs": [],
   "source": [
    "p2  = p_cl_2.voxel_down_sample(voxel_size=0.01)\n",
    "p3  = p_cl_2.voxel_down_sample(voxel_size=0.02)\n",
    "p4  = p_cl_2.voxel_down_sample(voxel_size=0.03)\n",
    "\n",
    "\n",
    "o3d.visualization.draw_geometries([p2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42cd469c",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_cl_2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad710fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "p2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd422e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "p3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb3e2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "p4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8b9aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "p2  = p_cl_2.voxel_down_sample(voxel_size=0.08)\n",
    "o3d.visualization.draw_geometries([p_cl_2])\n",
    "with o3d.utility.VerbosityContextManager(o3d.utility.VerbosityLevel.Error) as cm:\n",
    "        mesh1, densities = o3d.geometry.TriangleMesh.create_from_point_cloud_poisson(p_cl_2, depth=6)\n",
    "\n",
    "#o3d.visualization.draw_geometries([mesh])\n",
    "\n",
    "sa1 = mesh1.get_surface_area()\n",
    "print(\"Original:\", sa1)\n",
    "\n",
    "\n",
    "with o3d.utility.VerbosityContextManager(o3d.utility.VerbosityLevel.Error) as cm:\n",
    "        mesh2, densities = o3d.geometry.TriangleMesh.create_from_point_cloud_poisson(p2, depth=6)\n",
    "\n",
    "#o3d.visualization.draw_geometries([mesh])\n",
    "\n",
    "sa2 = mesh2.get_surface_area()\n",
    "print(\"Downsampled: \", sa2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab106f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "pcd_cl = cluster_point_cloud_new(pcd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171ff213",
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d.visualization.draw_geometries([pcd_cl])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04c5656",
   "metadata": {},
   "outputs": [],
   "source": [
    "with o3d.utility.VerbosityContextManager(o3d.utility.VerbosityLevel.Error) as cm:\n",
    "        mesh, densities = o3d.geometry.TriangleMesh.create_from_point_cloud_poisson(pcd_cl, depth=6)\n",
    "\n",
    "o3d.visualization.draw_geometries([mesh])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7b8a0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0467c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_point_cloud(outlier_cloud) :\n",
    "    cloud_colors = np.asarray(outlier_cloud.colors).T\n",
    "    with o3d.utility.VerbosityContextManager(\n",
    "            o3d.utility.VerbosityLevel.Error) as cm:\n",
    "        labels = np.array(\n",
    "            outlier_cloud.cluster_dbscan(eps=0.1, min_points=10, print_progress=True))\n",
    "\n",
    "    max_label = labels.max()\n",
    "    print(f\"point cloud has {max_label + 1} clusters\")\n",
    "    colors = plt.get_cmap(\"tab20\")(labels / (max_label if max_label > 0 else 1))\n",
    "    colors[labels < 0] = 0\n",
    "    copy_outlier_cloud = copy.deepcopy(outlier_cloud)\n",
    "    copy_outlier_cloud.colors = o3d.utility.Vector3dVector(colors[:, :3])\n",
    "    o3d.visualization.draw_geometries([copy_outlier_cloud])\n",
    "\n",
    "    values, counts = np.unique(labels, return_counts=True)\n",
    "    ind = np.argmax(counts)\n",
    "    print(values[ind])  # prints the most frequent element\n",
    "\n",
    "    cloud_xyz = pcd2xyz(outlier_cloud)\n",
    "    cloud_normals  = pcd2normals(outlier_cloud)\n",
    "    \n",
    "    print(\"C: \", cloud_colors.shape, \" N\", cloud_normals.shape)\n",
    "    cloud_filtered = cloud_xyz[:,(labels == 0)]\n",
    "    normals_filtered = (cloud_normals[:,(labels == 0)])\n",
    "    colors_filtered = (cloud_colors[:,(labels == 0)])\n",
    "    pcd_filtered_largest_cluster = o3d.geometry.PointCloud()\n",
    "    pcd_filtered_largest_cluster.points = o3d.utility.Vector3dVector(cloud_filtered.T)\n",
    "    pcd_filtered_largest_cluster.normals = o3d.utility.Vector3dVector(normals_filtered.T)\n",
    "    pcd_filtered_largest_cluster.colors = o3d.utility.Vector3dVector(colors_filtered.T)\n",
    "    # copy the normals also\n",
    "    o3d.visualization.draw_geometries([pcd_filtered_largest_cluster])\n",
    "    return pcd_filtered_largest_cluster\n",
    "\n",
    "\n",
    "def pcd2normals(pcd):\n",
    "    return np.asarray(pcd.normals).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ff36d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tform_path = '/home/vigir3d/Datasets/cattle_scans/farm_scan1/Animal_482_1/'\n",
    "h0 = np.loadtxt(tforma_path+\"htm_0_3.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02303c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d.visualization.draw_geometries([tforms_apriltag[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e406a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d.visualization.draw_geometries([pcds[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59807197",
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d.visualization.draw_geometries([pt[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5b2788",
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d.visualization.draw_geometries([p[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641de6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_registration_result(pt[0],pt[0], h0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a524e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d.visualization.draw_geometries(pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8813c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/home/vigir3d/Datasets/cattle_scans/farm_scan1/Animal_482_2'\n",
    "\n",
    "ws = 2\n",
    "flying_pixel_filter_threshold = 10000\n",
    "\n",
    "\n",
    "\n",
    "reader = o3d.io.AzureKinectMKVReader()\n",
    "abspath = data_path\n",
    "pcds = []\n",
    "filtered_pcds = []\n",
    "\n",
    "\n",
    "files_raw = glob.glob(data_path+'/*.mkv')\n",
    "files = filter_file_names(files_raw)\n",
    "files.sort()\n",
    "pcds_raw = []\n",
    "pcds_tsdf = []\n",
    "\n",
    "list_size = len(files)\n",
    "rgbd_frames = [None] * list_size\n",
    "\n",
    "for i in range(len(files)): # for each view\n",
    "\n",
    "    inFile = files[i]\n",
    "    fname = inFile.split('/')[-1]\n",
    "    file_name = fname.split('.mkv')[0]\n",
    "    reader.open(inFile)\n",
    "    if not reader.is_opened():\n",
    "        raise RuntimeError(\"Unable to open file {}\".format(inFile))\n",
    "    metadata = reader.get_metadata()\n",
    "\n",
    "    # write the metadata to a JSON file since that seems to be the only\n",
    "    # way to retrieve that data\n",
    "    o3d.io.write_azure_kinect_mkv_metadata(\n",
    "                '{}/{}_intrinsic.json'.format(abspath,file_name), metadata)\n",
    "\n",
    "    # Open the file and load the JSON\n",
    "    with open(abspath+\"/\" + file_name + \"_intrinsic.json\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    height = data['height']\n",
    "    width = data['width']\n",
    "    intrinsics = data[\"intrinsic_matrix\"]\n",
    "    time_stamp = data[\"stream_length_usec\"]\n",
    "    #print(f\"Intrinsic Matrix {intrinsics}\")\n",
    "\n",
    "    camera_intrinsics = o3d.camera.PinholeCameraIntrinsic()\n",
    "    cx = intrinsics[6]\n",
    "    cy = intrinsics[7]\n",
    "    fx = intrinsics[0]\n",
    "    fy = intrinsics[4]\n",
    "    camera_intrinsics.set_intrinsics(width,height,fx,fy,cx,cy)\n",
    "\n",
    "    last_frame = None\n",
    "    while not reader.is_eof(): # go until hitting eof because of exposure issues in early color frames\n",
    "        rgbda = reader.next_frame();\n",
    "        if rgbda is None:\n",
    "            #print(\"Got nothing! \")\n",
    "            continue\n",
    "        last_frame = rgbda\n",
    "\n",
    "    if last_frame is not None:\n",
    "        #print(\"Got the last frame\")\n",
    "        rgbd_frames[i] = last_frame\n",
    "    else:\n",
    "\n",
    "        print(\"************No valid frames found in the .mkv file.**********\")\n",
    "\n",
    "    # filter the depth image for flying pixels\n",
    "    # unfiltered PCD\n",
    "\n",
    "    # Convert the RGBD data to tensors\n",
    "    last_frame_t = o3d.t.geometry.Image.as_tensor(last_frame)\n",
    "    \n",
    "    #color_tensor = o3d.t.geometry.Image.from_legacy()   (last_frame.color, dtype=o3d.core.Dtype.Float32, device=o3d.core.Device(\"CUDA:0\"))\n",
    "    #depth_tensor = o3d.t.io.Image.to_tensor(last_frame.depth, dtype=o3d.core.Dtype.Float32, device=o3d.core.Device(\"CUDA:0\"))\n",
    "\n",
    "    # Construct the tensor-based RGBD image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a89f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert legacy images to numpy arrays\n",
    "color_np = np.asarray(last_frame.color)\n",
    "depth_np = np.asarray(last_frame.depth)\n",
    "\n",
    "# Convert numpy arrays to tensors\n",
    "color_tensor = o3d.core.Tensor(color_np, o3d.core.Dtype.Float32, o3d.core.Device(\"CPU:0\"))\n",
    "depth_tensor = o3d.core.Tensor(depth_np, o3d.core.Dtype.Float32, o3d.core.Device(\"CPU:0\"))\n",
    "\n",
    "# Create a tensor-based RGBDImage\n",
    "rgbdt = o3d.t.geometry.RGBDImage(color_tensor, depth_tensor)\n",
    "o3d.visualization.draw_geometries([rgbdt.to_legacy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7add6c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_frame = None\n",
    "while not reader.is_eof(): # go until hitting eof because of exposure issues in early color frames\n",
    "    rgbda = reader.next_frame();\n",
    "    if rgbda is None:\n",
    "        #print(\"Got nothing! \")\n",
    "        continue\n",
    "    last_frame = rgbda\n",
    "\n",
    "if last_frame is not None:\n",
    "    #print(\"Got the last frame\")\n",
    "    rgbd_frames[i] = last_frame\n",
    "else:\n",
    "\n",
    "    print(\"************No valid frames found in the .mkv file.**********\")\n",
    "rgbdc = o3d.geometry.RGBDImage.create_from_color_and_depth(\n",
    "last_frame.color, last_frame.depth, depth_trunc=4.0, convert_rgb_to_intensity=False)\n",
    "\n",
    "volume = o3d.pipelines.integration.ScalableTSDFVolume(\n",
    "            voxel_length= 4.0/ 512.0,\n",
    "            sdf_trunc=0.04,\n",
    "            color_type=o3d.pipelines.integration.TSDFVolumeColorType.RGB8)\n",
    "\n",
    "volume.integrate(\n",
    "    rgbdc,\n",
    "    camera_intrinsics,\n",
    "    np.eye(4),\n",
    ")\n",
    "\n",
    "\n",
    "pcd_tsdf = volume.extract_point_cloud()\n",
    "pcds_tsdf.append(pcd_tsdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a95080",
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_registration_result(pt[0],pt[0],np.eye(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8969b321",
   "metadata": {},
   "outputs": [],
   "source": [
    "x='/home/vigir3d/Datasets/cattle_scans/farm_scan1/Animal_482_2/'\n",
    "cc=x.split(\"Animal\")[-1:]\n",
    "fname = cc.split\n",
    "print(\"Animal\"+cc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca9bc50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_registration_result(source, target, transformation):\n",
    "    source_temp = copy.deepcopy(source)\n",
    "    target_temp = copy.deepcopy(target)\n",
    "    source_temp.paint_uniform_color([1, 0.706, 0])\n",
    "    target_temp.paint_uniform_color([0, 0.651, 0.929])\n",
    "    source_temp.transform(transformation)\n",
    "    o3d.visualization.draw_geometries([source_temp, target_temp])\n",
    "\n",
    "\n",
    "def pick_points(pcd):\n",
    "    print(\"\")\n",
    "    print(\n",
    "        \"1) Please pick at least three correspondences using [shift + left click]\"\n",
    "    )\n",
    "    print(\"   Press [shift + right click] to undo point picking\")\n",
    "    print(\"2) After picking points, press 'Q' to close the window\")\n",
    "    vis = o3d.visualization.VisualizerWithEditing()\n",
    "    vis.create_window()\n",
    "    vis.add_geometry(pcd)\n",
    "    vis.run()  # user picks points\n",
    "    vis.destroy_window()\n",
    "    print(\"\")\n",
    "    return vis.get_picked_points()\n",
    "\n",
    "\n",
    "def demo_manual_registration(src, tgt):\n",
    "    print(\"Demo for manual ICP\")\n",
    "    source = src\n",
    "    target = tgt\n",
    "    print(\"Visualization of two point clouds before manual alignment\")\n",
    "    draw_registration_result(source, target, np.identity(4))\n",
    "\n",
    "    # pick points from two point clouds and builds correspondences\n",
    "    picked_id_source = pick_points(source)\n",
    "    picked_id_target = pick_points(target)\n",
    "    assert (len(picked_id_source) >= 3 and len(picked_id_target) >= 3)\n",
    "    assert (len(picked_id_source) == len(picked_id_target))\n",
    "    corr = np.zeros((len(picked_id_source), 2))\n",
    "    corr[:, 0] = picked_id_source\n",
    "    corr[:, 1] = picked_id_target\n",
    "\n",
    "    # estimate rough transformation using correspondences\n",
    "    print(\"Compute a rough transform using the correspondences given by user\")\n",
    "    p2p = o3d.pipelines.registration.TransformationEstimationPointToPoint()\n",
    "    trans_init = p2p.compute_transformation(source, target,\n",
    "                                            o3d.utility.Vector2iVector(corr))\n",
    "\n",
    "    # point-to-point ICP for refinement\n",
    "    print(\"Perform point-to-point ICP refinement\")\n",
    "    threshold = 0.03  # 3cm distance threshold\n",
    "    reg_p2p = o3d.pipelines.registration.registration_icp(\n",
    "        source, target, threshold, trans_init,\n",
    "        o3d.pipelines.registration.TransformationEstimationPointToPoint())\n",
    "    draw_registration_result(source, target, reg_p2p.transformation)\n",
    "    return reg_p2p.transformation\n",
    "    print(\"\")\n",
    "\n",
    "\n",
    "#if __name__ == \"__main__\":\n",
    "    \n",
    "    #t01 = demo_manual_registration(p[0],p[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7fb67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = colored_ICP(pcds[0],pcds[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1466e563",
   "metadata": {},
   "outputs": [],
   "source": [
    "t01 = register_two_views_teaser(pcds[0],pcds[1],0.05)\n",
    "t12 = register_two_views_teaser(pcds[1],pcds[2],0.05)\n",
    "t52 = register_two_views_teaser(pcds[5],pcds[2],0.05)\n",
    "t43 = register_two_views_teaser(pcds[4],pcds[3],0.05)\n",
    "t32 = register_two_views_teaser(pcds[3],pcds[2],0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6ef01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_registratiaon_result(pcds[0],pcds[1],t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ccff5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "t01 = demo_manual_registration(pcds[0],pcds[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d08d1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "t12 = demo_manual_registration(p[1],p[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f74c2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "t52= demo_manual_registration(p[5],p[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9663b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "t43 = demo_manual_registration(p[4],p[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0dd8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "t01 = colored_ICP(p[0],p[1])\n",
    "draw_registration_result(p[0],p[1],t01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9a20ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "t01 = register_two_views_teaser(c[0],c[1],0.035)\n",
    "t01 = register_two_views_teaser(c[1],c[2],0.045)\n",
    "t01 = register_two_views_teaser(c[5],c[2],0.045)\n",
    "t01 = register_two_views_teaser(c[4],c[3],0.05)\n",
    "t01 = register_two_views_teaser(c[3],c[2],0.35)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7547bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "files_482 = glob.glob(data_path+\"/*.ply\")\n",
    "files_482.sort()\n",
    "\n",
    "pcds_482 = []\n",
    "for file in files_482:\n",
    "    pcds_482.append(o3d.io.read_point_cloud(file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3381a605",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dbae32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "r01,t01 = register_two_views_teaser(pcds_482[0],pcds_482[1],0.05)\n",
    "r13,t13 = register_two_views_teaser(pcds_482[1],pcds_482[3],0.08)\n",
    "#r56,t56 = register_two_views_teaser(pcds_482[5],pcds_482[6],0.05)\n",
    "#r73,t73 = register_two_views_teaser(pcds_482[7],pcds_482[3],0.05)\n",
    "#r67,t67 = register_two_views_teaser(pcds_482[6],pcds_482[7],0.08)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1f58bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "H0 = t13 @ t01\n",
    "H1 = t13\n",
    "H5 = t73 @ t67 @ t56\n",
    "H6 = t73 @ t67\n",
    "H7 = t73"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098108fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "p0 = copy.deepcopy(pcds_482[0]).transform(H0)\n",
    "p1 = copy.deepcopy(pcds_482[1]).transform(H1)\n",
    "p5 = copy.deepcopy(pcds_482[5]).transform(H5)\n",
    "p6 = copy.deepcopy(pcds_482[6]).transform(H6)\n",
    "p7 = copy.deepcopy(pcds_482[7]).transform(H7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6500c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d.visualization.draw_geometries([p0,p1,pcds_482[3],p5,p6,p7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7c1cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "r56,t56 = register_two_views_teaser(pcds_482[5],pcds_482[6],0.05)\n",
    "r73,t73 = register_two_views_teaser(pcds_482[7],pcds_482[3],0.05)\n",
    "r67,t67 = register_two_views_teaser(pcds_482[6],pcds_482[7],0.08)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8b8133",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tforms_apriltag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c7129d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pcds_482)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867cd848",
   "metadata": {},
   "outputs": [],
   "source": [
    "c0 = copy.deepcopy(tforms_apriltag[0]).transform(H0)\n",
    "c1 = copy.deepcopy(tforms_apriltag[1]).transform(H1)\n",
    "c5 = copy.deepcopy(tforms_apriltag[3]).transform(H5)\n",
    "c6 = copy.deepcopy(tforms_apriltag[4]).transform(H6)\n",
    "c7 = copy.deepcopy(tforms_apriltag[5]).transform(H7)\n",
    "\n",
    "o3d.visualization.draw_geometries([c0,c1,c5,c6,c7,tforms_apriltag[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d73fd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for vs in np.arange(0.01,0.09,0.01):\n",
    "    print(vs)\n",
    "    a01,b01 = register_two_views_teaser(tforms_apriltag[0],tforms_apriltag[1],vs)\n",
    "#r,p = register_two_views_teaser(tforms_apriltag[1],tforms_apriltag[2],0.05)\n",
    "#r,p = register_two_views_teaser(tforms_apriltag[3],tforms_apriltag[2],0.05)\n",
    "#r,p = register_two_views_teaser(tforms_apriltag[4],tforms_apriltag[3],0.05)\n",
    "#r,p = register_two_views_teaser(tforms_apriltag[5],tforms_apriltag[2],0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ddff51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d.visualization.draw_geometries([c0,c1,c5,c6,c7,tforms_apriltag[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2743067e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d as o3d\n",
    "# Read the point cloud from a PLY file\n",
    "point_cloud = o3d.io.read_point_cloud(\"/home/vigir3d/Desktop/animal_482_2_demo_cleaned_2.ply\")\n",
    "\n",
    "# Check the number of points in the point cloud\n",
    "print(f\"Point cloud has {len(point_cloud.points)} points.\")\n",
    "\n",
    "# Visualize the point cloud\n",
    "o3d.visualization.draw_geometries([point_cloud])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c74352d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
